Turn 0, F (PhD): OK .
Turn 1, B (Professor): Uh . Somebody else should run this . I 'm sick of being the one to sort of go through and say , " Well , what do you think about this ? " You wanna {disfmarker} ?
Turn 2, D (PhD): Yeah .
Turn 3, F (PhD): Should we take turns ? You want me to run it today ?
Turn 4, B (Professor): Yeah . Why don't you run it today ? OK .
Turn 5, F (PhD): OK . OK . Um . Let 's see , maybe we should just get a list of items {disfmarker} things that we should talk about . Um , I guess there 's the usual {pause} updates , everybody going around and saying , uh , you know , what they 're working on , the things that happened the last week . But aside from that is there anything in particular that anybody wants to bring up
Turn 6, D (PhD): Mmm .
Turn 7, F (PhD): for today ? No ? OK . So why don't we just around and people can give updates .
Turn 8, E (PhD): Oh .
Turn 9, F (PhD): Uh , do you want to start , Stephane ?
Turn 10, C (PhD): Alright . Um . Well , the first thing maybe is that the p Eurospeech paper is , uh , accepted . Um . Yeah .
Turn 11, F (PhD): This is {disfmarker} what {disfmarker} what do you , uh {disfmarker} what 's in the paper there ?
Turn 12, C (PhD): So it 's the paper that describe basically the , um , system that were proposed for the {pause} Aurora .
Turn 13, F (PhD): The one that we s we submitted the last round ?
Turn 14, C (PhD): Right , yeah .
Turn 15, D (PhD): Yeah .
Turn 16, F (PhD): Uh - huh .
Turn 17, C (PhD): Um {disfmarker} Yeah . So and the , fff {comment} comments seems {disfmarker} from the reviewer are good . So .
Turn 18, F (PhD): Hmm .
Turn 19, C (PhD): Mmm {disfmarker} Yeah .
Turn 20, F (PhD): Where {disfmarker} where 's it gonna be this year ?
Turn 21, C (PhD): It 's , uh , Aalborg in Denmark . And it 's ,
Turn 22, F (PhD): Oh , OK .
Turn 23, C (PhD): yeah , September .
Turn 24, F (PhD): Mmm .
Turn 25, C (PhD): Mmm {disfmarker} Yeah . Then , uh , whhh well , I 've been working on {disfmarker} on t mainly on on - line normalization this week . Uh , I 've been trying different {disfmarker} slightly {disfmarker} slightly different approaches . Um , the first thing is trying to play a little bit again with the , um , time constant . Uh , second thing is , uh , the training of , uh , on - line normalization with two different means , one mean for the silence and one for the speech . Um , and so I have two recursions which are controlled by the , um , probability of the voice activity detector . Mmm . This actually don't s doesn't seem to help , although it doesn't hurt . So . But {disfmarker} well , both {pause} on - line normalization approach seems equivalent . Well , they {disfmarker}
Turn 26, F (PhD): Are the means pretty different {pause} for the two ?
Turn 27, C (PhD): Yeah . They can be very different . Yeah . Mm - hmm .
Turn 28, F (PhD): Hmm .
Turn 29, B (Professor): So do you maybe make errors in different places ? Different kinds of errors ?
Turn 30, C (PhD): I didn't look , uh , more closely . Um . It might be , yeah . Mm - hmm . Um . Well , eh , there is one thing that we can observe , is that the mean are more different for {disfmarker} for C - zero and C - one than for the other coefficients . And {disfmarker} Yeah . And {disfmarker} Yeah , it {disfmarker} the C - one is {disfmarker} There are strange {disfmarker} strange thing happening with C - one , is that when you have different kind of noises , the mean for the {disfmarker} the silence portion is {disfmarker} can be different . And {disfmarker}
Turn 31, F (PhD): Hmm .
Turn 32, C (PhD): So when you look at the trajectory of C - one , it 's {disfmarker} has a strange shape and I was expecting th the s that these two mean helps , especially because of the {disfmarker} the strange C - ze C - one shape , uh , which can {disfmarker} like , yo you can have , um , a trajectory for the speech and then when you are in the silence it goes somewhere , but if the noise is different it goes somewhere else .
Turn 33, F (PhD): Oh .
Turn 34, C (PhD): So which would mean that if we estimate the mean based on all the signal , even though we have frame dropping , but we don't frame ev uh , drop everything , but {disfmarker} uh , this can {disfmarker} hurts the estimation of the mean for speech , and {disfmarker} Mmm . {comment} But I still have to investigate further , I think . Um , a third thing is , um , {vocalsound} that instead of t having a fixed time constant , I try to have a time constant that 's smaller at the beginning of the utterances to adapt more quickly to the r something that 's closer to the right mean . T t um {disfmarker} Yeah . And then this time constant increases and I have a threshold that {disfmarker}
Turn 35, B (Professor): Mm - hmm .
Turn 36, C (PhD): well , if it 's higher than a certain threshold , I keep it to this threshold to still , uh , adapt , um , the mean when {disfmarker} {vocalsound} if the utterance is , uh , long enough to {disfmarker} to continue to adapt after , like , one second
Turn 37, B (Professor): Mm - hmm . Mm - hmm .
Turn 38, C (PhD): or {disfmarker} Mmm . Uh , well , this doesn't help neither , but this doesn't hurt . So , well . It seems pretty {disfmarker}
Turn 39, F (PhD): Wasn't there some experiment you were gonna try where you did something differently for each , um , {vocalsound} uh {disfmarker} I don't know whether it was each mel band or each , uh , um , FFT bin or someth There was something you were gonna {disfmarker} uh , {comment} some parameter you were gonna vary depending on the frequency . I don't know if that was {disfmarker}
Turn 40, C (PhD): I guess it was {disfmarker} I don't know . No . u Maybe it 's this {disfmarker} this idea of having different {pause} on - line normalization , um , tunings for the different MFCC 's .
Turn 41, F (PhD): For each , uh {disfmarker}
Turn 42, B (Professor): Mm - hmm .
Turn 43, C (PhD): But {disfmarker} Mm - hmm .
Turn 44, F (PhD): Yeah . I {disfmarker} I thought , Morgan , you brought it up a couple meetings ago . And then it was something about , uh , some and then somebody said " yeah , it does seem like , you know , C - zero is the one that 's , you know , the major one " or , uh , s I can't remember exactly what it was now .
Turn 45, C (PhD): Mmm . Yeah . There {disfmarker} uh , actually , yeah . S um , it 's very important to normalize C - zero and {pause} much less to normalize the other coefficients . And , um , actu uh , well , at least with the current on - line normalization scheme . And we {disfmarker} I think , we {vocalsound} kind of know that normalizing C - one doesn't help with the current scheme . And {disfmarker} and {disfmarker} Yeah . In my idea , I {disfmarker} I was thinking that the {disfmarker} the {disfmarker} the reason is maybe because of these funny things that happen between speech and silence which have different means . Um {disfmarker} Yeah . But maybe it 's not so {disfmarker} {vocalsound} so easy to {disfmarker}
Turn 46, B (Professor): Um , I I really would like to suggest looking , um , a little bit at the kinds of errors . I know you can get lost in that and go forever and not see too much , but {disfmarker} {vocalsound} sometimes ,
Turn 47, C (PhD): Mm - hmm .
Turn 48, B (Professor): but {disfmarker} but , um , just seeing that each of these things didn't make things better may not be enough . It may be that they 're making them better in some ways and worse in others ,
Turn 49, C (PhD): Yeah . Mm - hmm .
Turn 50, B (Professor): or increasing insertions and decreasing deletions , or {disfmarker} or , um , um , you know , helping with noisy case but hurting in quiet case . And if you saw that then maybe you {disfmarker} it would {disfmarker} {vocalsound} something would occur to you of how to deal with that .
Turn 51, C (PhD): Mm - hmm . Mm - hmm .
Turn 52, D (PhD): Hmm .
Turn 53, C (PhD): Alright . Mmm . Yeah . W um , So that 's it , I think , for the on - line normalization . Um {disfmarker} Yeah . I 've been playing a little bit with some kind of thresholding , and , mmm , as a first experiment , I think I Yeah . Well , what I did is t is to take , um {disfmarker} {vocalsound} to measure the average {disfmarker} no , the maximum energy of s each utterance and then put a threshold {disfmarker} Well , this for each mel band . Then put a threshold that 's fifteen DB below {disfmarker} well , uh , a couple of DB below this maximum ,
Turn 54, B (Professor): Mm - hmm . Mmm .
Turn 55, C (PhD): and {disfmarker} Actually it was not a threshold , it was just adding noise .
Turn 56, B (Professor): Mm - hmm .
Turn 57, C (PhD): So I was adding a white noise energy , uh , that 's fifteen DB below the maximum energy of the utterance . And {disfmarker} Yeah . When we look at {disfmarker} at the , um , MFCC that result from this , they are {pause} a lot more smoother . Um , when we compare , like , a channel zero and channel one utterance {disfmarker} um , so a clean and , uh , the same noisy utterance {disfmarker} well , there is almost no difference between the cepstral coefficients of the two .
Turn 58, F (PhD): Hmm .
Turn 59, C (PhD): Um . And {disfmarker} Yeah . And the result that we have in term of speech recognition , actually it 's not {disfmarker} it 's not worse , it 's not better neither , but it 's , um , kind of surprising that it 's not worse
Turn 60, F (PhD): Hmm .
Turn 61, C (PhD): because basically you add noise that 's fifteen DB {disfmarker} just fifteen DB below {pause} the maximum energy .
Turn 62, A (Grad): Sorry .
Turn 63, C (PhD): And at least {disfmarker}
Turn 64, F (PhD): So why does that m {pause} smooth things out ? I don't {disfmarker} I don't understand that .
Turn 65, B (Professor): Well , there 's less difference . Right ?
Turn 66, C (PhD): It 's {disfmarker} I think , it 's whitening {disfmarker} This {disfmarker} the portion that are more silent ,
Turn 67, B (Professor): Cuz it 's {disfmarker}
Turn 68, C (PhD): as you add a white noise that are {disfmarker} has a very high energy , it whitens everything
Turn 69, F (PhD): Huh . Oh , OK .
Turn 70, C (PhD): and {disfmarker} and the high - energy portion of the speech don't get much affected anyway by the other noise . And as the noise you add is the same is {disfmarker} {pause} the shape , it 's also the same .
Turn 71, F (PhD): Hmm .
Turn 72, B (Professor): Yeah .
Turn 73, C (PhD): So they have {disfmarker} the trajectory are very , very similar . And {disfmarker} and {disfmarker}
Turn 74, B (Professor): So , I mean , again , if you trained in one kind of noise and tested in the same kind of noise , you 'd {disfmarker} you know , given enough training data you don't do b do badly . The reason that we d that we have the problems we have is because {pause} it 's different in training and test . Even if {vocalsound} the general kind is the same , the exact instances are different . And {disfmarker} and
Turn 75, F (PhD): Mm - hmm .
Turn 76, B (Professor): so when you whiten it , then it 's like you {disfmarker} the {disfmarker} the only noise {disfmarker} to {disfmarker} to first order , the only th noise that you have is white noise and you 've added the same thing to training and test .
Turn 77, F (PhD): Mm - hmm .
Turn 78, B (Professor): So it 's ,
Turn 79, F (PhD): Hmm .
Turn 80, B (Professor): uh {disfmarker}
Turn 81, F (PhD): So would that {pause} be similar to , like , doing the smoothing , then , over time or {disfmarker} ?
Turn 82, C (PhD): Mm - hmm .
Turn 83, B (Professor): Well , it 's a kind of smoothing ,
Turn 84, C (PhD): I think it 's {disfmarker} I think it 's different .
Turn 85, B (Professor): but {disfmarker}
Turn 86, C (PhD): It 's {disfmarker} it 's something that {disfmarker} yeah , that affects more or less the silence portions because {disfmarker}
Turn 87, F (PhD): Mm - hmm .
Turn 88, C (PhD): Well , anyway , the sp the portion of speech that ha have high energy are not ch a lot affected by the noises in the Aurora database .
Turn 89, B (Professor): Mm - hmm .
Turn 90, C (PhD): If {disfmarker} if you compare th the two shut channels of SpeechDat - Car during speech portion , it 's n n n the MFCC are not very different . They are very different when energy 's lower , like during fricatives or during speech pauses . And ,
Turn 91, B (Professor): Yeah , but you 're still getting more recognition errors ,
Turn 92, C (PhD): uh {disfmarker}
Turn 93, B (Professor): which means {vocalsound} that the differences , even though they look like they 're not so big , {vocalsound} are {disfmarker} are hurting your recognition .
Turn 94, C (PhD): Ye
Turn 95, B (Professor): Right ?
Turn 96, C (PhD): Yeah . So it distort {vocalsound} the speech . Right .
Turn 97, B (Professor): Yeah .
Turn 98, C (PhD): Um .
Turn 99, F (PhD): So performance went down ?
Turn 100, C (PhD): No . It didn't . But {disfmarker}
Turn 101, F (PhD): Oh .
Turn 102, C (PhD): Yeah . So , but in this case I {disfmarker} I really expect that maybe the {disfmarker} the two {disfmarker} these two stream of features , they are very different . I mean , and maybe we could gain something by combining them
Turn 103, B (Professor): Well , the other thing is that you just picked one particular way of doing it .
Turn 104, C (PhD): or {disfmarker}
Turn 105, B (Professor): Uh , I mean , first place it 's fifteen DB , uh , {vocalsound} down across the utterance . And {vocalsound} maybe you 'd want to have something that was a little more adaptive . Secondly , you happened to pick fifteen DB
Turn 106, C (PhD): Mmm .
Turn 107, B (Professor): and maybe twenty 'd be better ,
Turn 108, C (PhD): Yeah .
Turn 109, B (Professor): or {disfmarker} or twelve .
Turn 110, C (PhD): Yeah . Right .
Turn 111, F (PhD): So what was the {disfmarker} what was the threshold part of it ? Was the threshold , uh , how far down {disfmarker} ?
Turn 112, B (Professor): Yeah . Well , he {disfmarker} yeah , he had to figure out how much to add . So he was looking {disfmarker} he was looking at the peak value .
Turn 113, F (PhD): Uh - huh .
Turn 114, B (Professor): Right ? And then {disfmarker}
Turn 115, C (PhD): Uh - huh .
Turn 116, F (PhD): And {disfmarker} and so what 's {disfmarker} ho I don't understand . How does it go ? If it {disfmarker} if {disfmarker} if the peak value 's above some threshold , then you add the noise ? Or if it 's below s
Turn 117, C (PhD): I systematically {comment} add the noise , but the , um , noise level is just {pause} some kind of threshold below the peak .
Turn 118, F (PhD): Oh , oh . I see .
Turn 119, C (PhD): Mmm .
Turn 120, F (PhD): I see .
Turn 121, B (Professor): Yeah .
Turn 122, C (PhD): Um . Yeah . Which is not really noise , actually . It 's just adding a constant to each of the mel , uh , energy .
Turn 123, F (PhD): Mm - hmm .
Turn 124, C (PhD): To each of the {pause} mel filter bank . Yeah .
Turn 125, F (PhD): I see .
Turn 126, C (PhD): So , yeah , it 's really , uh , white noise . I th
Turn 127, B (Professor): Yeah .
Turn 128, F (PhD): Mm - hmm .
Turn 129, B (Professor): So then afterwards a log is taken , and that 's so sort of why the {disfmarker} {vocalsound} the little variation tends to go away .
Turn 130, C (PhD): Mm - hmm . Um . Yeah . So may Well , the {disfmarker} this threshold is still a factor that we have to look at . And I don't know , maybe a constant noise addition would {disfmarker} {vocalsound} would be fine also , or {disfmarker} Um {disfmarker}
Turn 131, B (Professor): Or {disfmarker} or not constant but {disfmarker} but , uh , varying over time {pause} in fact is another way {pause} to go .
Turn 132, C (PhD): Mm - hmm . Mm - hmm .
Turn 133, B (Professor): Um .
Turn 134, C (PhD): Yeah . Um {disfmarker}
Turn 135, B (Professor): Were you using the {disfmarker} the normalization in addition to this ? I mean , what was the rest of the system ?
Turn 136, C (PhD): Um {disfmarker} Yeah . It was {disfmarker} it was , uh , the same system . Mm - hmm .
Turn 137, B (Professor): OK .
Turn 138, C (PhD): It was the same system . Mmm . Oh , yeah . A third thing is that , um , {vocalsound} I play a little bit with the , um {disfmarker} {vocalsound} finding what was different between , um , And there were a couple of differences , like the LDA filters were not the same . Um , he had the France Telecom blind equalization in the system . Um , the number o of MFCC that was {disfmarker} were used was different . You used thirteen and we used fifteen . Well , a bunch of differences . And , um , actually the result that he {disfmarker} he got were much better on TI - digits especially . So I 'm kind of investigated to see what was the main factor for this difference . And it seems that the LDA filter is {disfmarker} is {disfmarker} was hurting . Um , {vocalsound} so when we put s some noise compensation the , um , LDA filter that {disfmarker} that 's derived from noisy speech is not more {disfmarker} anymore optimal . And it makes a big difference , um , {vocalsound} on TI - digits trained on clean . Uh , if we use the {disfmarker} the old LDA filter , I mean the LDA filter that was in the proposal , we have , like , eighty - two point seven percent recognition rate , um , on noisy speech when the system is trained on clean speech . But {disfmarker} and when we use the filter that 's derived from clean speech we jumped {disfmarker} so from eighty - two point seven to eighty - five point one , which is a huge leap .
Turn 139, B (Professor): Mm - hmm .
Turn 140, C (PhD): Um . Yeah . So now the results are more similar , and I don't {disfmarker} I will not , I think , investigate on the other differences , which is like the number of MFCC that we keep and other small things that we can I think optimize later on anyway .
Turn 141, B (Professor): Sure . But on the other hand if everybody is trying different kinds of noise suppression things and so forth , it might be good to standardize on the piece {vocalsound} that we 're not changing . Right ? So if there 's any particular reason to ha pick one or the other , I mean {disfmarker} Which {disfmarker} which one is closer to what the proposal was that was submitted to Aurora ? Are they {disfmarker} they both {disfmarker} ? Well , I mean {disfmarker}
Turn 142, C (PhD): I think {disfmarker} Yeah . I think th th uh , the new system that I tested is , I guess , closer because it doesn't have {disfmarker} it have less of {disfmarker} of France Telecom stuff ,
Turn 143, D (PhD): You mean the {disfmarker}
Turn 144, C (PhD): I {disfmarker}
Turn 145, D (PhD): The {disfmarker} whatever you , uh , tested with recently . Right ?
Turn 146, C (PhD): Mmm ? Yeah .
Turn 147, D (PhD): Yeah ?
Turn 148, B (Professor): Well , no , I {disfmarker} I 'm {disfmarker} I {disfmarker} Yeah , you 're trying to add in France Telecom .
Turn 149, C (PhD): But , we {disfmarker}
Turn 150, B (Professor): Tell them about the rest of it . Like you said the number of filters might be {vocalsound} different or something . Right ? Or {disfmarker}
Turn 151, D (PhD): The number of cepstral coefficients is what ?
Turn 152, B (Professor): Cep
Turn 153, C (PhD): Mm - hmm .
Turn 154, B (Professor): Yeah . So , I mean , I think we 'd wanna standardize there , wouldn't we ?
Turn 155, C (PhD): Yeah , yeah .
Turn 156, B (Professor): So , sh you guys should pick something
Turn 157, D (PhD): Yeah .
Turn 158, B (Professor): and {disfmarker} Well , all th all three of you .
Turn 159, D (PhD): Yeah .
Turn 160, C (PhD): I think we were gonna work with {disfmarker} with this or this new system , or with {disfmarker}
Turn 161, D (PhD): Uh , so the {disfmarker} the {disfmarker} right now , the {disfmarker} the system that is there in the {disfmarker} what we have in the repositories , with {disfmarker} uses fifteen .
Turn 162, C (PhD): So {disfmarker} Right . Yeah .
Turn 163, D (PhD): Yeah , so {disfmarker} Yeah , so {disfmarker} Yep .
Turn 164, C (PhD): But we will use the {disfmarker} the LDA filters f derived from clean speech . Well , yeah , actually it 's {disfmarker} it 's not the {disfmarker} the LDA filter .
Turn 165, D (PhD): Yeah , yeah . So {disfmarker}
Turn 166, C (PhD): It 's something that 's also short enough in {disfmarker} in latency .
Turn 167, D (PhD): Yeah . Well .
Turn 168, C (PhD): So .
Turn 169, D (PhD): Yeah . So , we haven't {disfmarker} w we have been always using , uh , fifteen coefficients ,
Turn 170, C (PhD): Yeah .
Turn 171, D (PhD): not thirteen ?
Turn 172, C (PhD): Mm - hmm .
Turn 173, D (PhD): Yeah . Well , uh , that 's {disfmarker} something 's {disfmarker} Um . Yeah . Then {disfmarker}
Turn 174, B (Professor): I think as long as you guys agree on it , it doesn't matter .
Turn 175, D (PhD): mmm {disfmarker}
Turn 176, B (Professor): I think we have a maximum of sixty , {vocalsound} uh , features that we 're allowed . So .
Turn 177, C (PhD): Yeah .
Turn 178, D (PhD): Yeah . Ma - maybe we can {disfmarker} I mean , at least , um , I 'll t s run some experiments to see whether {disfmarker} once I have this {vocalsound} {comment} noise compensation to see whether thirteen and fifteen really matters or not .
Turn 179, C (PhD): Mm - hmm . Mm - hmm .
Turn 180, D (PhD): Never tested it with the compensation , but without , {vocalsound} uh , compensation it was like fifteen was s slightly better than thirteen ,
Turn 181, C (PhD): Yeah .
Turn 182, D (PhD): so that 's why we stuck to thirteen .
Turn 183, C (PhD): Yeah . And there is {disfmarker} there is also this log energy versus C - zero .
Turn 184, D (PhD): Sorry , fifteen . Yeah , the log energy versus C - zero .
Turn 185, C (PhD): Well . W w if {disfmarker} if {disfmarker}
Turn 186, D (PhD): Uh , that 's {disfmarker} that 's the other thing . I mean , without noise compensation certainly C - zero is better than log energy . Be - I mean , because the {disfmarker} there are more , uh , mismatched conditions than the matching conditions for testing .
Turn 187, C (PhD): Mm - hmm .
Turn 188, D (PhD): You know , always for the matched condition , you always get a {pause} slightly better performance for log energy than C - zero .
Turn 189, C (PhD): Mm - hmm .
Turn 190, D (PhD): But not for {disfmarker} I mean , for matched and the clean condition both , you get log energy {disfmarker} I mean you get a better performance with log energy .
Turn 191, C (PhD): Mm - hmm .
Turn 192, D (PhD): Well , um , maybe once we have this noise compensation , I don't know , we have to try that also , whether we want to go for C - zero or log energy .
Turn 193, C (PhD): Mm - hmm .
Turn 194, D (PhD): We can see that .
Turn 195, C (PhD): Yeah .
Turn 196, D (PhD): Hmm .
Turn 197, C (PhD): Mmm .
Turn 198, F (PhD): So do you have {pause} more , Stephane , or {disfmarker} ?
Turn 199, C (PhD): Uh , that 's it , I think . Mmm .
Turn 200, F (PhD): Do you have anything , Morgan , or {disfmarker} ?
Turn 201, B (Professor): Uh , no . I 'm just , you know , being a manager this week . So .
Turn 202, F (PhD): How about you , Barry ?
Turn 203, A (Grad): Um , {vocalsound} still working on my {disfmarker} my quals preparation stuff . Um , {vocalsound} so I 'm {disfmarker} I 'm thinking about , um , starting some , {vocalsound} uh , cheating experiments to , uh , determine the , um {disfmarker} {vocalsound} the relative effectiveness of , um , some intermediate categories that I want to classify . So , for example , um , {vocalsound} if I know where voicing occurs and everything , um , {vocalsound} I would do a phone {disfmarker} um , phone recognition experiment , um , somehow putting in the {disfmarker} the , uh {disfmarker} the perfect knowledge that I have about voicing . So , um , in particular I was thinking , {vocalsound} um , in {disfmarker} in the hybrid framework , just taking those LNA files , {vocalsound} and , um , {vocalsound} setting to zero those probabilities that , um {disfmarker} that these phones are not voicing . So say , like , I know this particular segment is voicing , um , {vocalsound} I would say , uh , go into the corresponding LNA file and zonk out the {disfmarker} the posteriors for , um , those phonemes that , um , are not voiced ,
Turn 204, F (PhD): Mm - hmm . Mm - hmm .
Turn 205, A (Grad): and then see what kinds of improvements I get . And so this would be a useful thing , um , to know {vocalsound} in terms of , like , which {disfmarker} which , um {disfmarker} which of these categories are {disfmarker} are good for , um , speech recognition .
Turn 206, F (PhD): Hmm . Mm - hmm .
Turn 207, A (Grad): So , that 's {disfmarker} I hope to get those , uh {disfmarker} those experiments done by {disfmarker} by the time quals come {disfmarker} come around in July .
Turn 208, F (PhD): So do you just take the probabilities of the other ones and spread them out evenly among the {disfmarker} the remaining ones ?
Turn 209, A (Grad): Yeah . I {disfmarker} I {disfmarker} I was thinking {disfmarker} OK , so just set to {disfmarker} set to some really low number , the {disfmarker} the non - voiced , um , phones .
Turn 210, F (PhD): Mm - hmm .
Turn 211, A (Grad): Right ? And then renormalize .
Turn 212, F (PhD): Mmm .
Turn 213, A (Grad): Right . Yeah .
Turn 214, D (PhD): Mm - hmm .
Turn 215, F (PhD): Cool . That will be really interesting to see , you know . So then you 're gonna feed the {disfmarker} those into {pause} some standard recognizer .
Turn 216, A (Grad): Mm - hmm .
Turn 217, F (PhD): Uh , wh are you gonna do digits
Turn 218, A (Grad): Yeah , m Um , well , I 'm gonna f work with TIMIT {disfmarker}
Turn 219, F (PhD): or {disfmarker} ? With TIMIT . OK .
Turn 220, A (Grad): TIMIT {disfmarker} uh , phone recognition with TIMIT .
Turn 221, F (PhD): Mm - hmm .
Turn 222, A (Grad): And , um {disfmarker}
Turn 223, F (PhD): Oh , so then you 'll feed those {disfmarker} Sorry . So where do the outputs of the net go into if you 're doing phone recognition ?
Turn 224, A (Grad): Oh . Um , the outputs of the net go into the standard , h um , ICSI hybrid , um , recognizer . So maybe , um , Chronos
Turn 225, F (PhD): An - and you 're gonna {disfmarker} the {disfmarker} you 're gonna do phone recognition with that ?
Turn 226, A (Grad): or {disfmarker} Phone recognition . Right , right .
Turn 227, F (PhD): OK , OK . I see .
Turn 228, A (Grad): So . And , uh , another thing would be to extend this to , uh , digits or something where I can look at whole words .
Turn 229, F (PhD): Mm - hmm .
Turn 230, A (Grad): And I would be able to see , uh , not just , like , phoneme events , but , um , {vocalsound} inter - phoneme events . So , like , this is from a stop to {disfmarker} to a vo a vocalic
Turn 231, F (PhD): Mm - hmm .
Turn 232, A (Grad): segment . You know , so something that is transitional in nature .
Turn 233, F (PhD): Right .
Turn 234, A (Grad): Yeah .
Turn 235, F (PhD): Cool . Great .
Turn 236, A (Grad): So that 's {disfmarker} that 's it .
Turn 237, F (PhD): Uh {disfmarker} OK .
Turn 238, A (Grad): Yeah .
Turn 239, F (PhD): Um {disfmarker} Let 's see , I haven't done a whole lot on anything related to this this week . I 've been focusing mainly on Meeting Recorder stuff .
Turn 240, C (PhD): Oh .
Turn 241, F (PhD): So , um , {vocalsound} I guess I 'll just pass it on to Dave .
Turn 242, G (Grad): Uh , OK . Well , in my lunch talk last week I {disfmarker} I said I 'd tried phase normalization and gotten garbage results using that l um , long - term mean subtraction approach . It turned out there was a bug in my Matlab code . So I tried it again , um , and , um , the results {vocalsound} were {disfmarker} were better . I got intelligible speech back . But they still weren't as good as just subtracting the magnitude {disfmarker} the log magnitude means . And also I 've been talking to , um , Andreas and Thilo about the , um , SmartKom language model and about coming up with a good model for , um , far mike use of the SmartKom system . So I 'm gonna be working on , um , implementing this mean subtraction approach in the {vocalsound} far - mike system {disfmarker} for the SmartKom system , I mean . And , um , one of the experiments we 're gonna do is , um , we 're gonna , um , train the {disfmarker} a Broadcast News net , which is because that 's what we 've been using so far , and , um , adapt it on some other data . Um , An - Andreas wants to use , um , data that resembles read speech , like {pause} these digit readings , because he feels that the SmartKom system interaction is not gonna be exactly conversational .
Turn 243, F (PhD): Mm - hmm .
Turn 244, G (Grad): S so actually I was wondering , how long does it take to train that Broadcast News net ?
Turn 245, B (Professor): The big one takes a while . Yeah . That takes two , three weeks .
Turn 246, G (Grad): Two , three weeks .
Turn 247, B (Professor): So {disfmarker} but , you know , uh , you can get {disfmarker} I don't know if you even want to run the big one , uh , um , in the {disfmarker} in the final system , cuz , you know , it takes a little while to run it . So , {vocalsound} um , you can scale it down by {disfmarker} I 'm sorry , it was two , three weeks for training up for the large Broadcast News test set {disfmarker} training set . I don't know how much you 'd be training on .
Turn 248, G (Grad): Oh .
Turn 249, B (Professor): The full ?
Turn 250, G (Grad): OK .
Turn 251, B (Professor): Uh , i so if you trained on half as much {vocalsound} and made the net , uh , uh , half as big , then it would be one fourth {pause} the amount of time
Turn 252, G (Grad): OK .
Turn 253, B (Professor): and it 'd be nearly as good . So .
Turn 254, G (Grad): OK .
Turn 255, B (Professor): Yeah . Also , I guess we had {disfmarker} we 've had these , uh , little di discussions {disfmarker} I guess you ha haven't had a chance to work with it too much {disfmarker} about {disfmarker} about , uh {disfmarker} uh , uh m other ways of taking care of the phase . So , I mean , I {disfmarker} I guess that was something I could say would be that we 've talked a little bit about
Turn 256, G (Grad): Mm - hmm .
Turn 257, B (Professor): you just doing it all with complex arithmetic and , uh {disfmarker} and not {disfmarker} not , uh , doing the polar representation with magnitude and phase . But {vocalsound} it looks like there 's ways that one could potentially just work with the complex numbers and {disfmarker} and {disfmarker} and in principle get rid of the {vocalsound} effects of the average complex spectrum . But {disfmarker}
Turn 258, G (Grad): And , um , actually , regarding the phase normalization {disfmarker} So I did two experiments , and one is {disfmarker} So , phases get added , modulo two pi , and {disfmarker} because you only know the phase of the complex number t t to a value modulo two pi . And so I thought at first , um , that , uh , what I should do is unwrap the phase because that will undo that . Um , but I actually got worse results doing that unwrapping using the simple phase unwrapper that 's in Matlab than I did not unwrapping at all .
Turn 259, D (PhD): Mm - hmm .
Turn 260, F (PhD): Hmm .
Turn 261, B (Professor): Yeah . P So .
Turn 262, G (Grad): And that 's all I have to say .
Turn 263, F (PhD): Hmm .
Turn 264, B (Professor): Yeah . So I 'm {disfmarker} I 'm still hopeful that {disfmarker} that {disfmarker} I mean , we {disfmarker} we don't even know if the phase {vocalsound} is something {disfmarker} the average phase is something that we do want to remove . I mean , maybe there 's some deeper reason why it isn't the right thing to do . But , um , at least in principle it looks like there 's {disfmarker} there 's , uh , a couple potential ways to do it . One {disfmarker} one being to just work with the complex numbers , um , and , uh {disfmarker} in rectangular kind of coordinates . And the other is {vocalsound} to , uh , do a Taylor series {disfmarker} Well . So you work with the complex numbers and then when you get the spectrum {disfmarker} the average complex spectrum {disfmarker} um , actually divide it out , um , as opposed to taking the log and subtracting . So then , um , um , you know , there might be some numerical issues . We don't really know that . The other thing we talked a little bit about was Taylor series expansion . And , um , uh , actually I was talking to Dick Karp about it a little bit , and {disfmarker} and {disfmarker} and , since I got thinking about it , and {disfmarker} and , uh , so one thing is that y you 'd have to do , I think , uh {disfmarker} we may have to do this on a whiteboard , but I think you have to be a little careful about scaling the numbers that you 're {vocalsound} taking {disfmarker} the complex numbers that you 're taking the log of because {vocalsound} the Taylor expansion for it has , you know , a square and a cube , and {disfmarker} and so forth . And {disfmarker} and so if {disfmarker} {vocalsound} if you have a {disfmarker} a number that is modulus , you know , uh , very different from one {disfmarker} {vocalsound} It should be right around one , if it 's {disfmarker} cuz it 's a expansion of log one {disfmarker} one minus epsilon or o is {disfmarker} is {vocalsound} one plus epsilon , or is it one plus {disfmarker} ? Well , there 's an epsilon squared over two and an epsilon cubed over three ,
Turn 265, G (Grad): OK .
Turn 266, B (Professor): and so forth . So if epsilon is bigger than one , then it diverges .
Turn 267, G (Grad): Oh .
Turn 268, B (Professor): So you have to do some scaling . But that 's not a big deal cuz it 's the log of {disfmarker} {vocalsound} of K times a complex number , then you can just {disfmarker} that 's the same as log of K plus {vocalsound} log of the complex number .
Turn 269, G (Grad): Oh .
Turn 270, B (Professor): Uh , so there 's {disfmarker}
Turn 271, G (Grad): OK .
Turn 272, B (Professor): converges . But .
Turn 273, F (PhD): Hmm . OK . How about you , Sunil ?
Turn 274, D (PhD): So , um , I 've been , uh , implementing this , uh , Wiener filtering for this Aurora task . And , uh , I {disfmarker} I actually thought it was {disfmarker} it was doing fine when I tested it once . I it 's , like , using a small section of the code . And then I ran the whole recognition experiment with Italian and I got , {vocalsound} like , worse results than not using it . Then I {disfmarker} So , I 've been trying to find where the problem came from . And then it looks like I have some problem in the way {disfmarker} there is some {disfmarker} some very silly bug somewhere . And , ugh ! I {disfmarker} I mean , i uh , it actually {disfmarker} i it actually made the whole thing worse . I was looking at the spectrograms that I got and it 's , like {disfmarker} w it 's {disfmarker} it 's very horrible . Like , when I {disfmarker}
Turn 275, B (Professor): I {disfmarker} I missed the v I 'm sorry , I was {disfmarker} I was distracted . I missed the very first sentence . So then , I 'm a little lost on the rest .
Turn 276, D (PhD): Oh , I mean {disfmarker}
Turn 277, B (Professor): What {disfmarker} what {disfmarker} what {disfmarker} ?
Turn 278, D (PhD): Oh , yeah . I actually implemented the Wiener f f fil filtering as a module and then tested it out separately .
Turn 279, B (Professor): Yeah , I see . Oh , OK .
Turn 280, D (PhD): And it {disfmarker} it {disfmarker} it gave , like {disfmarker} I just got the signal out and it {disfmarker} it was OK . So , I plugged it in somewhere and then {disfmarker} I mean , it 's like I had to remove some part and then plugging it in somewhere . And then I {disfmarker} in that process I messed it up somewhere .
Turn 281, B (Professor): OK .
Turn 282, D (PhD): So . So , it was real I mean , I thought it was all fine and then I ran it , and I got something worse than not using it . So , I was like {disfmarker} I 'm trying to find where the m m problem came ,
Turn 283, B (Professor): Uh - huh .
Turn 284, D (PhD): and it seems to be , like , somewhere {disfmarker}
Turn 285, B (Professor): OK .
Turn 286, D (PhD): some silly stuff . And , um , the other thing , uh , was , uh , uh {disfmarker} Well , Hynek showed up one {disfmarker} suddenly on one day and then I was t talking wi
Turn 287, B (Professor): Right . Yeah . As {disfmarker} as he is wont to do . Yeah .
Turn 288, D (PhD): Uh , yeah . So I was actually {disfmarker} that day I was thinking about d doing something about the Wiener filtering , and then Carlos matter of stuff . And then he showed up and then I told him . And then he gave me a whole bunch of filters {disfmarker} what Carlos used for his , uh , uh , thesis and then {vocalsound} that was something which came up . And then , um {disfmarker} So , uh , I 'm actually , {vocalsound} uh , thinking of using that also in this , uh , W Wiener filtering because that is a m modified Wiener filtering approach , where instead of using the current frame , it uses {vocalsound} adjacent frames also in designing the Wiener filter . So instead of designing our own new Wiener filters , I may just use one of those Carlos filters in {disfmarker} in this implementation
Turn 289, B (Professor): Mm - hmm .
Turn 290, D (PhD): and see whether it {disfmarker} it actually gives me something better than using just the current f current frame , which is in a way , uh , something like the smoothing {disfmarker} the Wiener filter {disfmarker}
Turn 291, B (Professor): Mm - hmm .
Turn 292, D (PhD): but @ @ {disfmarker} S so , I don't know , I was h I 'm {disfmarker} I 'm {disfmarker} I 'm , like {disfmarker} that {disfmarker} so that is the next thing . Once this {disfmarker} I {disfmarker} once I sort this pro uh , problem out maybe I 'll just go into that also . And the {disfmarker} the other thing was about the subspace approach . So , um , I , like , plugged some groupings for computing this eigen uh , uh , uh , s values and eigenvectors . So just {disfmarker} I just @ @ some small block of things which I needed to put together for the subspace approach . And I 'm in the process of , like , building up that stuff . And , um , uh {disfmarker} {nonvocalsound} Yeah . I guess {disfmarker} Yep . I guess that 's it . And , uh , th th that 's where I am right now . So .
Turn 293, F (PhD): Oh . How about you , Carmen ?
Turn 294, E (PhD): Mmm . I 'm working with VTS . Um , I do several experiment with the Spanish database first , only with VTS and nothing more . Not VAD , no LDA , nothing more .
Turn 295, F (PhD): What {disfmarker} what is VTS again ?
Turn 296, D (PhD): New {disfmarker}
Turn 297, E (PhD): Eh , Vectorial Taylor Series .
Turn 298, F (PhD): Oh , yes .
Turn 299, E (PhD): To remove the noise too .
Turn 300, F (PhD): Right , right . I think I ask you that every single meeting , don't I ?
Turn 301, E (PhD): What ?
Turn 302, F (PhD): I ask you that question every meeting .
Turn 303, E (PhD): Yeah .
Turn 304, B (Professor): So , that 'd be good from {disfmarker} for analysis .
Turn 305, E (PhD): If {disfmarker} Well {disfmarker}
Turn 306, B (Professor): It 's good to have some , uh , cases of the same utterance at different {disfmarker} different times .
Turn 307, F (PhD): Yeah .
Turn 308, B (Professor): Yeah .
Turn 309, F (PhD): " What is VTS ? "
Turn 310, E (PhD): VTS . I 'm sor Well , um , the question is that {disfmarker} Well . Remove some noise but not too much . And when we put the {disfmarker} m m the , em , VAD , the result is better . And we put everything , the result is better , but it 's not better than the result that we have without VTS . No , no .
Turn 311, B (Professor): I see . So that @ @ {comment} given that you 're using the VAD also , the effect of the VTS is not {pause} so far {disfmarker}
Turn 312, E (PhD): Is not .
Turn 313, B (Professor): Do you {disfmarker} How much of that do you think is due to just the particular implementation and how much you 're adjusting it ? Or how much do you think is intrinsic to {disfmarker} ?
Turn 314, E (PhD): Pfft . I don't know because {disfmarker}
Turn 315, C (PhD): Are you still using only the ten first frame for noise estimation
Turn 316, E (PhD): Hhh ,
Turn 317, C (PhD): or {disfmarker} ? Or i ?
Turn 318, E (PhD): Uh , I do the experiment using only the f onl eh , to use on only one fair estimation of the noise .
Turn 319, C (PhD): Yeah . Hmm .
Turn 320, E (PhD): And also I did some experiment , {vocalsound} uh , doing , um , a lying estimation of the noise . And , well , it 's a little bit better but not {disfmarker} n
Turn 321, C (PhD): Maybe you have to standardize this thing also , noise estimation , because all the thing that you are testing use a different {disfmarker} They all need some {disfmarker} some noise {disfmarker} noise spectra
Turn 322, D (PhD): Mmm .
Turn 323, E (PhD): Mmm . No , I do that two {disfmarker} t did two time .
Turn 324, C (PhD): but they use {disfmarker} every {disfmarker} all use a different one .
Turn 325, B (Professor): I have an idea . If {disfmarker} if , uh , uh , y you 're right . I mean , each of these require this . Um , given that we 're going to have for this test at least of {disfmarker} uh , boundaries , what if initially we start off by using {pause} known sections of nonspeech {pause} for the estimation ?
Turn 326, C (PhD): Mm - hmm .
Turn 327, E (PhD): Mm - hmm .
Turn 328, B (Professor): Right ? S so , e um ,
Turn 329, C (PhD): Yeah . Mm - hmm .
Turn 330, B (Professor): first place , I mean even if ultimately we wouldn't be given the boundaries , {vocalsound} uh , this would be a good initial experiment to separate out the effects of things . I mean , how much is the poor {disfmarker} {vocalsound} you know , relatively , uh , unhelpful result that you 're getting in this or this or this is due to some inherent limitation to the method for these tasks and how much of it is just due to the fact that you 're not accurately {vocalsound} finding enough regions that {disfmarker} that are really {vocalsound} n noise ?
Turn 331, D (PhD): Mmm .
Turn 332, E (PhD): Mm - hmm .
Turn 333, C (PhD): Mm - hmm .
Turn 334, B (Professor): Um . So maybe if you tested it using that , {vocalsound} you 'd have more reliable {pause} stretches of nonspeech to do the estimation from and see if that helps .
Turn 335, E (PhD): Yeah . Another thing is the , em {disfmarker} the codebook , the initial codebook . That maybe , well , it 's too clean and {disfmarker}
Turn 336, B (Professor): Mm - hmm .
Turn 337, E (PhD): Cuz it 's a {disfmarker} I don't know . The methods {disfmarker} If you want , you c I can say something about the method .
Turn 338, B (Professor): Mm - hmm .
Turn 339, E (PhD): Yeah . In the {disfmarker} Because it 's {vocalsound} a little bit different of the other method . Well , we have {disfmarker} If this {disfmarker} if this is the noise signal , {nonvocalsound} uh , in the log domain , we have something like this . Now , we have something like this . And the idea of these methods is to {disfmarker} {vocalsound} n given a , um {disfmarker}
Turn 340, B (Professor): 
Turn 341, E (PhD): How do you say ? I will read because it 's better for my English . I i given is the estimate of the PDF of the noise signal when we have a , um , a statistic of the clean speech and an statistic of the noisy speech . And the clean speech {disfmarker} the statistic of the clean speech is {pause} from a {pause} codebook . Mmm ? This is the idea . Well , like , this relation is not linear . The methods propose to develop this in a vectorial Taylor series {pause} approximation .
Turn 342, B (Professor): I I 'm actually just confused about {pause} the equations you have up there . So , uh , the top equation is {disfmarker} is {disfmarker} is {disfmarker}
Turn 343, E (PhD): No , this in the {disfmarker} it 's {disfmarker} this is the log domain . I {disfmarker} I must to say that .
Turn 344, B (Professor): Which is {disfmarker} which is the log domain ?
Turn 345, E (PhD): Is the T {disfmarker} is egual {disfmarker} {comment} is equal to , uh , log of {disfmarker}
Turn 346, B (Professor): And {disfmarker} but Y is what ? Y of {disfmarker} the spectrum
Turn 347, E (PhD): Uh , this {disfmarker} this is this
Turn 348, B (Professor): or {disfmarker} ?
Turn 349, E (PhD): and this is this .
Turn 350, B (Professor): No , no . The top Y is what ?
Turn 351, E (PhD): Mm - hmm .
Turn 352, B (Professor): Is that power spectrum ?
Turn 353, E (PhD): Uh , this is the noisy speech .
Turn 354, C (PhD): p s this {disfmarker}
Turn 355, B (Professor): No , is that power spectrum ? Is it {disfmarker} ?
Turn 356, C (PhD): Yeah . I guess it 's the power spectrum of noisy speech .
Turn 357, E (PhD): Yeah . It 's the power spectrum .
Turn 358, B (Professor): Oh , OK .
Turn 359, C (PhD): Yeah . And {disfmarker}
Turn 360, B (Professor): So that 's uh {disfmarker}
Turn 361, E (PhD): This is the noisy {disfmarker} Yeah , it 's {disfmarker}
Turn 362, B (Professor): OK .
Turn 363, E (PhD): of the value {disfmarker}
Turn 364, B (Professor): Yeah , OK . So this {disfmarker} it 's the magnitude squared or something .
Turn 365, E (PhD): Yeah .
Turn 366, B (Professor): OK , so you have power spectrum added there and down here you have {disfmarker} {vocalsound} you {disfmarker} you put the {disfmarker} depends on T , but {disfmarker} b all of this is just {disfmarker} you just mean {disfmarker}
Turn 367, E (PhD): w o Yeah . It 's the same .
Turn 368, B (Professor): you just mean the log of the {disfmarker} of the one up above .
Turn 369, E (PhD): Yeah .
Turn 370, B (Professor): And , uh , so that is X times ,
Turn 371, C (PhD): Mm - hmm .
Turn 372, B (Professor): uh ,
Turn 373, D (PhD): One {disfmarker} one plus N by X .
Turn 374, E (PhD): Yeah , maybe {disfmarker}
Turn 375, B (Professor): o
Turn 376, E (PhD): But , n Well , y we can expre we can put this expression {disfmarker}
Turn 377, B (Professor): X times one plus , uh , N {disfmarker} uh , N {disfmarker} N {disfmarker} N minus X ?
Turn 378, E (PhD): The {disfmarker} Yeah .
Turn 379, B (Professor): And then , uh {disfmarker} So that 's log of X plus log of one plus , uh {disfmarker}
Turn 380, E (PhD): And the noise signal .
Turn 381, B (Professor): Well . Is that right ? Log of {disfmarker}
Turn 382, D (PhD): One plus N by X .
Turn 383, E (PhD): Well , mmm {disfmarker}
Turn 384, B (Professor): I actually don't see how you get that . Uh .
Turn 385, E (PhD): Well , if we apply the log , we have E is n
Turn 386, C (PhD): Mmm .
Turn 387, D (PhD): Uh , and {disfmarker}
Turn 388, E (PhD): uh , log {disfmarker} {nonvocalsound} E is equal , oh , to log of X plus N .
Turn 389, B (Professor): Yeah .
Turn 390, E (PhD): And , well ,
Turn 391, D (PhD): And , log of {disfmarker}
Turn 392, E (PhD): uh , we can say that E {nonvocalsound} {vocalsound} is equal to log of , {nonvocalsound} {nonvocalsound} um , exponential of X plus exponential of N .
Turn 393, B (Professor): Uh {disfmarker}
Turn 394, D (PhD): Mm - hmm .
Turn 395, B (Professor): No .
Turn 396, D (PhD): No .
Turn 397, B (Professor): That doesn't follow .
Turn 398, D (PhD): Well , if E restricts {disfmarker} It is y
Turn 399, E (PhD): Well , this is {disfmarker} this is in the ti the time domain . Well , we have that , um {disfmarker} We have first that , for example , X is equal , uh {disfmarker} Well . This is the frequency domain
Turn 400, B (Professor): Yeah .
Turn 401, E (PhD): and we can put {vocalsound} u that n the log domain {disfmarker} log of X omega , but , well , in the time domain we have an exponential . No ? No ? Oh , maybe it 's I am {disfmarker} I 'm problem .
Turn 402, B (Professor): Yeah . I mean , just never mind what they are . Uh , it 's just if X and N are variables {disfmarker} Right ?
Turn 403, D (PhD): What is , uh {disfmarker} ?
Turn 404, B (Professor): The {disfmarker} the {disfmarker} the log of X plus N is not the same as the log of E to the X plus E to the N .
Turn 405, E (PhD): Yeah . But this i Well , I don't {disfmarker} Well , uh ,
Turn 406, B (Professor): Maybe we can take it off - line ,
Turn 407, E (PhD): maybe {disfmarker}
Turn 408, B (Professor): but I {disfmarker} I don't know .
Turn 409, E (PhD): I {disfmarker} I can do this incorrectly . Well , the expression that appear in the {disfmarker} in the paper , {nonvocalsound} is , uh {disfmarker}
Turn 410, D (PhD): The log {disfmarker} the Taylor series expansion for log one plus N by X is {disfmarker}
Turn 411, B (Professor): OK .
Turn 412, C (PhD): Is it the first - order expansion ?
Turn 413, E (PhD): is X {disfmarker}
Turn 414, B (Professor): I i
Turn 415, D (PhD): Yeah , the first one .
Turn 416, C (PhD): Yeah , I guess .
Turn 417, D (PhD): Yeah .
Turn 418, B (Professor): OK . Yeah . Cuz it doesn't just follow what 's there .
Turn 419, C (PhD): Yeah .
Turn 420, D (PhD): Yeah .
Turn 421, C (PhD): Uh - huh .
Turn 422, B (Professor): It has to be some , uh , Taylor series {disfmarker}
Turn 423, D (PhD): Y yeah . If {disfmarker} if you take log X into log one plus N by X , and then expand the log one plus N by X into Taylor series {disfmarker}
Turn 424, C (PhD): Yeah .
Turn 425, E (PhD): Now , this is the {disfmarker} and then {disfmarker}
Turn 426, C (PhD): Yeah , but the {disfmarker} the second {pause} expression that you put is the first - order expansion of the nonlinear relation between {disfmarker}
Turn 427, E (PhD): Not exactly .
Turn 428, B (Professor): No .
Turn 429, E (PhD): No , no , no . It 's not the first space . Well , we have {disfmarker} pfft , uh , em {disfmarker} Well , we can put that X is equal {disfmarker} I is equal to log of , uh , mmm {disfmarker}
Turn 430, B (Professor): That doesn't follow .
Turn 431, D (PhD): Mmm .
Turn 432, E (PhD): Well , we can put , uh , this ?
Turn 433, D (PhD): No .
Turn 434, B (Professor): That {disfmarker} I mean , that {disfmarker} the f top one does not {pause} imply the second one . Because {disfmarker} cuz the log of a sum is not the same as {pause} th
Turn 435, E (PhD): The top ?
Turn 436, B (Professor): I mean , as {disfmarker}
Turn 437, E (PhD): Yeah , yeah , yeah , yeah , yeah .
Turn 438, B (Professor): Yeah .
Turn 439, E (PhD): But we can {disfmarker} uh , we {disfmarker} we know that , for example , the log of {vocalsound} E plus B is equal to log of E plus log to B .
Turn 440, B (Professor): Right .
Turn 441, E (PhD): And we can say here , it i
Turn 442, B (Professor): Right . So you could s
Turn 443, C (PhD): What is that ?
Turn 444, E (PhD): And we can , uh , put this inside .
Turn 445, B (Professor): Yeah .
Turn 446, E (PhD): And then we can , uh ,
Turn 447, B (Professor): N no ,
Turn 448, E (PhD): you know {disfmarker}
Turn 449, B (Professor): but {disfmarker}
Turn 450, E (PhD): Yeah .
Turn 451, B (Professor): I don't see how you get the second expression from the top one .
Turn 452, D (PhD): Uh .
Turn 453, B (Professor): The {disfmarker} I mean , just more generally here , {vocalsound} if you say " log of , um , A plus B " , the log of {disfmarker} log of A plus B is not {disfmarker} or A plus B is not the , um , log of E to the A plus E to the B .
Turn 454, E (PhD): No , no , no , no , no , no , no . This not .
Turn 455, B (Professor): Right ? And that 's what you seem to be saying .
Turn 456, E (PhD): No . No . It 's not . But this is the same {disfmarker} oh .
Turn 457, B (Professor): Right ? Cuz you {disfmarker} cuz you {disfmarker} up here you have the A plus B {disfmarker}
Turn 458, E (PhD): No . I say if I apply log , I have , uh , log of E is equal to log of , uh {disfmarker} in this side , is equal to log of X
Turn 459, B (Professor): Plus N .
Turn 460, E (PhD): plus N .
Turn 461, B (Professor): Right .
Turn 462, E (PhD): No ?
Turn 463, B (Professor): Right .
Turn 464, E (PhD): Right .
Turn 465, B (Professor): And then how do you go from there to the {disfmarker} ?
Turn 466, E (PhD): This is right . And then if I apply exponential , to have here E {disfmarker}
Turn 467, B (Professor): Look . OK , so let 's {disfmarker} I mean , C equals A plus B ,
Turn 468, C (PhD): It 's log o of capital Y . Yeah , right .
Turn 469, B (Professor): and then {disfmarker}
Turn 470, C (PhD): Capital {pause} Y .
Turn 471, E (PhD): Yeah .
Turn 472, D (PhD): X . X . This is X , inside .
Turn 473, C (PhD): Mm - hmm .
Turn 474, B (Professor): Right .
Turn 475, E (PhD): We have this , no ?
Turn 476, B (Professor): Yeah . That one 's right .
Turn 477, E (PhD): Mm - hmm .
Turn 478, D (PhD): One and {disfmarker}
Turn 479, E (PhD): S uh , i th we can put here the set transformation .
Turn 480, B (Professor): Oh . I see .
Turn 481, E (PhD): No ?
Turn 482, B (Professor): I see . OK , I understand now . Alright , thanks .
Turn 483, E (PhD): Yeah . In this case , well , we can put here a {nonvocalsound} Y .
Turn 484, B (Professor): OK . So , yeah . It 's just by definition {pause} that the individual {disfmarker} {vocalsound} that the , uh {disfmarker} So , capital X is by definition the same as E to the little X because she 's saying that the little X is {disfmarker} is the , uh {disfmarker} is the log . Alright .
Turn 485, E (PhD): Now we can put this .
Turn 486, B (Professor): Yeah .
Turn 487, E (PhD): No ?
Turn 488, B (Professor): Alright .
Turn 489, E (PhD): And here we can multiply by X .
Turn 490, B (Professor): I think these things are a lot clearer when you can use fonts {disfmarker} different fonts there
Turn 491, E (PhD): Oh , yes .
Turn 492, B (Professor): so you know which is which . But I {disfmarker} I under I understand what you mean now .
Turn 493, E (PhD): Yeah , yeah . That 's true . That 's true .
Turn 494, B (Professor): OK .
Turn 495, E (PhD): But this {disfmarker} this is correct ?
Turn 496, B (Professor): Sure .
Turn 497, E (PhD): And now I can do it , uh {disfmarker} pfff ! I can put log {nonvocalsound} of EX {vocalsound} plus log {disfmarker}
Turn 498, B (Professor): Oh . Yes . I understand now . And that 's where it comes from .
Turn 499, E (PhD): And this is {disfmarker}
Turn 500, B (Professor): Yeah .
Turn 501, C (PhD): Yeah . Right .
Turn 502, B (Professor): Right .
Turn 503, E (PhD): Now it 's correct .
Turn 504, B (Professor): Right . OK . Thanks .
Turn 505, E (PhD): Well . The idea {disfmarker} Well , we have fixed this equa
Turn 506, B (Professor): OK . So now once you get that {disfmarker} that one , then you {disfmarker} then you do a first or second - order , or something , Taylor {vocalsound} series expansion of this .
Turn 507, E (PhD): Yeah . This is another linear relation that this {disfmarker} to develop this in {vocalsound} vector s Taylor series .
Turn 508, C (PhD): Yeah , sure .
Turn 509, B (Professor): Right .
Turn 510, E (PhD): Mm - hmm . And for that , well , the goal is to obtain , um {disfmarker} {vocalsound} {vocalsound} est estimate a PDF for the noisy speech when we have a {disfmarker} {vocalsound} a statistic for clean speech and for the noisy speech . Mmm ? And when w the way to obtain the PDF for the noisy speech is {disfmarker} well , we know this statistic and we know the noisy st well , we can apply first order of the vector st Taylor series of the {disfmarker} of the {disfmarker} of {disfmarker} well , the order that we want , increase the complexity of the problem .
Turn 511, B (Professor): Mm - hmm .
Turn 512, E (PhD): And then when we have a expression , uh , for the {vocalsound} mean and variance of the noisy speech , we apply a technique of minimum mean - square estimation
Turn 513, B (Professor): Mm - hmm .
Turn 514, E (PhD): to obtain the expected value of the clean speech given the {disfmarker} this {vocalsound} statistic for the noisy speech {disfmarker}
Turn 515, B (Professor): Mm - hmm .
Turn 516, E (PhD): the statistic for clean speech and the statistic of the noisy speech . This only that . But the idea is that {disfmarker}
Turn 517, C (PhD): And the {disfmarker} the model of clean speech is a codebook . Right ?
Turn 518, E (PhD): u Yeah . We have our codebook with different density {vocalsound} Gaussian .
Turn 519, B (Professor): Mm - hmm .
Turn 520, E (PhD): We can expre we can put that the {vocalsound} PDF {comment} for the clean test , probability of the clean speech is equal to {disfmarker}
Turn 521, B (Professor): Yeah .
Turn 522, E (PhD): 
Turn 523, C (PhD): Mm - hmm .
Turn 524, B (Professor): So , um , how {disfmarker} h how much {disfmarker} in {disfmarker} in the work they reported , how much noisy speech did you need to get , uh , good enough statistics for the {disfmarker} to get this mapping ?
Turn 525, E (PhD): I don't know exactly .
Turn 526, B (Professor): Yeah .
Turn 527, E (PhD): I {disfmarker} I need to s
Turn 528, B (Professor): Yeah .
Turn 529, E (PhD): I don't know exactly .
Turn 530, B (Professor): Cuz I think what 's certainly characteristic of a lot of the {pause} data in this test is that , um , you don't have {disfmarker} {vocalsound} the {disfmarker} the training set may not be a {disfmarker} a great estimator for the noise in the test set . Sometimes it is and sometimes it 's not .
Turn 531, E (PhD): Yeah . I {disfmarker} the clean speech {disfmarker} the codebook for clean speech , I am using TIMIT . And I have now , uh , sixty - four {nonvocalsound} Gaus - Gaussian .
Turn 532, B (Professor): Uh - huh . And what are you using for the noisy {disfmarker} ? Y y doing that strictly {disfmarker}
Turn 533, E (PhD): Of the noise {disfmarker} I estimate the noises wi
Turn 534, B (Professor): Mm - hmm .
Turn 535, E (PhD): Well , for the noises I only use one Gaussian .
Turn 536, B (Professor): And {disfmarker} and you {disfmarker} and you train it up entirely from , uh , nonspeech sections in the test ?
Turn 537, C (PhD): Hmm .
Turn 538, E (PhD): Uh , yes . The first experiment that I do it is solely to calculate the , mmm {disfmarker} well , this value {disfmarker}
Turn 539, B (Professor): Yeah .
Turn 540, E (PhD): uh , the compensation of the dictionary o one time using the {disfmarker} the noise at the f beginning of the sentence .
Turn 541, B (Professor): Mm - hmm .
Turn 542, E (PhD): This is the first experiment .
Turn 543, B (Professor): Yeah .
Turn 544, E (PhD): And I fix this for all the {disfmarker} all the sentences . Uh , because {disfmarker} well , the VTS methods {disfmarker} In fact the first thing that I do is to {disfmarker} to obtain , uh , an expression for E {disfmarker} probability e expression of {disfmarker} of E . That mean that the VTS {disfmarker} mmm , with the VTS we obtain , uh {disfmarker} well , we {disfmarker} we obtain the means for each Gaussian {comment} and the variance .
Turn 545, B (Professor): Mm - hmm .
Turn 546, E (PhD): This is one . Eh , this is the composition of the dictionary .
Turn 547, B (Professor): Mm - hmm .
Turn 548, E (PhD): This one thing . And the other thing that this {disfmarker} with these methods is to , uh , obtain {disfmarker} to calculate this value .
Turn 549, B (Professor): Mm - hmm .
Turn 550, E (PhD): Because we can write {disfmarker} uh , we can write that {vocalsound} the estimation of the clean speech is equal at an expected value of the clean speech conditional to , uh , the noise signal {disfmarker} {vocalsound} the probability f of the {disfmarker} the statistic of the clean speech and the statistic of the noise .
Turn 551, B (Professor): Mm - hmm . Mm - hmm .
Turn 552, E (PhD): This is the methods that say that we 're going obtain this .
Turn 553, B (Professor): Mm - hmm .
Turn 554, E (PhD): And we can put that this is equal to the estimated value of E minus a function that conditional to E to the T {disfmarker} to the noise signal . Well , this is {disfmarker} this function is the {vocalsound} the term {disfmarker} after develop this , the term that we {disfmarker} we take . Give PX and , uh , P the noise .
Turn 555, D (PhD): X K C noise .
Turn 556, B (Professor): Mmm .
Turn 557, E (PhD): And I can {vocalsound} put that this is equal to {pause} the {pause} noise signal minus {disfmarker} Well , I put before {pause} this name , uh {disfmarker} And I can calculate this .
Turn 558, B (Professor): What is the first variable in that probability ?
Turn 559, E (PhD): Uh , this is the Gaussian .
Turn 560, B (Professor): No , no . I 'm sorry . In {disfmarker} in the one you pointed at . What 's that variable ?
Turn 561, E (PhD): v Uh , this is the {disfmarker}
Turn 562, D (PhD): Weak . So probably it {disfmarker} it would do that .
Turn 563, E (PhD): like this ,
Turn 564, C (PhD): It 's one mixture of the model . Right ?
Turn 565, E (PhD): but conditional . No , it 's condition it 's not exactly this . It 's modify . Uh , if we have clean speech {disfmarker} we have the dictionary for the clean speech , we have a probability f of {disfmarker} our {disfmarker} our weight for each Gaussian .
Turn 566, B (Professor): OK .
Turn 567, E (PhD): No . And now , this weight is different now
Turn 568, B (Professor): Yes .
Turn 569, E (PhD): because it 's conditional . And this I need to {disfmarker} to calcu I know this
Turn 570, B (Professor): Uh - huh .
Turn 571, E (PhD): and I know this because this is from the dictionary that you have .
Turn 572, B (Professor): Uh - huh .
Turn 573, E (PhD): I need to calculate this .
Turn 574, B (Professor): Yes .
Turn 575, E (PhD): And for calculate this , {vocalsound} I have an {disfmarker} I {disfmarker} I can develop an expression that is
Turn 576, D (PhD): It 's overlapping .
Turn 577, E (PhD): that . I can calculate {disfmarker} I can {disfmarker} I calculated this value , {vocalsound} uh , with the statistic of the noisy speech that I calculated before with the VTS approximation .
Turn 578, B (Professor): Mm - hmm .
Turn 579, E (PhD): And {disfmarker} well , normalizing . And I know everything . Uh , with the , nnn {disfmarker} when I develop this in s Taylor {disfmarker} Taylor series , I can't , um , {vocalsound} calculate the mean and the variance {vocalsound} of the {disfmarker} for each of the Gaussian of the dictionary for the noisy speech . Now . And this is fixed .
Turn 580, B (Professor): Mm - hmm .
Turn 581, E (PhD): If I never do an estimat a newer estimation of the noise , this mean as {disfmarker} mean and the variance are fixed .
Turn 582, B (Professor): Mm - hmm .
Turn 583, E (PhD): And for each s uh , frame of the speech the only thing that I need to do is to calculate this in order to calculate the estimation of the clean speech given our noisy speech .
Turn 584, B (Professor): So , I 'm {disfmarker} I 'm not following this perfectly but , um , I {disfmarker} Are you saying that all of these estimates are done {pause} using , um , estimates of the probability density for the noise that are calculated only from the first ten frames ? And never change throughout anything else ?
Turn 585, E (PhD): Yeah . Never cha This is one of the approximations that I am doing .
Turn 586, B (Professor): Per {disfmarker} per {disfmarker} per utterance , or per {disfmarker} ?
Turn 587, E (PhD): Per utterance . Yes .
Turn 588, B (Professor): Per utterance . OK .
Turn 589, E (PhD): Per utterance . Yes .
Turn 590, B (Professor): So it 's done {disfmarker} it 's done new for each new utterance .
Turn 591, E (PhD): And th
Turn 592, B (Professor): So this changes the whole mapping for every utterance .
Turn 593, E (PhD): Yeah . It 's not {disfmarker} Yeah .
Turn 594, B (Professor): OK .
Turn 595, E (PhD): Yeah . It 's fixed , the dictionary .
Turn 596, B (Professor): OK .
Turn 597, E (PhD): And the other estimation is when I do the uh on - line estimation , I change the means and variance of th for the noisy speech
Turn 598, B (Professor): Yeah ?
Turn 599, E (PhD): each time that I detect noise .
Turn 600, B (Professor): Mm - hmm .
Turn 601, E (PhD): I do it uh again this develop . Estimate the new mean and the variance of the noisy speech . And with th with this new s new mean and variance I estimate again this .
Turn 602, B (Professor): So you estimated , uh , f completely forgetting what you had before ? Uh , or is there some adaptation ?
Turn 603, E (PhD): Um , no , no , no . It 's not completely {disfmarker} No , it 's {disfmarker} I am doing something like an adaptation of the noise .
Turn 604, B (Professor): OK . Now do we know , either from their experience or from yours , that , uh , just having , uh , two parameters , the {disfmarker} the mean and variance , is enough ? Yeah . I mean , I know you don't have a lot of data to estimate with , but {disfmarker} but , uh , um {disfmarker}
Turn 605, E (PhD): I estimate mean and variance for each one of the Gaussian of the codebook .
Turn 606, B (Professor): No , I 'm talking about the noise .
Turn 607, E (PhD): Oh ,
Turn 608, B (Professor): There 's only one Gaussian .
Turn 609, E (PhD): um . Well , only one {disfmarker} I am only {disfmarker} using only one .
Turn 610, B (Professor): Right .
Turn 611, E (PhD): I don't know i
Turn 612, B (Professor): And you {disfmarker} and {disfmarker} and it 's , uh , uh {disfmarker} right , it 's only {disfmarker} it 's only one {disfmarker} Wait a minute . This is {disfmarker} what 's the dimensionality of the Gaussian ? This is {disfmarker}
Turn 613, E (PhD): Uh , it 's in {disfmarker} after the mel filter bank .
Turn 614, B (Professor): So this is twenty or something ?
Turn 615, E (PhD): Twenty - three .
Turn 616, B (Professor): Twenty ? So it 's {disfmarker} Yeah . So it 's actually forty numbers {pause} that you 're getting . Yeah , maybe {disfmarker} maybe you don't have a {disfmarker}
Turn 617, E (PhD): Uh , the original paper say that only one Gaussian for the noise .
Turn 618, B (Professor): Well , yeah . But , I mean , {vocalsound} no {disfmarker} no paper is {disfmarker} is a Bible ,
Turn 619, E (PhD): Yeah , maybe isn't the right thing .
Turn 620, B (Professor): you know . This is {disfmarker} this is , uh {disfmarker}
Turn 621, E (PhD): Yeah , yeah , yeah .
Turn 622, B (Professor): The question is , um , {vocalsound} whether it would be helpful , i particularly if you used {disfmarker} if you had more {disfmarker} So , suppose you did {disfmarker} This is almost cheating . It certainly isn't real - time . But if y suppose you use the real boundaries that {disfmarker} that you were {disfmarker} in fact were given {vocalsound} by the VAD and so forth or I {disfmarker} I guess we 're gonna be given even better boundaries than that . And you look {disfmarker} you take all o all of the nonspeech components in an utterance , so you have a fair amount . Do you benefit from having a better model for the noise ? That would be another question .
Turn 623, E (PhD): Maybe .
Turn 624, B (Professor): So first question would be {vocalsound} to what extent i are the errors that you 're still seeing {vocalsound} based on the fact that you have poor boundaries for the , uh , uh , nonspeech ? And the second question might be , given that you have good boundaries , could you do better if you used more parameters to characterize the noise ? Um . Also another question might be {disfmarker} Um , they are doing {disfmarker} they 're using first term only of the vector Taylor series ?
Turn 625, E (PhD): Yeah .
Turn 626, B (Professor): Um , if you do a second term does it get too complicated cuz of the nonlinearity ?
Turn 627, E (PhD): Yeah . It 's quite complicated .
Turn 628, B (Professor): Yeah , OK . No , I won't ask the next question then .
Turn 629, E (PhD): Oh , it 's {disfmarker} it 's the {disfmarker} for me it 's the first time that I am working with VTS .
Turn 630, B (Professor): Yeah . No , it 's interesting .
Turn 631, E (PhD): Uh {disfmarker}
Turn 632, B (Professor): Uh , w we haven't had anybody work with it before , so it 's interesting to get your {disfmarker} get your feedback about it .
Turn 633, E (PhD): It 's another type of approximation because i because it 's a statistic {disfmarker} statistic approximation to remove the noise . I don't know .
Turn 634, B (Professor): Right .
Turn 635, F (PhD): Great . OK . Well , I guess we 're about done . Um , so some of the digit forms don't have digits . Uh , {vocalsound} we ran out there were some blanks in there , so not everybody will be reading digits . But , um , I guess you 've got some . Right , Morgan ?
Turn 636, B (Professor): I have some .
Turn 637, F (PhD): So , why don't you go ahead and start . And I think it 's {pause} just us down here at this end that have them .
Turn 638, D (PhD): S
Turn 639, E (PhD): um
Turn 640, F (PhD): So .
Turn 641, B (Professor): Uh , OK .
Turn 642, D (PhD): S so , we switch off with this
Turn 643, F (PhD): Whenever you 're ready .
Turn 644, D (PhD): or n ?
Turn 645, F (PhD): Uh , leave it on ,
Turn 646, D (PhD): No . OK .
Turn 647, F (PhD): uh ,
Turn 648, B (Professor): They prefer to have them on
Turn 649, F (PhD): and the {disfmarker}
Turn 650, B (Professor): just so that they 're continuing to get the distant , uh , information .
Turn 651, F (PhD): Yeah .
Turn 652, D (PhD): OK . OK .
Turn 653, F (PhD): OK .
Turn 654, B (Professor): OK . S
