Turn 0, E (PhD): OK .
Turn 1, B (Professor): OK , so {pause} We {disfmarker} we had a meeting with , uh {disfmarker} with Hynek , um , in {disfmarker} in which , uh , uh , Sunil and Stephane , uh {vocalsound} summarized where they were and {disfmarker} and , uh , talked about where we were gonna go . So that {disfmarker} that happened sort of mid - week . Uh .
Turn 2, E (PhD): D did {disfmarker} did you guys get your code pushed together ?
Turn 3, D (PhD): Oh , yeah . Yeah . It 's {disfmarker} it 's {disfmarker} it 's {disfmarker} it was updated yesterday ,
Turn 4, E (PhD): Cool .
Turn 5, D (PhD): right ?
Turn 6, A (PhD): Yeah .
Turn 7, D (PhD): Yeah .
Turn 8, A (PhD): You probably received the mail .
Turn 9, E (PhD): Oh , right , I saw {disfmarker} I saw the note .
Turn 10, A (PhD): Yeah .
Turn 11, E (PhD): Mm - hmm .
Turn 12, B (Professor): What was the update ?
Turn 13, A (PhD): What was the update ? So there is th then {disfmarker} the {disfmarker} all the new features that go in .
Turn 14, B (Professor): Yeah .
Turn 15, A (PhD): The , um , noise suppression , the re - synthesis of speech after suppression . These are the {disfmarker}
Turn 16, E (PhD): Is the , um {disfmarker} the CVS mechanism working {pause} well ?
Turn 17, A (PhD): Yeah .
Turn 18, E (PhD): Are {disfmarker} are people , uh , up at OGI grabbing code uh , via that ?
Turn 19, D (PhD): Uh , I don't think {disfmarker} I don't think {disfmarker}
Turn 20, E (PhD): Or {disfmarker} ?
Turn 21, A (PhD): I don't know if they use it , but .
Turn 22, D (PhD): Yeah , I I don't think anybody up there is like {pause} working on it right now .
Turn 23, E (PhD): Uh - huh . Mmm .
Turn 24, B (Professor): I think it more likely that what it means is that when Sunil is up there {vocalsound} he will grab it .
Turn 25, D (PhD): Yeah . Yeah . So right now nobody 's working on Aurora there .
Turn 26, E (PhD): Yeah .
Turn 27, B (Professor): They 're {disfmarker} Yeah . They 're working on a different task .
Turn 28, E (PhD): I see . I see .
Turn 29, D (PhD): Yeah .
Turn 30, E (PhD): OK .
Turn 31, B (Professor): But what 'll happen is {disfmarker} is he 'll go back up there and , uh , Pratibha will come back from {disfmarker} from , uh , the east coast . Uh .
Turn 32, E (PhD): Mm - hmm .
Turn 33, B (Professor): And , uh {disfmarker} and {disfmarker} and I guess actually , uh , after Eurospeech for a little bit , uh , he 'll go up there too . So , actually everybody {vocalsound} who 's working on it {comment} will be up there for at least a little while . So they 'll remotely access it {vocalsound} from there .
Turn 34, E (PhD): So has {disfmarker} Has anybody tried remotely accessing the CVS using , uh , uh , SSH ?
Turn 35, B (Professor): Yeah . 
Turn 36, A (PhD): Um , I don't know if Hari did that or {disfmarker} You d
Turn 37, D (PhD): I {comment} can actually do it today . I mean , I can just log into {disfmarker}
Turn 38, E (PhD): Have you tried it yet ?
Turn 39, D (PhD): No , I didn't . So I I 'll try it today .
Turn 40, E (PhD): OK .
Turn 41, B (Professor): Good idea .
Turn 42, A (PhD): Actually I {disfmarker} I tried wh while {disfmarker} when I installed the {pause} repository , I tried from Belgium .
Turn 43, B (Professor): Yeah .
Turn 44, D (PhD): Yeah .
Turn 45, A (PhD): I logged in there and I tried {pause} to import {disfmarker}
Turn 46, E (PhD): Yeah ? It worked good ?
Turn 47, A (PhD): Yeah , it works .
Turn 48, E (PhD): Oh , good !
Turn 49, A (PhD): But it 's {disfmarker} So , right now it 's the mechanism with SSH .
Turn 50, D (PhD): Oh .
Turn 51, E (PhD): Great !
Turn 52, A (PhD): I don't {pause} s I didn't set up {disfmarker} You can also set up a CVS server {pause} on a new port . It 's like well {pause} uh , a main server , or d You can do a CVS server .
Turn 53, E (PhD): Yeah . Right . Then that 's using the CVS password mechanism and all that ,
Turn 54, A (PhD): But . Yeah , right .
Turn 55, E (PhD): right ?
Turn 56, A (PhD): But I didn't do that because I was not sure about {pause} security problems . I {disfmarker} I would have to {disfmarker}
Turn 57, E (PhD): So w when you came in from Belgian {disfmarker} {comment} Belgium , using SSH , uh , was it asking you for your own {pause} password into ICSI ? So if yo you can only do that if you have an account at ICSI ?
Turn 58, A (PhD): Right . Yeah .
Turn 59, E (PhD): OK .
Turn 60, A (PhD): Yeah .
Turn 61, E (PhD): Cuz there is an {disfmarker} a way to set up anonymous CVS right ?
Turn 62, A (PhD): Yeah , you ha in this way you ca you have to set up a CVS server but then , yeah , you can access it .
Turn 63, E (PhD): So that {disfmarker} Oh , OK .
Turn 64, A (PhD): you {disfmarker} you can set up priorities .
Turn 65, E (PhD): So the anonymous mechanism {disfmarker}
Turn 66, A (PhD): You can access them and mostly if you {disfmarker} if y the set the server is set up like this .
Turn 67, E (PhD): OK . Because a lot of the open source stuff works with anonymous CVS and I 'm just wondering {disfmarker} Uh , I mean , for our transcripts we may want to do that .
Turn 68, A (PhD): Mm - hmm .
Turn 69, B (Professor): Yeah .
Turn 70, E (PhD): Uh .
Turn 71, B (Professor): Yeah , for this stuff I don't think we 're {pause} quite up to that . I mean , we 're still so much in development .
Turn 72, E (PhD): Mm - hmm . Yeah ,
Turn 73, B (Professor): We want to have just the insiders .
Turn 74, E (PhD): yeah , yeah . Oh , I wasn't suggesting for this . I 'm {pause} thinking of the Meeting Recorder {comment} stuff
Turn 75, B (Professor): Yeah .
Turn 76, E (PhD): but . Yeah . OK . Cool .
Turn 77, B (Professor): Yeah . So , uh {disfmarker}
Turn 78, E (PhD): What 's new ?
Turn 79, B (Professor): Well , I mean , I think maybe the thing to me might be {disfmarker} I me I 'm sure you 've just been working on {disfmarker} on , uh , details of that since the meeting , right ? And so {disfmarker}
Turn 80, A (PhD): Mmm , since the meeting , well , I {disfmarker} I 've been {disfmarker} I 've been train training a new VAD and a new {pause} feature net .
Turn 81, B (Professor): That was {disfmarker} that was Tuesday . OK .
Turn 82, A (PhD): So they should be ready . Um .
Turn 83, B (Professor): But I guess maybe the thing {disfmarker} since you weren't {disfmarker} yo you guys weren't at that {disfmarker} that meeting , might be just {disfmarker} just to , um , sort of recap , uh , the {disfmarker} the conclusions of the meeting .
Turn 84, A (PhD): Mm - hmm .
Turn 85, E (PhD): Oh , great .
Turn 86, B (Professor): So .
Turn 87, E (PhD): You 're talking about the meeting with Hynek ?
Turn 88, B (Professor): Yeah . Cuz that was sort of , uh {disfmarker} we {disfmarker} we 'd sort of been working up to that , that {disfmarker} that , uh , he would come here this week and {disfmarker} and we would sort of {disfmarker}
Turn 89, E (PhD): Uh - huh .
Turn 90, B (Professor): Since he 's going out of town like now , and I 'm going out town in a couple weeks , uh , and time is marching , sort of , given all the mu many wonderful things we could be working on , what {disfmarker} what will we actually focus on ?
Turn 91, E (PhD): Mm - hmm .
Turn 92, B (Professor): And , uh {disfmarker} and what do we freeze ? And , you know , what do we {disfmarker} ? So , um . I mean , this {pause} software that these guys created was certainly a {disfmarker} a key part . So then there 's something central and there aren't at least a bunch of different versions going off in {disfmarker} in ways that {pause} differ {pause} trivially . Uh , um , and , um ,
Turn 93, E (PhD): Yeah . That 's {disfmarker} that 's nice .
Turn 94, B (Professor): and then within that , I guess the idea was to freeze a certain set of options for now , to run it , uh , a particular way , and decide on what things are gonna be experimented with , as opposed to just experimenting with everything . So keep a certain set of things constant . So , um . Uh , maybe describe roughly what {disfmarker} what we are keeping constant for now , or {disfmarker} ?
Turn 95, A (PhD): Yeah . Well . So we 've been working like six weeks on {disfmarker} on the noise compensation and we end up with something that seems reasonable . Um .
Turn 96, E (PhD): Are you gonna use {disfmarker} which of the two techniques ?
Turn 97, A (PhD): So finally it 's {disfmarker} it 's , um , Wiener filtering on FFT bins . And it uses , uh , two steps , smoothing of the transfer function , the first step , that 's along time , which use recursion . And {vocalsound} after this step there is a further smoothing along frequency , which use a sliding window of twenty FFT bins . Mmm . And , uh {disfmarker}
Turn 98, E (PhD): So this is on the {disfmarker} uh , before any mel scaling has been done ?
Turn 99, A (PhD): Yeah , yeah .
Turn 100, E (PhD): This is {disfmarker}
Turn 101, A (PhD): It was {disfmarker}
Turn 102, B (Professor): This {disfmarker} this smoothing is done on the estimate , um , of what you 're going to subtract ? Or on the thing that has already had something subtracted ?
Turn 103, A (PhD): Yeah . Uh , {vocalsound} it 's on the transfer function . So {disfmarker}
Turn 104, B (Professor): Oh , it 's on the transfer function for the Wiener filter .
Turn 105, A (PhD): Yeah .
Turn 106, B (Professor): Yeah , OK .
Turn 107, A (PhD): Yeah , so basically we tried {vocalsound} different configuration within this idea . We tried u u applying this on mel bands , having spectral subtraction instead of wiener filtering . Um . Well , finally we end up with {pause} this configuration that works , uh , quite well . So we are going to fix this for the moment and work on the other aspects of {vocalsound} the whole system .
Turn 108, E (PhD): Mm - hmm .
Turn 109, A (PhD): So {disfmarker}
Turn 110, B (Professor): Actually , let me int eh , Dave isn't here to talk about it , but let me just interject . This module , in principle , i I mean , you would know whether it 's {vocalsound} true in fact , is somewhat independent from the rest of it . I mean , because you {disfmarker} you re - synthesize speech , right ?
Turn 111, A (PhD): Mm - hmm .
Turn 112, B (Professor): So , um . Uh , well you don't {disfmarker} I guess you don't re - synthesize speech , but you could {disfmarker}
Turn 113, A (PhD): We {disfmarker} we do not fo
Turn 114, B (Professor): Uh , but you could .
Turn 115, A (PhD): Well {disfmarker} well , we do , but we don't {disfmarker} don't re - synthesize . In {disfmarker} in the program we don't re - synthesize and then re - analyze once again . We just use the clean FFT bins .
Turn 116, B (Professor): But you have a re - synthesized thing that you {disfmarker} that 's an {disfmarker} an option here .
Turn 117, A (PhD): This is an option that {disfmarker} then you can {disfmarker} Yeah .
Turn 118, B (Professor): Yeah , I gu I guess my point is that , um , i in some of the work he 's doing in reverberation , one of the things that we 're finding is that , uh , it 's {disfmarker} it 's {disfmarker} for the {disfmarker} for an artificial situation , we can just deal with the reverberation and his techniques work really well . But for the real situation uh , problem is , is that you don't just have reverberation , you have reverberation in noise . And if you don't include that in the model , it doesn't work very well . So in fact it might be a very nice thing to do , to just take the noise removal part of it and put that in front of what he 's looking at . And , uh , generate new files or whatever , and {disfmarker} and , uh , uh {disfmarker} and then do the reverberation part .
Turn 119, A (PhD): Mm - hmm .
Turn 120, B (Professor): So it 's {disfmarker}
Turn 121, D (PhD): Mmm .
Turn 122, B (Professor): Anyway .
Turn 123, E (PhD): So Dave hasn't {pause} tried that yet ?
Turn 124, B (Professor): No , no . He 's {disfmarker} I mean , e
Turn 125, E (PhD): I guess he 's busy with {disfmarker}
Turn 126, B (Professor): Yeah , prelims , right .
Turn 127, C (Grad): Pre - prelim hell .
Turn 128, B (Professor): Yeah .
Turn 129, E (PhD): Yeah .
Turn 130, B (Professor): So .
Turn 131, E (PhD): Yeah .
Turn 132, B (Professor): Uh , but {disfmarker} but , you know , that 'll {disfmarker} uh , it 's clear that we , uh {disfmarker} we are not {disfmarker} with the real case that we 're looking at , we can't just look at reverberation in isolation because the interaction between that and noise is {disfmarker} is considerable . And that 's I mean , in the past we 've looked at , uh , and this is hard enough , the interaction between channel effects and {disfmarker} and , uh {disfmarker} and additive noise , uh , so convolutional effects and {disfmarker} and additive effects . And that 's hard enough . I mean , I don't think we really {disfmarker} I mean , we 're trying to deal with that . In a sense that 's what we 're trying to deal with in this Aurora task . And we have , uh , the , uh , uh , LDA stuff that in principle is doing something about convolutional effects . And we have the noise suppression that 's doing something about noise . Uh , even that 's hard enough . And {disfmarker} and the on - line normalization as well , in that s category . i i There 's all these interactions between these two and that 's part of why these guys had to work so hard on {disfmarker} on juggling everything around . But now when you throw in the reverberation , it 's even worse , because not only do you have these effects , but you also have some long time effects . And , um , so Dave has something which , uh , is doing some nice things under some conditions with {disfmarker} with long time effects but when it 's {disfmarker} when there 's noise there too , it 's {disfmarker} it 's {disfmarker} it 's pretty hard . So we have to start {disfmarker} Since any {disfmarker} almost any real situation is gonna have {disfmarker} uh , where you have the microphone distant , is going to have both things , we {disfmarker} we actually have to think about both at the same time .
Turn 133, E (PhD): Hmm .
Turn 134, B (Professor): So , um {disfmarker} So there 's this noise suppression thing , which is sort of worked out and then , uh , maybe you should just continue telling what {disfmarker} what else is in the {disfmarker} the form we have .
Turn 135, A (PhD): Yeah , well , {vocalsound} the , um , the other parts of the system are the {disfmarker} the blocks that were already present before and that we did not modify a lot .
Turn 136, B (Professor): So that 's {disfmarker} again , that {disfmarker} that 's the Wiener filtering , followed by , uh {disfmarker} uh , that 's done at the FFT level . Then {disfmarker}
Turn 137, A (PhD): Yeah , th then the mel filter bank ,
Turn 138, B (Professor): Mm - hmm .
Turn 139, A (PhD): then the log operation ,
Turn 140, B (Professor): Mm - hmm .
Turn 141, A (PhD): Mmm .
Turn 142, B (Professor): The {disfmarker} the {disfmarker} the filtering is done in the frequency domain ?
Turn 143, A (PhD): Yeah .
Turn 144, B (Professor): Yeah , OK . And then the mel and then the log , and then the
Turn 145, A (PhD): Then the LDA filter ,
Turn 146, B (Professor): LDA filter .
Turn 147, A (PhD): mmm , then the downsampling ,
Turn 148, B (Professor): And then uh downsample ,
Turn 149, A (PhD): DCT ,
Turn 150, B (Professor): DCT ,
Turn 151, A (PhD): then , um , on - line normalization ,
Turn 152, B (Professor): on - line norm ,
Turn 153, A (PhD): followed by {pause} upsampling . Then finally , we compute delta and we put the neural network also .
Turn 154, B (Professor): Right , and then in parallel with {disfmarker} an {disfmarker} a neural net . And then following neural net , some {disfmarker} probably some orthogonalization .
Turn 155, A (PhD): Yeah .
Turn 156, B (Professor): Uh {disfmarker} Um .
Turn 157, A (PhD): And finally frame dropping , which um , {vocalsound} would be a neural network also , used for estimated silence probabilities . And the input of this neural network would be somewhere between log {pause} mel bands or one of the earlier stages of the processing .
Turn 158, B (Professor): Mm - hmm . So that 's sort of {disfmarker} most of this stuff is {disfmarker} yeah , is operating parallel with this other stuff .
Turn 159, A (PhD): Mm - hmm .
Turn 160, B (Professor): Yeah . So the things that we , um , uh , I guess we sort of {disfmarker} uh , There 's {disfmarker} there 's some , uh , neat ideas for {vocalsound} V A So , I mean , in {disfmarker} I think there 's sort of like {disfmarker} There 's a bunch of tuning things to improve stuff . There 's questions about {pause} various places where there 's an exponent , if it 's the right exponent , or {pause} ways that we 're estimating noise , that we can improve estimating noise . And there 's gonna be a host of those . But structurally it seemed like the things {disfmarker} the main things that {disfmarker} that we brought up that , uh , are {disfmarker} are gonna need to get worked on seriously are , uh , uh , a {disfmarker} {vocalsound} a significantly better VAD , uh , putting the neural net on , um , which , you know , we haven't been doing anything with , the , uh , neural net at the end there , and , uh , the , uh , {vocalsound} opening up the second front . Uh .
Turn 161, E (PhD): The other half of the channel ?
Turn 162, B (Professor): Yeah , yeah , I mean , cuz we {disfmarker} we have {disfmarker} we have , uh , uh , half the {disfmarker} the , uh , data rate that they allow .
Turn 163, E (PhD): That what you mean ?
Turn 164, B (Professor): And , uh , so the initial thing which came from , uh , the meeting that we had down south was , uh , that , um , we 'll initially just put in a mel spectrum as the second one . It 's , you know , {pause} cheap , easy . Uh . There 's a question about exactly how we do it . We probably will go to something better later , but the initial thing is that cepstra and spectra behave differently ,
Turn 165, E (PhD): Mm - hmm .
Turn 166, B (Professor): so . Um , {comment} I think Tony Robinson used to do {disfmarker} I was saying this before . I think he used to do mel , uh , spectra and mel cepstra . He used them as alternate features . Put them together .
Turn 167, E (PhD): Hmm .
Turn 168, B (Professor): Uh .
Turn 169, E (PhD): So if you took the system the way it is now , the way it 's fro you 're gonna freeze it , and it ran it on the last evaluation , where it would it be ?
Turn 170, A (PhD): Mm - hmm . It , uh ,
Turn 171, E (PhD): In terms of ranking ?
Turn 172, A (PhD): Ri - right now it 's second .
Turn 173, D (PhD): Second . 
Turn 174, A (PhD): Um .
Turn 175, E (PhD): Mm - hmm .
Turn 176, B (Professor): Although you {disfmarker} you know , you haven't tested it actually on the German and Danish , have you ?
Turn 177, A (PhD): No , we didn't . No , um .
Turn 178, B (Professor): Yeah .
Turn 179, E (PhD): So on the ones that you did test it on it would have been second ?
Turn 180, B (Professor): Yeah . Would it {disfmarker} I mean {disfmarker} But {disfmarker} When you 're saying second , you 're comparing to the numbers that the , uh {disfmarker} that the best system before got on , uh {disfmarker} also without German and Danish ?
Turn 181, A (PhD): Yeah , yeah .
Turn 182, B (Professor): Yeah , OK .
Turn 183, D (PhD): And th the ranking actually didn't change after the German and Danish . So , yeah .
Turn 184, B (Professor): Well ranking didn't before , but I 'm just asking where this is to where theirs was without the German and Danish ,
Turn 185, A (PhD): Yeah .
Turn 186, D (PhD): Yeah .
Turn 187, A (PhD): Mmm .
Turn 188, D (PhD): Yeah .
Turn 189, B (Professor): right ?
Turn 190, D (PhD): Yeah , yeah .
Turn 191, B (Professor): So .
Turn 192, E (PhD): Where {disfmarker} where {disfmarker} where were we actually on the last test ?
Turn 193, B (Professor): Oh , we were also esp essentially second , although there were {disfmarker} there were {disfmarker} I mean , we had a couple systems and they had a couple systems . And so , I guess by that {pause} we were third , but I mean , there were two systems that were pretty close , that came from the same place .
Turn 194, E (PhD): Uh - huh . I see . OK .
Turn 195, B (Professor): Uh , so institutionally we were {disfmarker} {vocalsound} we were second , with , uh , the third {disfmarker} third system .
Turn 196, E (PhD): We 're {disfmarker} so this second that you 're saying now is system - wide second ?
Turn 197, B (Professor): See {disfmarker} Uh , no I think it 's also institutional , isn't it ?
Turn 198, E (PhD): Still institutionally second ?
Turn 199, B (Professor): Right ? I mean , I think both of their systems probably {disfmarker}
Turn 200, A (PhD): Uh , we are between their two systems . So
Turn 201, B (Professor): Oh , are we ?
Turn 202, A (PhD): I {disfmarker} It is a triumph .
Turn 203, D (PhD): Yeah .
Turn 204, B (Professor): Is it ?
Turn 205, D (PhD): Their {disfmarker} their first system is fifty - four point something . And , uh , we are fifty - three point something .
Turn 206, A (PhD): But everything is {pause} within the range of one {disfmarker} one percent .
Turn 207, D (PhD): And their second system is also fifty - three point something . Yeah , one percent .
Turn 208, B (Professor): Yeah , so {disfmarker} so basically they 're all {disfmarker} they 're all pretty close .
Turn 209, E (PhD): Oh , wow !
Turn 210, A (PhD): So .
Turn 211, E (PhD): That 's very close .
Turn 212, D (PhD): Yeah .
Turn 213, E (PhD): Yeah .
Turn 214, B (Professor): And {disfmarker} and , {vocalsound} um , you know , in some sense we 're all doing fairly similar things . Uh , I mean , one could argue about the LDA and so forth but I {disfmarker} I think , you know , in a lot of ways we 're doing very similar things . But what {disfmarker} what {disfmarker}
Turn 215, E (PhD): So how did they fill up this {disfmarker} all these {disfmarker} these bits ? I mean , if we 're u
Turn 216, B (Professor): Um , why are we using half ? Well , so you could {disfmarker} you c
Turn 217, E (PhD): Yeah . Or how are they using more than half , I guess maybe is what I {disfmarker}
Turn 218, B (Professor): Yeah , so I {disfmarker} I think {disfmarker} uh , you guys are closer to it than me , so correct me if I 'm wrong , but I {disfmarker} I think that what 's going on is that in {disfmarker} in both cases , some kind of normalization is done to deal with convola convolutional effects . Uh , they have some cepstral {pause} modification ,
Turn 219, A (PhD): Mm - hmm .
Turn 220, B (Professor): right ? In our case we have a couple things . We have the on - line normalization and then we have the LDA RASTA . And {pause} they seem to comple complement each other enough and be different enough that they both seem to help {disfmarker} help us . But in any event , they 're both doing the same sort of thing . But there 's one difference . The LDA RASTA , uh , throws away high modulation frequencies . And they 're not doing that .
Turn 221, E (PhD): So th So {disfmarker}
Turn 222, B (Professor): So that if you throw away high modulation frequencies , then you can downsample .
Turn 223, C (Grad): Get down .
Turn 224, E (PhD): I see . I see .
Turn 225, B (Professor): So {disfmarker}
Turn 226, E (PhD): So what if you didn't {disfmarker} So do you explicitly downsample then ? Do we explicitly downsample ?
Turn 227, B (Professor): Yeah .
Turn 228, A (PhD): Yeah .
Turn 229, E (PhD): And what if we didn't do that ? Would we get worse performance ?
Turn 230, A (PhD): Um {pause} Yeah , not better , not worse .
Turn 231, B (Professor): I think it doesn't affect it , does it ?
Turn 232, E (PhD): I see . OK .
Turn 233, B (Professor): Yeah . So I think the thing is , since we 're not evidently throwing away useful information , let 's try to put in some useful information .
Turn 234, E (PhD): Yeah . Yeah .
Turn 235, B (Professor): And , uh , so I {disfmarker} you know , we {disfmarker} we 've found in a lot of ways for quite a while that having a second stream uh , helps a lot . So that 's {disfmarker} that 's put in , and you know , it may even end up with mel spectrum even though I 'm saying I think we could do much better , just because it 's simple .
Turn 236, E (PhD): Mm - hmm .
Turn 237, B (Professor): Um . And you know , in the long run having something everybody will look at and say , " oh , yeah , I understand " , is {disfmarker} is very helpful .
Turn 238, E (PhD): So you would {disfmarker} you 're {disfmarker} You 're thinking to put the , uh , mel spectrum in before any of the noise removal stuff ? or after ?
Turn 239, B (Professor): Well , that 's a question . I mean , we were talking about that . It looks like it 'd be straightforward to {disfmarker} to , uh , remove the noise , um , and , uh ,
Turn 240, E (PhD): Cuz that happens before the mel conversion , right ?
Turn 241, B (Professor): Yeah . So , I mean , to do it after the mel conversion {disfmarker} uh , after the noise removal , after the mel conversion . There 's even a question in my mind anyhow of whether th you should take the log or not . Uh . I sort of think you should , but I don't know .
Turn 242, A (PhD): What about norm normalizing also ?
Turn 243, B (Professor): Right . Uh . Well , but normalizing spectra instead of cepstra ?
Turn 244, A (PhD): Yeah .
Turn 245, B (Professor): Yeah , probably . Some kind would be good . You know ? I would think .
Turn 246, D (PhD): Well , it {disfmarker} it {disfmarker} it {disfmarker} it {disfmarker} so it actually makes it dependent on the overall energy of the {disfmarker} uh , the frame .
Turn 247, B (Professor): If you do or don't normalize ?
Turn 248, D (PhD): If yo if you don't normalize and {disfmarker} if {disfmarker} if you don't normalize .
Turn 249, B (Professor): Right . Yes , so I mean , one would think that you would want to normalize . But I {disfmarker} I {disfmarker} w w My thought is , uh , particularly if you take the log , try it . And then if {disfmarker} if normalization helps , then y you have something to compare against , and say , " OK , this much effect " {disfmarker} I mean , you don't want to change six things and then see what happens . You want to change them one at a time .
Turn 250, D (PhD): Mm - hmm .
Turn 251, B (Professor): So adding this other stream in , that 's simple in some way . And then {pause} saying , oh {disfmarker} uh {disfmarker} particularly because we 've found in the past there 's all these {disfmarker} these {disfmarker} these different results you get with slight modifications of how you do normalization . Normalization 's a very tricky , sensitive thing and {pause} you learn a lot . So , I would think you would wanna {pause} have some baseline that says , " OK , we don't normalize , this is what we get " , when we do this normalization , when we do that normalization . But {disfmarker} but the other question is {disfmarker} So I think ultimately we 'll wind up doing some normalization . I agree .
Turn 252, E (PhD): So this second stream , will it add latency to the system
Turn 253, B (Professor): No , it 's in parallel .
Turn 254, E (PhD): or {disfmarker} ?
Turn 255, C (Grad): Para
Turn 256, B (Professor): We 're not talking about computation time here .
Turn 257, E (PhD): S
Turn 258, B (Professor): We 're ta I think we 're pretty far out .
Turn 259, E (PhD): Yeah .
Turn 260, B (Professor): So it 's just in terms of what data it 's depending on . It 's depending on the same data as the other .
Turn 261, E (PhD): Same data .
Turn 262, B (Professor): So it 's in parallel .
Turn 263, E (PhD): OK .
Turn 264, B (Professor): Uh - huh .
Turn 265, C (Grad): So with this , uh , new stream would you train up a VAD on both {disfmarker} both features , somehow ?
Turn 266, D (PhD): No , I guess the VAD has its own set of features .
Turn 267, C (Grad): OK . that 's {disfmarker}
Turn 268, D (PhD): I mean , which could be this {disfmarker} one of these streams , or it can be something derived from {pause} these streams .
Turn 269, B (Professor): Yeah .
Turn 270, C (Grad): OK .
Turn 271, A (PhD): And there is also the idea of using TRAPS , maybe , for the VAD , which , um {disfmarker}
Turn 272, D (PhD): Yeah , that 's also {disfmarker}
Turn 273, A (PhD): Well , Pratibha apparently showed , when , she was at IBM , that it 's a good idea . So .
Turn 274, C (Grad): Would {disfmarker} would that fit on the handset , or {disfmarker} ? Oh !
Turn 275, A (PhD): I have no idea .
Turn 276, C (Grad): OK .
Turn 277, D (PhD): Well , it has t I mean the {disfmarker} th
Turn 278, A (PhD): It would have to fit but {disfmarker} Yeah .
Turn 279, D (PhD): Yeah , if it has to fit the delays and all this stuff .
Turn 280, B (Professor): Well , there 's the delays and the storage ,
Turn 281, C (Grad): OK .
Turn 282, B (Professor): yeah . But I don't think the storage is so big for that .
Turn 283, C (Grad): Right .
Turn 284, D (PhD): Yeah .
Turn 285, B (Professor): I think th the biggest we 've run into for storage is the neural net . Right ?
Turn 286, D (PhD): Yeah .
Turn 287, B (Professor): Yeah . Um . And so I guess the issue there is , are we {disfmarker} are we using neural - net - based TRAPS , and {disfmarker} and how big are they ? So that 'll {disfmarker} that 'll be , you know , an issue .
Turn 288, C (Grad): Oh , right .
Turn 289, B (Professor): Maybe they can be little ones .
Turn 290, C (Grad): Yeah . Cuz sh Right .
Turn 291, B (Professor): Mini - TRAPS .
Turn 292, C (Grad): Cuz she also does the , uh {disfmarker} the correlation - based , uh , TRAPS , with without the neural net , just looking at the correlation between {disfmarker}
Turn 293, B (Professor): Right . And maybe for VAD they would be OK . Yeah . Yeah .
Turn 294, C (Grad): Yeah .
Turn 295, B (Professor): That 's true .
Turn 296, D (PhD): Yeah .
Turn 297, B (Professor): Or a simple neural net , right ? I mean , the thing is , if you 're doing correlation , you 're just doing a simple {disfmarker} uh , uh {disfmarker} uh , dot product , you know , with some weights which you happened to learn from this {disfmarker} learn from the data .
Turn 298, C (Grad): Mm - hmm .
Turn 299, B (Professor): And so , uh , putting a nonlinearity on it is , {pause} you know , not that big a deal . It certainly doesn't take much space .
Turn 300, C (Grad): Mm - hmm . Right .
Turn 301, B (Professor): So , uh , the question is , how complex a function do you need ? Do you need to have an added layer or something ? In which case , uh , potentially , you know , it could be big . So .
Turn 302, C (Grad): Mm - hmm .
Turn 303, B (Professor): So , uh , uh {disfmarker} So what 's next ? Maybe s s remind us .
Turn 304, E (PhD): So the meeting with Hynek that you guys just had was to decide exactly what you were gonna freeze in this system ? Is that {disfmarker} ? Or was there {disfmarker} ? Were you talking about what t new stuff , or {disfmarker} ?
Turn 305, B (Professor): What to freeze and then what to do after we froze .
Turn 306, E (PhD): Mmm .
Turn 307, B (Professor): Yeah . And like I was saying , I think the {disfmarker} you know , the basic directions are , uh , uh {disfmarker} I mean , there 's lots of little things , such as improve the noise estimator but the bigger things are adding on the neural net and , uh , the second stream . And then , uh , improving the VAD . Uh . So .
Turn 308, D (PhD): So , I 'll , um {disfmarker} I 'll actually {disfmarker} after the meeting I 'll add the second stream to the VAD and maybe I 'll start with the feature net in that case . It 's like , you 're looking at the VAD , right ?
Turn 309, A (PhD): Uh , yeah . I I 've a new feature net ready also .
Turn 310, D (PhD): I 'll {disfmarker} For the VAD ?
Turn 311, A (PhD): No , uh . Well p two network , one VAD and one {pause} feature net .
Turn 312, D (PhD): Oh , you already have it ?
Turn 313, A (PhD): Mm - hmm .
Turn 314, D (PhD): OK , so just figure how to take the features from the final {disfmarker}
Turn 315, A (PhD): Yeah .
Turn 316, D (PhD): OK .
Turn 317, A (PhD): Um . But , yeah , I think there are plenty of issues to work on for the feature net @ @ .
Turn 318, C (Grad): Feature net .
Turn 319, E (PhD): What about the , um {disfmarker} uh , the new part of the evaluation , the , uh , Wall Street Journal part ?
Turn 320, B (Professor): Right . Right . Um . Have you ever {disfmarker} ? Very good question . Have you ever worked with the Mississippi State h uh , software ?
Turn 321, A (PhD): Sorry .
Turn 322, E (PhD): No . Not yet .
Turn 323, B (Professor): Oh . Well you {disfmarker} you may be called upon to help , uh , uh , on account of , uh , all the work in this stuff here has been , uh , with small vocabulary .
Turn 324, E (PhD): OK . Mm - hmm . So what {disfmarker} how is the , uh , interaction supposed to happen ? Uh , I remember the last time we talked about this , it was sort of up in the air whether they were going to be taking , uh , people 's features and then running them or they were gonna give the system out or {disfmarker}
Turn 325, D (PhD): Yeah . Yeah .
Turn 326, E (PhD): Oh , so they 're gonna just deliver a system basically .
Turn 327, D (PhD): Yeah , yeah .
Turn 328, B (Professor): Do we already have it ?
Turn 329, D (PhD): Yeah , th I {disfmarker} I guess it 's almost ready .
Turn 330, E (PhD): Uh - huh .
Turn 331, D (PhD): So {disfmarker} That 's what {disfmarker} So they have released their , uh , document , describing the system .
Turn 332, B (Professor): Maybe you could , uh , point it {pause} at Chuck ,
Turn 333, E (PhD): I see .
Turn 334, B (Professor): because , I mean {disfmarker}
Turn 335, D (PhD): Sure .
Turn 336, E (PhD): So we 'll have to grab this over CVS or something ?
Turn 337, D (PhD): It - no , it 's just downloadable from their {disfmarker} from their web site .
Turn 338, E (PhD): Is that how they do it ? OK .
Turn 339, B (Professor): Cuz one of the things that might be helpful , if you 've {disfmarker} if you 've got time in all of this is , is if {disfmarker} if these guys are really focusing on improving , uh , all the digit stuff , uh , maybe {disfmarker} and you got the front - end from them , maybe you could do the runs for the {disfmarker}
Turn 340, E (PhD): OK . Mm - hmm .
Turn 341, B (Professor): and {disfmarker} and , you know , iron out hassles that {disfmarker} that you have to , uh , tweak Joe about or whatever ,
Turn 342, E (PhD): Sure .
Turn 343, B (Professor): because you 're more experienced with running the large vocabulary stuff .
Turn 344, E (PhD): OK .
Turn 345, B (Professor): S
Turn 346, D (PhD): So I 'll point you to the web site and the mails corresponding . So I
Turn 347, E (PhD): And it {disfmarker} but it 's not ready yet , the system ?
Turn 348, D (PhD): Uh , I {disfmarker} I think they are still , uh , tuning something on that . So they 're like , d they 're varying different parameters like the insertion penalty and other stuff , and then seeing what 's the performance .
Turn 349, E (PhD): Are those going to be parameters that are frozen , nobody can change ? Or {disfmarker} ?
Turn 350, D (PhD): Uh , w I guess there is , uh , time during which people are gonna make suggestions .
Turn 351, E (PhD): Oh , but everybody 's gonna have to use the same values .
Turn 352, D (PhD): After that .
Turn 353, E (PhD): Oh ! Interesting .
Turn 354, D (PhD): Yeah , I guess .
Turn 355, E (PhD): OK .
Turn 356, D (PhD): So these sugges these {disfmarker} this , uh , period during which people are gonna make suggestions is to know whether it is actually biased towards any set of features or {disfmarker}
Turn 357, B (Professor): Yeah , so I th th certainly the thing that I would want to know about is whether we get really hurt , uh , on in insertion penalty , language model , scaling , sorts of things .
Turn 358, E (PhD): Using our features .
Turn 359, B (Professor): Yeah , yeah .
Turn 360, E (PhD): Yeah .
Turn 361, B (Professor): Uh , in which case , um , H Hari or Hynek will need to , you know , push the case {pause} more about {disfmarker} about this .
Turn 362, E (PhD): Mm - hmm .
Turn 363, B (Professor): Um .
Turn 364, E (PhD): And we may be able to revisit this idea about , you know , somehow modifying our features to work with {disfmarker}
Turn 365, B (Professor): Yes . In this case , that 's right .
Turn 366, E (PhD): Yeah .
Turn 367, B (Professor): That 's right . Um , some of that may be , uh , a last minute rush thing because if the {disfmarker} if our features are changing {disfmarker} Uh .
Turn 368, E (PhD): Yeah .
Turn 369, B (Professor): Uh . But , um . Yeah , the other thing is that even though it 's months away , uh , it 's starting to seem to me now like November fifteenth is right around the corner . And , um , if they haven't decided things like this , like what the parameters are gonna be for this , uh , when " deciding " is not just somebody deciding . I mean , in fact there should be some understanding behind the , uh , {vocalsound} deciding , which means some experiments and {disfmarker} and so forth . It {disfmarker} it {disfmarker} it seems pretty tight to me .
Turn 370, E (PhD): So wha what 's the significance of November fifteenth ?
Turn 371, B (Professor): That 's when the evaluation is .
Turn 372, E (PhD): OK .
Turn 373, B (Professor): Yeah . So , yeah , so after {disfmarker} But , you know , they may even decide in the end to push it off . It wouldn't , you know , entirely surprise me . But , uh , due to other reasons , like some people are going away , I 'm {disfmarker} I 'm hoping it 's not pushed off for {vocalsound} a l a long while . That would be , uh {disfmarker} put us in an awkward position . But {disfmarker} Anyway .
Turn 374, E (PhD): OK .
Turn 375, B (Professor): Great . Yeah , I think that 'll be helpful . There 's {disfmarker} there 's not anybody OGI currently who 's {disfmarker} who 's , uh , working with this and {disfmarker} and
Turn 376, E (PhD): Is {disfmarker} is this part of the evaluation just a small part , or ho how important is this to the overall {disfmarker} ?
Turn 377, B (Professor): I {disfmarker} I think it 's {disfmarker} it 's , um {disfmarker} it depends how badly {vocalsound} you do . I mean , I think that it {disfmarker} it is {disfmarker} Uh .
Turn 378, D (PhD): b
Turn 379, E (PhD): This is one of those things that will be debated afterwards ?
Turn 380, B (Professor): Yeah . Well , I mean , it 's {disfmarker} it 's {disfmarker} Conceptually , it {disfmarker} my impression , again , you guys correct me if I 'm wrong , but {pause} my impression is that , um , they want it as a double check . That you haven't come across {disfmarker} you haven't invented features which are actually gonna do badly for a {disfmarker} a significantly different task , particularly one with larger vocabulary . And , um , but it 's not the main emphasis .
Turn 381, E (PhD): Mmm .
Turn 382, B (Professor): I mean , the truth is , most of the applications they 're looking at are pretty small vocabulary .
Turn 383, E (PhD): Mmm .
Turn 384, B (Professor): So it 's {disfmarker} it 's a double check . So they 'll probably assign it some sort of low weight .
Turn 385, E (PhD): Seems to me that if it 's a double check , they should give you a one or a zero . Y you passed the threshold or you didn't pass the threshold , and they shouldn't even care about what the score is .
Turn 386, B (Professor): Yeah . But , I mean , we 'll {disfmarker} we 'll {disfmarker} we 'll see what they come up with . Uh , but in {disfmarker} in the current thing , for instance , where you have this well - matched , moderately - matched , and {disfmarker} and mis highly - mismatched , uh , the emphasis is somewhat on the {disfmarker} on the well - matched , but it 's only a {disfmarker} a marginal ,
Turn 387, E (PhD): Yeah .
Turn 388, B (Professor): right ? It 's like forty , thirty - five , twenty - five , or something like that . So you still {disfmarker} if you were way , way off on the highly - mismatched , it would have a big effect .
Turn 389, D (PhD): Yeah .
Turn 390, E (PhD): Mm - hmm .
Turn 391, B (Professor): And , um , it wouldn't surprise me if they did something like that with this . So again , if you 're {disfmarker} if you get {disfmarker} If it doesn't help you much , uh , for noisy versions of this {disfmarker} of large vocabulary data , then , uh , you know , it may not hurt you that much .
Turn 392, E (PhD): Oh .
Turn 393, B (Professor): But if it {disfmarker} if you don't {disfmarker} if it doesn't help you much at all , um , or to put it another way , if it helps some people a lot more than it helps other people , uh , if their strategies do , then {disfmarker}
Turn 394, E (PhD): Mm - hmm . So is this , uh {disfmarker} ? Uh , Guenter was putting a bunch of Wall Street Journal data on our disks .
Turn 395, B (Professor): That 's it .
Turn 396, E (PhD): So that 's the data that we 'll be running on ?
Turn 397, B (Professor): Yeah .
Turn 398, E (PhD): I see . OK .
Turn 399, B (Professor): Yeah . So {pause} we have the data , just not the recognizer . OK .
Turn 400, E (PhD): So this test may take quite a while to run , then . May - judging by the amount of data that he was putting on .
Turn 401, B (Professor): Uh , well there 's training and test , right ?
Turn 402, E (PhD): I {disfmarker} I guess , I 'm not sure .
Turn 403, B (Professor): No , I mean , if it 's like the other things , there 's {disfmarker} there 's data for training the H M Ms and {disfmarker} and data for testing it .
Turn 404, E (PhD): I just {disfmarker}
Turn 405, B (Professor): So I wouldn't {disfmarker} So it {disfmarker} it 's {disfmarker}
Turn 406, E (PhD): OK . So there 's {disfmarker}
Turn 407, B (Professor): So , training the recognizer , but , um Um . But I think it 's trained on clean and {disfmarker} Is it trained on clean and {disfmarker} and test on {disfmarker} ?
Turn 408, D (PhD): The Wall Street ?
Turn 409, B (Professor): Yeah .
Turn 410, A (PhD): Apparently , no . It 's training on a range between ten and twenty DB , I think , and testing between five and fifteen .
Turn 411, D (PhD): Mm - hmm . Yeah .
Turn 412, A (PhD): That 's what I got {pause} on {disfmarker}
Turn 413, B (Professor): OK .
Turn 414, D (PhD): It 's , uh {disfmarker} It 's like a medium {disfmarker} medium - mismatch condition , sort of .
Turn 415, A (PhD): Yeah ,
Turn 416, B (Professor): I see .
Turn 417, A (PhD): and {disfmarker} So the noise is {disfmarker} There is a range of different noises also {disfmarker} um {disfmarker} which are selected randomly and added randomly , uh , to the files . And there are noises that are different from the noises used {pause} on TI - digits .
Turn 418, B (Professor): Yeah . Yeah . I mean , I wouldn't imagine that the amount of testing data was that huge . They probably put training {disfmarker} uh , almost certain they put training data there too . Maybe not . So . That 's that . Anybody have anything else ?
Turn 419, E (PhD): Uh , one {disfmarker} one last question on that . When did they estimate that they would have that system available for download ?
Turn 420, D (PhD): Um , I guess {disfmarker} I guess one {disfmarker} some preliminary version is already there .
Turn 421, E (PhD): Oh , so there 's w something you can download to just learn ?
Turn 422, D (PhD): Yeah , it 's already there . Yeah .
Turn 423, E (PhD): OK ,
Turn 424, D (PhD): But they 're actually parallel - y doing some modifications also , I think .
Turn 425, E (PhD): good .
Turn 426, D (PhD): So I guess the f final system will be frozen by middle of , like , one more week maybe .
Turn 427, E (PhD): OK .
Turn 428, B (Professor): Oh , well that 's pretty soon .
Turn 429, D (PhD): Yeah , that 's just one more .
Turn 430, C (Grad): Is this their , um , SVM recognizer ?
Turn 431, D (PhD): No , it 's just a straightforward HMM .
Turn 432, B (Professor): You know , their {disfmarker} their {disfmarker} They have a lot of options {pause} in their recognizer and {disfmarker} and the SVM is one of the things they 've done with it , but it 's not their more standard thing .
Turn 433, C (Grad): Oh , OK . Uh - huh .
Turn 434, B (Professor): For the most part it 's {disfmarker} it 's Gaussian mixtures .
Turn 435, C (Grad): Oh , OK . Oh , OK .
Turn 436, B (Professor): Yeah .
Turn 437, D (PhD): It 's just a HMM , Gaussian mixture model .
Turn 438, C (Grad): Gaussian mixture HMM .
Turn 439, B (Professor): Yeah .
Turn 440, C (Grad): OK .
Turn 441, B (Professor): Yeah , the SVM thing was an HMM also . It was just a {disfmarker} it {disfmarker} it {disfmarker} it was like a hybrid , like {disfmarker}
Turn 442, C (Grad): Mm - hmm .
Turn 443, D (PhD): Yeah , this is a g yeah , this i
Turn 444, B (Professor): what ?
Turn 445, D (PhD): yeah .
Turn 446, B (Professor): Yeah .
Turn 447, E (PhD): So , just so that I understand , they 're providing scripts and everything so that basically , uh , you {disfmarker} you push a button and it does training , and then it does test , and everything ? Is that {pause} the idea ?
Turn 448, D (PhD): I {disfmarker} I {disfmarker} I think {disfmarker} yeah , I {disfmarker} I guess something like that . It 's like {vocalsound} {disfmarker} as painless as possible ,
Turn 449, E (PhD): Mm - hmm .
Turn 450, D (PhD): is what {disfmarker} Do they provide all the scripts , everything , and then {disfmarker} Just ,
Turn 451, E (PhD): I see . Hmm . Somehow yo there 's hooks to put your features in and {disfmarker}
Turn 452, D (PhD): ju Yeah , I th I think .
Turn 453, E (PhD): Hmm .
Turn 454, B (Professor): Hmm . Yeah , um . In fact , I mean , if you look into it a little bit , it might be reasonable {disfmarker} You know Joe , right ? Yeah .
Turn 455, E (PhD): Mm - hmm .
Turn 456, B (Professor): Just to sort of ask him about the issue of , um , different features having different kinds of , uh , scaling characteristics and so on . So that , you know , w w possibly having entirely different optimal values for {disfmarker} for the usual twiddle factors and what 's {disfmarker} what 's the plan about that ?
Turn 457, E (PhD): OK .
Turn 458, D (PhD): So sh shall we , like , add Chuck also to the mailing lists ? It may be better , I mean , in that case if he 's going to {disfmarker}
Turn 459, B (Professor): Yeah .
Turn 460, D (PhD): Because there 's a mailing list for this .
Turn 461, B (Professor): Is that OK ?
Turn 462, E (PhD): Yeah , that 'd be great .
Turn 463, D (PhD): Yeah , I guess maybe Hari or Hynek , one of them , has to {pause} send a mail to Joe . Or maybe if you {disfmarker}
Turn 464, E (PhD): I {disfmarker} I could send him an email .
Turn 465, D (PhD): Well , yeah , to add or maybe wh
Turn 466, E (PhD): I {disfmarker} I know him really well .
Turn 467, D (PhD): Yeah , so that 's just fine .
Turn 468, E (PhD): I {disfmarker} I was just talking with him on email the other day actually .
Turn 469, D (PhD): So {disfmarker}
Turn 470, B (Professor): Uh , yeah , and just , um , se maybe see .
Turn 471, D (PhD): So {disfmarker}
Turn 472, E (PhD): About other things , but .
Turn 473, B (Professor): Do you have Hari 's , uh {disfmarker} ?
Turn 474, E (PhD): I have Hari 's {disfmarker}
Turn 475, B (Professor): Yeah , so maybe just CC Hari and say that you 've just been asked to handle the large vocabulary part here , and , uh , you know ,
Turn 476, E (PhD): OK . Would it be better if I asked Hari to ask Joe ?
Turn 477, B (Professor): Uh . Why don't you just ask Joe but CC Hari , and then in the note say , " Hari , hopefully this is OK with you " .
Turn 478, E (PhD): OK .
Turn 479, B (Professor): And then if Joe feels like he needs a confirmation , Hari can answer it .
Turn 480, E (PhD): OK .
Turn 481, D (PhD): Yeah .
Turn 482, B (Professor): That way you can get started asking {comment} Joe quickly while he 's {disfmarker} while he 's maybe still , you know , putting in nails and screws and  Yeah .
Turn 483, D (PhD): And there is an , uh , archive of all the mails that has been {vocalsound} gon that has gone , uh , between these people {disfmarker} among these people . So just you can see all this {pause} mails in the ISIP web site {disfmarker}
Turn 484, E (PhD): OK .
Turn 485, D (PhD): Mississippi web site .
Turn 486, E (PhD): OK . Is that a password controlled {disfmarker} ?
Turn 487, D (PhD): Yeah , it 's password protected .
Turn 488, E (PhD): OK .
Turn 489, D (PhD): So , like {disfmarker} like , it 's , like {disfmarker}
Turn 490, B (Professor): Have you thought about {pause} how long {pause} would be uh , most useful for you to go up to OGI ?
Turn 491, A (PhD): I don't know , uh . We can {disfmarker} {vocalsound} For September , we can set up a work schedule and we can maybe work independently . And then at some point it maybe be better to work together again .
Turn 492, B (Professor): Oh , so you 're {disfmarker} you 're imagining more that you would come back here first for a while and then {disfmarker} and then go up there ?
Turn 493, A (PhD): I {disfmarker}
Turn 494, B (Professor): I mean , it 's to you .
Turn 495, A (PhD): Maybe , yeah .
Turn 496, B (Professor): I ju you guys are Well , y anyway , you don't have to decide this second but thi think about it {disfmarker} about what {disfmarker} what you would think would be the {disfmarker} the best way to work it . I 'll
Turn 497, A (PhD): But , uh {pause} Huh . Mm - hmm .
Turn 498, B (Professor): support it either way , so .
Turn 499, A (PhD): Mm - hmm Right .
Turn 500, B (Professor): OK . Uh . Got anything to tell us ?
Turn 501, C (Grad): Um . Well , I 've been reading some literature about clustering of data . Just , um , I guess , let me put it in context . OK , so we 're talking about discovering intermediate categories to , um {disfmarker} to classify . And , uh , I was looking at some of the work that , uh , Sangita was doing on these TRAPS things . So she has , um {disfmarker} she has temporal patterns for , um , a certain set of phonemes , from {disfmarker} from TIMIT , right ? the most common phonemes . And each one of them has {disfmarker} has a {disfmarker} a nice pattern over time , a one {disfmarker} one second window . And it has {disfmarker} has these patterns . Um , so she has , um a TRAP for each one of the phonemes , um , times fifteen , for each of the fifteen critical bands . And , um , {vocalsound} she does this agglomerative hierarchical clustering which {disfmarker} which basically , um , is a clustering algorithm that , uh , starts with many , many , many different points {disfmarker} many different clusters {disfmarker} uh , corresponding to the number of data , uh , patterns that you have in the data . And then you have this distance mej metric which , uh , measures how {disfmarker} how closely related they are . And you start , um {vocalsound} by merging the patterns that are most closely related .
Turn 502, E (PhD): And you create a tree .
Turn 503, C (Grad): And y yeah , yeah , a dendrogram tree .
Turn 504, E (PhD): Mm - hmm .
Turn 505, C (Grad): Um .
Turn 506, E (PhD): And then you can pick , uh , values anywhere along that tree to fix your set of clusters .
Turn 507, C (Grad): Right , usually it 's when , um {disfmarker} when the sol similarity measures , um , don't go down as much .
Turn 508, E (PhD): Mm - hmm .
Turn 509, C (Grad): And so , uh {disfmarker} so you stop at that point . And what she found was , sh um , was there were five broad , um {disfmarker} broad categories , uh , corresponding to , uh , things like , uh , fricatives and , uh , vocalic , um , and , uh , stops .
Turn 510, B (Professor): Mm - hmm .
Turn 511, C (Grad): And , uh , one for silence and {disfmarker} and another one for schwa {disfmarker} schwa sounds . Um , and , um , I was thinking about ways to {disfmarker} to generalize this because w you 're {disfmarker} it 's sort of like a {disfmarker} it 's not a completely automatic way of clustering , because yo beforehand you have these {disfmarker} these TRAPS and you 're saying that {disfmarker} that these frames correspond to this particular phoneme . Um , and that 's {disfmarker} that 's constraining your {disfmarker} your clustering to {disfmarker} to the set of phonemes that you already have . Um , whereas maybe we want to just take {disfmarker} take a look at , um , arbitrary windows in time , um , of varying length , um , and cluster those .
Turn 512, E (PhD): Mm - hmm .
Turn 513, C (Grad): And I 'm thinking if we {disfmarker} if we do that , then we would probably , um , at some point in the clustering algorithm find that we 've clustered things like , OK , thi this is a transition , um , this is a relatively stable {disfmarker} stable point .
Turn 514, E (PhD): Mm - hmm .
Turn 515, C (Grad): Um , and I 'm hoping to find other things of {disfmarker} of similarity and maybe use these things as the intermediate , um {disfmarker} intermediate categories that , uh , um , I 'll later classify .
Turn 516, E (PhD): Mm - hmm .
Turn 517, B (Professor): Are you looking at these in narrow bands ?
Turn 518, C (Grad): Um , right . F um , I 'm {disfmarker}
Turn 519, B (Professor): Cuz that 's what you 're gonna be using , right ?
Turn 520, C (Grad): Yeah , yeah . I {disfmarker} I haven't exactly figured out , um , the exact details for that but , uh , the {disfmarker} the representation of the data that I was thinking of , was using , um , critical band , um , energies , {vocalsound} um , over different lengths of time . So {disfmarker} Yeah .
Turn 521, B (Professor): Yeah , I mean , it seems somehow that needs th uh , there 's a couple things that I wonder about with this . I mean , so one is {disfmarker} is , {pause} again , looking at the same representation ,
Turn 522, C (Grad): OK .
Turn 523, B (Professor): I mean , if you 're going for this sort of thing where you have {pause} uh , little detectors that are looking at narrow bands , then what you 're going to be looking for should be some category that you can find with the narrow bands .
Turn 524, C (Grad): Mm - hmm .
Turn 525, B (Professor): That {disfmarker} that seems to be kind of fundamental to it . Um , and then the other thing , uh , is {disfmarker} that I wonder about with it , and {disfmarker} and don't take this in the wrong way , like I {disfmarker} I know what I 'm doing or anything ,
Turn 526, C (Grad): Right .
Turn 527, B (Professor): but , I mean . {vocalsound} Um , just wondering really .
Turn 528, C (Grad): Mm - hmm .
Turn 529, B (Professor): Um , the sort of standard answer about this sort of thing is that if you 're trying to find {pause} the right system in some sense , whether you 're trying by categories or {disfmarker} or parameters {pause} um , and your goal is discrimination , then having choices based on discrimination as opposed to , um , unsupervised nearness of things , um , is actually better .
Turn 530, C (Grad): Hmm .
Turn 531, B (Professor): Um , and I don't know if that {disfmarker} I mean , since you 're dealing with issues of robustness , you know , maybe {disfmarker} maybe this isn't right , but it 'd be something I 'd be concerned about . Because , for instance , you can imagine , uh , uh , i i if you remember from {disfmarker} from , uh {disfmarker} from your {disfmarker} your quals , John Ohala saying that , uh , " buh " {comment} and " puh " {comment} differed , uh , not really cuz of voicing but because of aspiration . I mean , in as far as wha what 's really there in the acoustics .
Turn 532, C (Grad): Mm - hmm .
Turn 533, B (Professor): So , um , if you looked {disfmarker} if you were doing some coarse clustering , you probably would put those two sounds together . And yet , I would gue I would guess that many of your recognition errors were coming from , uh , um , pfft , {comment} screwing up on this distinction .
Turn 534, C (Grad): Mm - hmm .
Turn 535, B (Professor): So , in fact , it 's a little hard because recognizers , to first order , sort of work . And the reasons we 're doing the things we 're doing is because they don't work as well as we 'd like . And since they sort of work , uh , it means that they are already doing {disfmarker} if you go and take any recognizer that 's already out there and you say , " how well is it distinguishing between {pause} schwas and stops ? "
Turn 536, C (Grad): Mm - hmm .
Turn 537, B (Professor): Boy , I bet they 're all doing nearly perfectly on this , right ?
Turn 538, C (Grad): Mm - hmm .
Turn 539, B (Professor): So these {disfmarker} these big categories that differ in huge obvious ways , we already know how to do . So , what are we bringing to the party ? I mean , in fact what we wanna do is have something that , particularly in the presence of noise , uh , is better at distinguishing between , uh , categories that are actually close to one another , and hence , would probably be clustered together .
Turn 540, C (Grad): Mmm .
Turn 541, B (Professor): So that 's th that 's the hard thing . I mean , I understand that there 's this other constraint that you 're considering , is that you wanna have categories that , uh {disfmarker} that would be straightforward for , say , a human being to mark if you had manual annotation . And it 's something that you really think you can pick up . But I think it 's also essential that you wanna look at what are the {vocalsound} confusions that you 're making and how can you come up with , uh , categories that , uh , can clarify these confusions .
Turn 542, C (Grad): Mm - hmm . Hmm .
Turn 543, B (Professor): So , I mean , the standard sort of way of doing that is take a look at the algorithms you 're looking at , but then throw in some discriminative aspect to it .  Y y this is more like , you know , how does LDA differ from PCA ? I mean , they 're the same sort of thing . They 're both orthogonalizing .
Turn 544, C (Grad): Right .
Turn 545, B (Professor): But , you know {disfmarker} and {disfmarker} and , um , this is a little harder because you 're not just trying to find parameters . You 're actually trying to find the {disfmarker} the {disfmarker} the {disfmarker} the categories themselves . Uh , so a little more like brain surgery , I think on yourself . Uh . So , uh
Turn 546, C (Grad): Yeah .
Turn 547, B (Professor): Um , anyway . That 's my {pause} thought .
Turn 548, C (Grad): OK .
Turn 549, B (Professor): You 've been thinking about this problem for a long time actually . I mean , well {disfmarker} W actually , you stopped thinking about it for a long time , but you used to think about it {vocalsound} a lot .
Turn 550, E (PhD): Yeah .
Turn 551, B (Professor): And you 've been thinking about it more now ,
Turn 552, D (PhD): Yeah .
Turn 553, B (Professor): these categories .
Turn 554, E (PhD): Yeah .
Turn 555, B (Professor): Mm - hmm .
Turn 556, E (PhD): I guess {disfmarker} I don't {disfmarker} I don't {disfmarker} um , it 's not clear to me how to reconcile , you know , what you 're saying , which I think is right , with {pause} the way I 've been looking at it . That it 's {disfmarker} it 's {disfmarker} it 's all not very clear to me . But it seems to me that the desire {disfmarker} the desirable feature to have is something that , um , is bottom - up . You know , however we do that .
Turn 557, B (Professor): Mm - hmm .
Turn 558, E (PhD): And and so I guess what I don't understand is how to do that and still be discriminative , because to be discriminative you have to have categories and the only categories that we know of to use are sort of these human {disfmarker} human sig significant {disfmarker} categories that are significant to humans , like phonemes , things like that .
Turn 559, B (Professor): Right .
Turn 560, E (PhD): But that 's sort of what you want to avoid . And so that feels {disfmarker} I don't know how to get out of this .
Turn 561, B (Professor): Well , here 's a {disfmarker} here 's a , uh , uh Here 's a generic and possibly useless thought , which is , {vocalsound} um , what do you really {disfmarker} I mean , in a sense the only s s systems that make sense , uh , are ones that {disfmarker} that have something from top - down in th in them . Right ? Because if e even the smallest organism that 's trying to learn to do anything , if it doesn't have any kind of reward for doing {disfmarker} or penal penalty for doing anything , then it 's just going to behave randomly .
Turn 562, E (PhD): Mm - hmm .
Turn 563, B (Professor): So whether you 're talking about something being learned through evolution or being learned through experience , it 's gotta have something come down to it that gives its reward or , you know , at least some reinforcement learning ,
Turn 564, E (PhD): Right .
Turn 565, B (Professor): right ?
Turn 566, E (PhD): So the question is , how far down ?
Turn 567, B (Professor): And
Turn 568, E (PhD): We could stop at words , but we don't , right ? We go all the way down to phonemes .
Turn 569, B (Professor): Right , but I me I {disfmarker} I think that maybe in some ways part of the difficulty is {disfmarker} is trying to deal with the {disfmarker} with these phonemes . You know , and {disfmarker} and {disfmarker} and i it 's almost like you want categories if {disfmarker} if our {disfmarker} if our , uh , um , {vocalsound} metric of {disfmarker} of goodness , uh , i if our {disfmarker}
Turn 570, E (PhD): Mm - hmm .
Turn 571, B (Professor): correction {disfmarker} if our metric of badness {vocalsound} is word error rate then , um , maybe we should be looking at words .
Turn 572, E (PhD): Mm - hmm .
Turn 573, B (Professor): I mean , for {disfmarker} for {disfmarker} for very nice , uh , reasons we 've looked for a while at syllables , and they have a lot of good properties , but i i i if you go all the way to words , I mean , that 's really {disfmarker} I mean , d w In many applications you wanna go further . You wanna go to concepts or something , or have {disfmarker} have {disfmarker} have concepts , actions , this sort of thing .
Turn 574, E (PhD): Yeah . But words would be a nice {disfmarker}
Turn 575, B (Professor): But , words aren't bad , yeah . And {disfmarker} and
Turn 576, E (PhD): Yeah , so the common {disfmarker} right , the common wisdom is you can't do words because there 's too many of them , right ? So you have to have some smaller set that you can use , uh , and {disfmarker} and so everybody goes to phonemes . But the problem is that we {disfmarker} we build models of words in terms of phonemes and these models are {disfmarker} are really cartoon - ish , right ? So when you look at conversational speech , for example , you don't see the phonemes that you {disfmarker} that you have in your word models .
Turn 577, B (Professor): Yeah . But {disfmarker} but {disfmarker} but we 're not trying for models of words here . See , so her here 's maybe where {disfmarker} If the issue is that we 're trying to come up with , um , some sort of intermediate categories which will then be useful for later stuff , uh , then {pause} maybe it doesn't matter that we can't have enough {disfmarker}
Turn 578, E (PhD): Mm - hmm . Mm - hmm .
Turn 579, B (Professor): I mean , what you wanna do is {disfmarker} is build up these categories that are {disfmarker} that are best for word recognition .
Turn 580, E (PhD): Right . Right .
Turn 581, B (Professor): And {disfmarker} and somehow if that 's built into the loop of what the categories {disfmarker} I mean , we do this every day in this very gross way of {disfmarker} of running o a thousand experiments
Turn 582, E (PhD):  Right .
Turn 583, B (Professor): because we have fast computers and picking the thing that has the best word error rate .
Turn 584, E (PhD): Yeah .
Turn 585, B (Professor): In some way {disfmarker} I mean , we derive that all the time . In some ways it 's really not {comment} a bad {disfmarker} bad thing to do because it tells you in fact how your adjustments at the very low level affect the {disfmarker} the final goal .
Turn 586, E (PhD): Mm - hmm . Mm - hmm .
Turn 587, B (Professor): Um , so maybe there 's a way to even put that in in a much more automatic way ,
Turn 588, E (PhD): Right .
Turn 589, B (Professor): where you take , you know , something about the error at the level of the word or some other {disfmarker} it could be syllable {disfmarker} but in some large unit ,
Turn 590, E (PhD): Uh - huh .
Turn 591, B (Professor): uh , and uh {disfmarker} yeah , you may not have word models , you have phone models , whatever , but you sort of {pause} don't worry about that , and just somehow feed it back through .
Turn 592, E (PhD): Mm - hmm .
Turn 593, B (Professor): You know , so that 's , uh , wh what I called a useless comments because I 'm not really telling you how to do it . But I mean , it 's a {disfmarker} {vocalsound} it 's {disfmarker} it 's , you know {disfmarker} it
Turn 594, E (PhD): No , but I think the important part in there is that , you know , if you want to be discriminative , you have to have uh , you know , categories .
Turn 595, B (Professor): Right .
Turn 596, E (PhD): And I think this {disfmarker} the important categories are the words , and {pause} not the phones .
Turn 597, B (Professor): Yeah . Yeah .
Turn 598, E (PhD): Maybe . And so {disfmarker} Right . If you can put the words in to the loop somehow for determining goodness of your sets of clusters {disfmarker} Uh {disfmarker}
Turn 599, B (Professor): Now , that being said , I think that {disfmarker} that if you have something that is , um {disfmarker} i Once you start dealing with spontaneous speech , all the things you 're saying are {disfmarker} are really true .
Turn 600, E (PhD): Mm - hmm .
Turn 601, B (Professor): If you {pause} have read speech that 's been manually annotated , like TIMIT , then , you know , i i you the phones are gonna be right , actually , {vocalsound} for the most part .
Turn 602, E (PhD): Yeah . Yeah ,
Turn 603, B (Professor): So {disfmarker} so , uh , it doesn't really hurt them to {disfmarker} to do that , to put in discrimination at that level .
Turn 604, E (PhD): yeah .
Turn 605, B (Professor): Um , if you go to spontaneous speech then it 's {disfmarker} it 's trickier and {disfmarker} and {disfmarker} and , uh , the phones are {disfmarker} uh , you know , it 's gonna be based on bad pronunciation models that you have of {disfmarker}
Turn 606, E (PhD): 
Turn 607, B (Professor): and , um {disfmarker} And it won't allow for the overlapping phenomenon
Turn 608, E (PhD): Mmm . So it 's almost like there 's this mechanism that we have that , you know , when {disfmarker} when we 're hearing read speech and all the phonemes are there you know , we {disfmarker} we deal with that , but {disfmarker} but when we go to conversational , and then all of a sudden not all the phonemes are there , it doesn't really matter that much to us as humans because we have some kind of mechanism that allows for these word models , whatever those models are , to be {pause} munged , you know , and {disfmarker} and it doesn't really hurt , and I 'm not sure how {disfmarker} {vocalsound} how to build that in . Uh .
Turn 609, B (Professor): Yeah , I mean , I guess the other thing i is {disfmarker} is to think of a little bit {disfmarker} I mean , we when y when you start looking at these kind of results I think it usually is {disfmarker} is pretty intuitive , but start looking at um , what are the kinds of confusions that you do make , uh , you know , between words if you want or {disfmarker} or {disfmarker} or , uh , even phones in {disfmarker} in {disfmarker} in {disfmarker} in read speech , say , uh , when there is noise . You know , so is it more across place or more across manner ? Or is it cor you know , is it {disfmarker} ?
Turn 610, C (Grad): Mm - hmm .
Turn 611, B (Professor): I mean , I know one thing that happens is that you {disfmarker} you {disfmarker} you , uh , you lose the , um , uh , low energy phones . I mean , if there 's added noise then low energy phones {vocalsound} sometimes don't get heard . And if that {disfmarker} if that is {disfmarker} if it {disfmarker} uh , if that turns it into another word or {disfmarker} or different {disfmarker} you know , or another pair of words or something , then it 's more likely to happen . But , um , I don't know , I w I would {disfmarker} I would guess that you 'd {disfmarker}
Turn 612, C (Grad): Mm - hmm .
Turn 613, B (Professor): W I don't know . Anyway , that 's {disfmarker}
Turn 614, E (PhD): I think part of the difficulty is that a l a lot of the robustness that we have is probably coming from a much higher level .
Turn 615, B (Professor): Mm - hmm .
Turn 616, E (PhD): You know , we understand the context of the situation when we 're having a conversation . And so if there 's noise in there , you know , our brain fills in and imagines what {disfmarker} what should be there .
Turn 617, B (Professor): Well that {disfmarker}
Turn 618, C (Grad): Yeah . We 're {disfmarker} we 're doing some sort of prediction of what {disfmarker}
Turn 619, E (PhD): Yeah , exactly .
Turn 620, B (Professor): Oh , sure , that 's really big .
Turn 621, C (Grad): Yeah .
Turn 622, B (Professor): Uh , but I mean , even if you do um , uh , diagnostic rhyme test kind of things , you know , where there really isn't an any information like that , uh , people are still better in noise than they {disfmarker} than they are in {disfmarker} in , uh {disfmarker} uh , than the machines are .
Turn 623, E (PhD): Hmm .
Turn 624, B (Professor): So , I mean , that 's {disfmarker} i Right . We can't {disfmarker} we can't get it at all without any language models . Language models are there and important but {disfmarker} but , uh {disfmarker} Uh . If we 're not working on that then {vocalsound} we should work on something else and improve it , but {disfmarker} especially if it looks like the potential is there . So {disfmarker} Should we do some digits ?
Turn 625, E (PhD): Yeah .
Turn 626, B (Professor): Since we 're here ?
Turn 627, E (PhD): Go ahead , Morgan .
Turn 628, B (Professor): OK .
Turn 629, E (PhD): OK .
Turn 630, B (Professor): That 's all folks .
