Turn 0, A (Professor): We 're going ? OK . Sh - Close your door on {disfmarker} door on the way out ?
Turn 1, B (Grad): OK . Thanks .
Turn 2, A (Professor): Thanks .
Turn 3, B (Grad): Oh .
Turn 4, A (Professor): Yeah . Probably wanna get this other door , too . OK . So . Um . {vocalsound} {vocalsound} What are we talking about today ?
Turn 5, E (PhD): Uh , well , first there are perhaps these uh Meeting Recorder digits that we tested .
Turn 6, A (Professor): Oh , yeah . That was kind of uh interesting .
Turn 7, E (PhD): So .
Turn 8, A (Professor): The {disfmarker} both the uh {disfmarker} {vocalsound} the SRI System and the oth
Turn 9, E (PhD): Um .
Turn 10, A (Professor): And for one thing that {disfmarker} that sure shows the {vocalsound} difference between having a lot of uh training data {vocalsound} or not ,
Turn 11, E (PhD): Of data ? Yeah .
Turn 12, A (Professor): uh , the uh {disfmarker} {vocalsound} The best kind of number we have on the English uh {disfmarker} on near microphone only is {disfmarker} is uh three or four percent .
Turn 13, E (PhD): Mm - hmm .
Turn 14, A (Professor): And uh it 's significantly better than that , using fairly simple front - ends {vocalsound} on {disfmarker} {vocalsound} on the uh {disfmarker} {vocalsound} uh , with the SRI system .
Turn 15, E (PhD): Mm - hmm .
Turn 16, A (Professor): So I th I think that the uh {disfmarker} But that 's {disfmarker} that 's using uh a {disfmarker} a pretty huge amount of data , mostly not digits , of course , but {disfmarker} but then again {disfmarker} Well , yeah . In fact , mostly not digits for the actual training the H M Ms whereas uh in this case we 're just using digits for training the H M
Turn 17, E (PhD): Yeah . Right .
Turn 18, A (Professor): Did anybody mention about whether the {disfmarker} the SRI system is a {disfmarker} {vocalsound} is {disfmarker} is doing the digits um the wor as a word model or as uh a sub s sub - phone states ?
Turn 19, E (PhD): I guess it 's {disfmarker} it 's uh allophone models ,
Turn 20, A (Professor): Yeah . Probably .
Turn 21, E (PhD): so , well {disfmarker}
Turn 22, A (Professor): Huh ?
Turn 23, E (PhD): Yeah . I think so , because it 's their very d huge , their huge system .
Turn 24, A (Professor): Yeah .
Turn 25, E (PhD): And . But . So . There is one difference {disfmarker} Well , the SRI system {disfmarker} the result for the SRI system that are represented here are with adaptation . So there is {disfmarker} It 's their complete system and {disfmarker} including on - line uh unsupervised adaptation .
Turn 26, A (Professor): That 's true .
Turn 27, E (PhD): And if you don't use adaptation , the error rate is around fifty percent worse , I think , if I remember .
Turn 28, A (Professor): OK .
Turn 29, E (PhD): Yeah .
Turn 30, A (Professor): It 's tha it 's that much , huh ?
Turn 31, E (PhD): Nnn . It 's {disfmarker} Yeah . It 's quite significant .
Turn 32, A (Professor): Oh . OK .
Turn 33, E (PhD): Yeah .
Turn 34, A (Professor): Still .
Turn 35, E (PhD): Mm - hmm .
Turn 36, A (Professor): But {disfmarker} but uh what {disfmarker} what I think I 'd be interested to do given that , is that we {disfmarker} we should uh {vocalsound} take {disfmarker} I guess that somebody 's gonna do this , right ? {disfmarker} is to take some of these tandem things and feed it into the SRI system , right ?
Turn 37, E (PhD): Yeah .
Turn 38, A (Professor): Yeah .
Turn 39, E (PhD): We can do something like that .
Turn 40, A (Professor): Yeah . Because {disfmarker}
Turn 41, E (PhD): Yeah . But {disfmarker} But I guess the main point is the data because uh {vocalsound} I am not sure . Our back - end is {disfmarker} is fairly simple but until now , well , the attempts to improve it or {disfmarker} have fail Ah , well , I mean uh what Chuck tried to {disfmarker} to {disfmarker} to do
Turn 42, A (Professor): Yeah , but he 's doing it with the same data , right ? I mean so to {disfmarker} {vocalsound} So there 's {disfmarker} there 's {disfmarker} there 's two things being affected .
Turn 43, E (PhD): Yeah . So it 's {disfmarker} Yeah .
Turn 44, A (Professor): I mean . One is that {disfmarker} that , you know , there 's something simple that 's wrong with the back - end . We 've been playing a number of states
Turn 45, E (PhD): Mm - hmm .
Turn 46, A (Professor): uh I {disfmarker} I don't know if he got to the point of playing with the uh number of Gaussians yet
Turn 47, E (PhD): Mm - hmm .
Turn 48, A (Professor): but {disfmarker} but uh , uh , you know . But , yeah , so far he hadn't gotten any big improvement ,
Turn 49, E (PhD): Mm - hmm .
Turn 50, A (Professor): but that 's all with the same amount of data which is pretty small .
Turn 51, E (PhD): Yeah .
Turn 52, A (Professor): And um .
Turn 53, E (PhD): Mmm . So , yeah , we could retrain some of these tandem on {disfmarker} on huge {disfmarker}
Turn 54, A (Professor): Well , you could do that , but I 'm saying even with it not {disfmarker} with that part not retrained , just {disfmarker} just using {disfmarker} having the H M Ms {disfmarker} much better H M
Turn 55, E (PhD): Ah , yeah . Just {disfmarker} f for the HMM models .
Turn 56, A (Professor): Yeah .
Turn 57, E (PhD): Yeah . Mm - hmm . Mm - hmm .
Turn 58, A (Professor): Um . {vocalsound} But just train those H M Ms using different features , the features coming from our Aurora stuff .
Turn 59, E (PhD): Yeah .
Turn 60, A (Professor): So .
Turn 61, E (PhD): Yeah . But {vocalsound} what would be interesting to see also is what {disfmarker} what {disfmarker} perhaps it 's not related , the amount of data but the um recording conditions . I don't know . Because {vocalsound} it 's probably not a problem of noise , because our features are supposed to be robust to noise .
Turn 62, A (Professor): Well , yeah .
Turn 63, E (PhD): It 's not a problem of channel , because there is um {vocalsound} {vocalsound} normalization with respect to the channel . So {disfmarker}
Turn 64, A (Professor): I {disfmarker} I {disfmarker} I 'm sorry . What {disfmarker} what is the problem that you 're trying to explain ?
Turn 65, E (PhD): The {disfmarker} the fact that {disfmarker} the result with the tandem and Aurora system are {vocalsound} uh so much worse .
Turn 66, A (Professor): That the {disfmarker} Oh . So much worse ? Oh .
Turn 67, E (PhD): Yeah .
Turn 68, A (Professor): I uh but I 'm {disfmarker} I 'm almost certain that it {disfmarker} it {disfmarker} {vocalsound} I mean , that it has to do with the um amount of training data .
Turn 69, E (PhD): It {disfmarker}
Turn 70, A (Professor): It {disfmarker} it 's {disfmarker} it 's orders of magnitude off .
Turn 71, E (PhD): Yeah but {disfmarker} Yeah . Yeah but we train only on digits and it 's {disfmarker} it 's a digit task , so . Well .
Turn 72, A (Professor): But {disfmarker} but having a huge {disfmarker} If {disfmarker} {vocalsound} if you look at what commercial places do , they use a huge amount of data .
Turn 73, E (PhD): It {disfmarker} Mm - hmm .
Turn 74, A (Professor): This is a modest amount of data .
Turn 75, E (PhD): Alright . Yeah .
Turn 76, A (Professor): So . {vocalsound} I mean , ordinarily you would say " well , given that you have enough occurrences of the digits , you can just train with digits rather than with , you know " {disfmarker}
Turn 77, E (PhD): Mm - hmm . Mm - hmm .
Turn 78, A (Professor): But the thing is , if you have a huge {disfmarker} in other words , do word models {disfmarker} But if you have a huge amount of data then you 're going to have many occurrences of similar uh allophones .
Turn 79, E (PhD): Right . Mmm .
Turn 80, A (Professor): And that 's just a huge amount of training for it .
Turn 81, E (PhD): Yeah .
Turn 82, A (Professor): So it 's {vocalsound} um {disfmarker} {vocalsound} I {disfmarker} I think it has to be that , because , as you say , this is , you know , this is near - microphone ,
Turn 83, E (PhD): Mm - hmm .
Turn 84, A (Professor): it 's really pretty clean data .
Turn 85, E (PhD): Mm - hmm .
Turn 86, A (Professor): Um . Now , some of it could be the fact that uh {disfmarker} let 's see , in the {disfmarker} in these multi - train things did we include noisy data in the training ?
Turn 87, E (PhD): Yeah .
Turn 88, A (Professor): I mean , that could be hurting us actually , for the clean case .
Turn 89, E (PhD): Yeah . Well , actually we see that the clean train for the Aurora proposals are {disfmarker} are better than the multi - train ,
Turn 90, A (Professor): It is if {disfmarker} Yeah .
Turn 91, E (PhD): yeah .
Turn 92, A (Professor): Yeah . Cuz this is clean data , and so that 's not too surprising .
Turn 93, E (PhD): Mm - hmm .
Turn 94, A (Professor): But um . Uh . So .
Turn 95, E (PhD): Well , o I guess what I meant is that well , let 's say if we {disfmarker} if we add enough data to train on the um on the Meeting Recorder digits , I guess we could have better results than this .
Turn 96, A (Professor): Uh - huh . Mm - hmm .
Turn 97, E (PhD): And . What I meant is that perhaps we can learn something uh from this , what 's {disfmarker} what 's wrong uh what {disfmarker} what is different between TI - digits and these digits and {disfmarker}
Turn 98, A (Professor): What kind of numbers are we getting on TI - digits ?
Turn 99, E (PhD): It 's point eight percent , so .
Turn 100, A (Professor): Oh . I see .
Turn 101, E (PhD): Four - Fourier .
Turn 102, A (Professor): So in the actual TI - digits database we 're getting point eight percent ,
Turn 103, E (PhD): Yeah . Yeah .
Turn 104, A (Professor): and here we 're getting three or four {disfmarker} three , let 's see , three for this ?
Turn 105, E (PhD): Mm - hmm .
Turn 106, A (Professor): Yeah . Sure , but I mean , um point eight percent is something like double uh or triple what people have gotten who 've worked very hard at doing that .
Turn 107, E (PhD): Mm - hmm .
Turn 108, A (Professor): And {disfmarker} and also , as you point out , there 's adaptation in these numbers also . So if you , you know , put the ad adap take the adaptation off , then it {disfmarker} for the English - Near you get something like two percent .
Turn 109, E (PhD): Mmm .
Turn 110, A (Professor): And here you had , you know , something like three point four . And I could easily see that difference coming from this huge amount of data that it was trained on .
Turn 111, E (PhD): Mm - hmm .
Turn 112, A (Professor): So it 's {disfmarker}
Turn 113, E (PhD): Mm - hmm .
Turn 114, A (Professor): You know , I don't think there 's anything magical here .
Turn 115, E (PhD): Yeah .
Turn 116, A (Professor): It 's , you know , we used a simple HTK system with a modest amount of data . And this is a {disfmarker} a , you know , modern {vocalsound} uh system uh has {disfmarker} has a lot of nice points to it .
Turn 117, E (PhD): Yeah . Mm - hmm .
Turn 118, A (Professor): Um . So . I mean , the HTK is an older HTK , even . So . Yeah it {disfmarker} it 's not that surprising .
Turn 119, E (PhD): Mm - hmm .
Turn 120, A (Professor): But to me it just {disfmarker} it just meant a practical {vocalsound} point that um if we want to {vocalsound} publish results on digits that {disfmarker} that people pay {vocalsound} attention to we probably should uh {disfmarker} Cuz we 've had the problem before that you get {disfmarker} show some {vocalsound} nice improvement on something that 's {disfmarker} that 's uh , uh {disfmarker} it seems like too large a number , and uh {vocalsound} uh people don't necessarily take it so seriously .
Turn 121, E (PhD): Mm - hmm .
Turn 122, A (Professor): Um . Yeah . Yeah . So the three point four percent for this uh is {disfmarker} is uh {disfmarker} So why is it {disfmarker} It 's an interesting question though , still . Why is {disfmarker} why is it three point four percent for the d the digits recorded in this environment as opposed to {vocalsound} the uh point eight percent for {disfmarker} for {disfmarker} for the original TI - digits database ? Um .
Turn 123, E (PhD): Yeah . th that 's {disfmarker} th that 's my point
Turn 124, A (Professor): Given {disfmarker} given the same {disfmarker} Yeah . So ignore {disfmarker} ignoring the {disfmarker} the {disfmarker} the SRI system for a moment ,
Turn 125, E (PhD): I {disfmarker} I {disfmarker} I don't I {disfmarker} Mm - hmm .
Turn 126, A (Professor): just looking at {vocalsound} the TI - di the uh tandem system , if we 're getting point eight percent , which , yes , it 's high . It 's , you know , it {disfmarker} it 's not awfully high ,
Turn 127, E (PhD): Mm - hmm .
Turn 128, A (Professor): but it 's , you know {disfmarker} it 's {disfmarker} it 's high . Um . {vocalsound} Why is it {vocalsound} uh four times as high , or more ?
Turn 129, E (PhD): Yeah , I guess .
Turn 130, A (Professor): Right ? I mean , there 's {disfmarker} {vocalsound} even though it 's close - miked there 's still {disfmarker} there really is background noise .
Turn 131, E (PhD): Mm - hmm .
Turn 132, A (Professor): Um . And {vocalsound} uh I suspect when the TI - digits were recorded if somebody fumbled or said something wrong or something that they probably made them take it over .
Turn 133, E (PhD): Mm - hmm .
Turn 134, A (Professor): It was not {disfmarker} I mean there was no attempt to have it be realistic in any {disfmarker} in any sense at all .
Turn 135, E (PhD): Well . Yeah . And acoustically , it 's q it 's {disfmarker} I listened . It 's quite different . TI - digit is {disfmarker} it 's very , very clean and it 's like studio recording
Turn 136, A (Professor): Mm - hmm .
Turn 137, E (PhD): whereas these Meeting Recorder digits sometimes you have breath noise and Mmm .
Turn 138, A (Professor): Right . Yeah . So I think they were {disfmarker}
Turn 139, E (PhD): It 's {nonvocalsound} not controlled at all , I mean .
Turn 140, A (Professor): Bless you .
Turn 141, B (Grad): Thanks .
Turn 142, A (Professor): I {disfmarker} Yeah . I think it 's {disfmarker} it 's {disfmarker} So . Yes .
Turn 143, E (PhD): Mm - hmm . But
Turn 144, A (Professor): It 's {disfmarker} I think it 's {disfmarker} it 's the indication it 's harder .
Turn 145, E (PhD): Yeah .
Turn 146, A (Professor): Uh . {vocalsound} Yeah and again , you know , i that 's true either way . I mean so take a look at the uh {disfmarker} {vocalsound} um , the SRI results . I mean , they 're much much better , but still you 're getting something like one point three percent for uh things that are same data as in T {disfmarker} TI - digits the same {disfmarker} same text .
Turn 147, E (PhD): Mm - hmm .
Turn 148, A (Professor): Uh . And uh , I 'm sure the same {disfmarker} same system would {disfmarker} would get , you know , point {disfmarker} point three or point four or something {vocalsound} on the actual TI - digits . So this {disfmarker} I think , on both systems the {vocalsound} these digits are showing up as harder .
Turn 149, E (PhD): Mmm .
Turn 150, A (Professor): Um .
Turn 151, E (PhD): Mm - hmm .
Turn 152, A (Professor): Which I find sort of interesting cause I think this is closer to {disfmarker} uh I mean it 's still read . But I still think it 's much closer to {disfmarker} to what {disfmarker} what people actually face , {vocalsound} um when they 're {disfmarker} they 're dealing with people saying digits over the telephone . I mean . {vocalsound} I don't think uh {disfmarker} I mean , I 'm sure they wouldn't release the numbers , but I don't think that uh {vocalsound} the uh {disfmarker} the {disfmarker} the companies that {disfmarker} that do telephone {vocalsound} speech get anything like point four percent on their {vocalsound} digits . I 'm {disfmarker} I 'm {disfmarker} I 'm sure they get {disfmarker} Uh , I mean , for one thing people do phone up who don't have uh uh Middle America accents and it 's a we we it 's {disfmarker} it 's {disfmarker} it 's US .
Turn 153, E (PhD): Mm - hmm .
Turn 154, A (Professor): it has {disfmarker} has many people {vocalsound} {vocalsound} who sound in many different ways . So . Um . I mean . OK . That was that topic . What else we got ?
Turn 155, E (PhD): Um .
Turn 156, A (Professor): Did we end up giving up on {disfmarker} on , any Eurospeech submissions ,
Turn 157, E (PhD): But {disfmarker}
Turn 158, A (Professor): or {disfmarker} ? I know Thilo and Dan Ellis are {disfmarker} are submitting something , but uh .
Turn 159, E (PhD): Yeah . I {disfmarker} {vocalsound} I guess e the only thing with these {disfmarker} the Meeting Recorder and , well , {disfmarker} So , I think , yeah {disfmarker} I think we basically gave up .
Turn 160, A (Professor): Um . {vocalsound} Now , actually for the {disfmarker} for the Aur - uh
Turn 161, E (PhD): But {disfmarker}
Turn 162, A (Professor): we do have stuff for Aurora , right ? Because {disfmarker} because we have ano an extra month or something .
Turn 163, E (PhD): Yeah . Yeah . Yeah . So . Yeah , for sure we will do something for the special session .
Turn 164, A (Professor): Yeah . Well , that 's fine . So th so {disfmarker} so we have a couple {disfmarker} a couple little things on Meeting Recorder
Turn 165, E (PhD): Yeah . Mm - hmm .
Turn 166, A (Professor): and we have {disfmarker} {vocalsound} We don't {disfmarker} we don't have to flood it with papers . We 're not trying to prove anything to anybody . so . That 's fine . Um . Anything else ?
Turn 167, E (PhD): Yeah . Well . So . Perhaps the point is that we 've been working on {vocalsound} is , yeah , we have put the um the good VAD in the system and {vocalsound} it really makes a huge difference . Um . So , yeah . I think , yeah , this is perhaps one of the reason why our system was not {disfmarker} {vocalsound} not the best , because with the new VAD , it 's very {disfmarker} the results are similar to the France Telecom results and perhaps even better sometimes .
Turn 168, A (Professor): Hmm .
Turn 169, B (Grad): Huh .
Turn 170, E (PhD): Um . So there is this point . Uh . The problem is that it 's very big and {vocalsound} {vocalsound} we still have to think how to {disfmarker} where to put it and {disfmarker} {vocalsound} um ,
Turn 171, A (Professor): Mm - hmm .
Turn 172, E (PhD): because it {disfmarker} it {disfmarker} well , this VAD uh either some delay and we {disfmarker} if we put it on the server side , it doesn't work , because on the server side features you already have LDA applied {vocalsound} from the f from the terminal side and {vocalsound} so you accumulate the delay so the VAD should be before the LDA which means perhaps on the terminal side and then smaller {vocalsound} and
Turn 173, A (Professor): So wha where did this good VAD come from ?
Turn 174, E (PhD): So . It 's um from OGI . So it 's the network trained {disfmarker} it 's the network with the huge amounts on hidden {disfmarker} of hidden units , and um nine input frames compared to the VAD that was in the proposal which has a very small amount of hidden units and fewer inputs .
Turn 175, A (Professor): This is the one they had originally ?
Turn 176, E (PhD): Yeah .
Turn 177, A (Professor): Oh . Yeah , but they had to {pause} get rid of it because of the space , didn't they ?
Turn 178, E (PhD): Yeah . So . Yeah . But the abso assumption is that we will be able to make a VAD that 's small and that works fine . And . So we can {disfmarker}
Turn 179, A (Professor): Well . So that 's a problem . Yeah .
Turn 180, E (PhD): Yeah but {disfmarker} nnn .
Turn 181, A (Professor): But the other thing is uh to use a different VAD entirely . I mean , uh i if {disfmarker} if there 's a {vocalsound} if {disfmarker} if {disfmarker} I {disfmarker} I don't know what the thinking was amongst the {disfmarker} the {disfmarker} the {vocalsound} the ETSI folk but um if everybody agreed sure let 's use this VAD and take that out of there {disfmarker}
Turn 182, E (PhD): Mm - hmm . Mm - hmm . They just want , apparently {disfmarker} they don't want to fix the VAD because they think there is some interaction between feature extraction and {disfmarker} and VAD or frame dropping But they still {vocalsound} want to {disfmarker} just to give some um {vocalsound} requirement for this VAD because it 's {disfmarker} it will not be part of {disfmarker} they don't want it to be part of the standard .
Turn 183, A (Professor): OK .
Turn 184, E (PhD): So . So it must be at least uh somewhat fixed but not completely . So there just will be some requirements that are still not {disfmarker} uh not yet uh ready I think .
Turn 185, A (Professor): Determined . I see . But I was thinking that {disfmarker} that uh {vocalsound} s " Sure , there may be some interaction ,
Turn 186, E (PhD): Nnn .
Turn 187, A (Professor): but I don't think we need to be stuck on using our or OGI 's {pause} VAD . We could use somebody else 's if it 's smaller or {disfmarker}
Turn 188, E (PhD): Yeah .
Turn 189, A (Professor): You know , as long as it did the job .
Turn 190, E (PhD): Mm - hmm .
Turn 191, A (Professor): So that 's good .
Turn 192, E (PhD): Uh . So there is this thing . There is um {disfmarker} Yeah . Uh I designed a new {disfmarker} a new filter because when I designed other filters with shorter delay from the LDA filters , {vocalsound} there was one filter with fif sixty millisecond delay and the other with ten milliseconds
Turn 193, A (Professor): Right .
Turn 194, E (PhD): and {vocalsound} uh Hynek suggested that both could have sixty - five sixty - s I think it 's sixty - five .
Turn 195, A (Professor): Yeah .
Turn 196, E (PhD): Yeah . Both should have sixty - five because {disfmarker}
Turn 197, A (Professor): You didn't gain anything , right ?
Turn 198, E (PhD): Yeah . And . So I did that and uh it 's running . So , {vocalsound} let 's see what will happen . Uh but the filter is of course closer to the reference filter .
Turn 199, A (Professor): Mm - hmm .
Turn 200, E (PhD): Mmm . Um . Yeah . I think {disfmarker}
Turn 201, A (Professor): So that means logically , in principle , it should be better . So probably it 'll be worse .
Turn 202, E (PhD): Yeah
Turn 203, A (Professor): Or in the basic perverse nature uh of reality . Yeah . OK .
Turn 204, E (PhD): Yeah . Sure .
Turn 205, C (Grad): Yeah .
Turn 206, A (Professor): OK .
Turn 207, E (PhD): Yeah , and then we 've started to work with this of um voiced - unvoiced stuff .
Turn 208, A (Professor): Mm - hmm .
Turn 209, E (PhD): And next week I think we will {vocalsound} perhaps try to have um a new system with uh uh MSG stream also see what {disfmarker} what happens . So , something that 's similar to the proposal too , but with MSG stream .
Turn 210, A (Professor): Mm - hmm . Mm - hmm .
Turn 211, E (PhD): Mmm .
Turn 212, A (Professor): OK .
Turn 213, D (PhD): No , I w {vocalsound} I begin to play {vocalsound} with Matlab and to found some parameter robust for voiced - unvoiced decision . But only to play . And we {disfmarker} {vocalsound} they {disfmarker} we found that maybe w is a classical parameter , the {vocalsound} sq the variance {vocalsound} between the um FFT of the signal and the small spectrum of time {vocalsound} we {disfmarker} after the um mel filter bank .
Turn 214, A (Professor): Uh - huh .
Turn 215, D (PhD): And , well , is more or less robust . Is good for clean speech . Is quite good {vocalsound} for noisy speech .
Turn 216, A (Professor): Huh ? Mm - hmm .
Turn 217, D (PhD): but um we must to have bigger statistic with TIMIT ,
Turn 218, A (Professor): Mm - hmm .
Turn 219, D (PhD): and is not ready yet to use on ,
Turn 220, A (Professor): Yeah .
Turn 221, D (PhD): well , I don't know .
Turn 222, A (Professor): Yeah .
Turn 223, E (PhD): Yeah . So , basically we wa want to look at something like the ex the ex excitation signal and {disfmarker}
Turn 224, A (Professor): Right .
Turn 225, D (PhD): Mm - hmm .
Turn 226, E (PhD): which are the variance of it and {disfmarker}
Turn 227, D (PhD): I have here . I have here for one signal , for one frame .
Turn 228, E (PhD): Mmm .
Turn 229, A (Professor): Yeah . Uh - huh .
Turn 230, D (PhD): The {disfmarker} the mix of the two , noise and unnoise , and the signal is this . Clean , and this noise .
Turn 231, A (Professor): Uh .
Turn 232, D (PhD): These are the two {disfmarker} the mixed , the big signal is for clean .
Turn 233, A (Professor): Well , I 'm s uh {disfmarker} There 's {disfmarker} None of these axes are labeled , so I don't know what this {disfmarker} What 's this axis ?
Turn 234, D (PhD): Uh this is uh {disfmarker} this axis is {vocalsound} nnn , " frame " .
Turn 235, A (Professor): Frame .
Turn 236, D (PhD): Mm - hmm .
Turn 237, A (Professor): And what 's th what this ?
Turn 238, D (PhD): Uh , this is uh energy , log - energy of the spectrum . Of the this is the variance , the difference {nonvocalsound} between the spectrum of the signal and FFT of each frame of the signal and this mouth spectrum of time after the f may fit for the two ,
Turn 239, A (Professor): For this one . For the noi
Turn 240, D (PhD): this big , to here , they are to signal . This is for clean and this is for noise .
Turn 241, A (Professor): Oh . There 's two things on the same graph .
Turn 242, D (PhD): Yeah . I don't know . I {disfmarker} I think that I have d another graph , but I 'm not sure .
Turn 243, A (Professor): So w which is clean and which is noise ?
Turn 244, E (PhD): Yeah . I think the lower one is noise .
Turn 245, D (PhD): The lower is noise and the height is clean .
Turn 246, A (Professor): OK . So it 's harder to distinguish
Turn 247, D (PhD): It 's height .
Turn 248, A (Professor): but it {disfmarker} but it g
Turn 249, E (PhD): Yeah .
Turn 250, A (Professor): with noise of course but {disfmarker} but {disfmarker}
Turn 251, D (PhD): Oh . I must to have .
Turn 252, A (Professor): Uh .
Turn 253, D (PhD): Pity , but I don't have two different
Turn 254, A (Professor): And presumably when there 's a {disfmarker} a {disfmarker}
Turn 255, E (PhD): So this should the {disfmarker} the {disfmarker} the t voiced portions .
Turn 256, A (Professor): Uh - huh .
Turn 257, D (PhD): Yeah , it is the height is voiced portion .
Turn 258, E (PhD): The p the peaks should be voiced portion .
Turn 259, D (PhD): And this is the noise portion .
Turn 260, A (Professor): Uh - huh .
Turn 261, D (PhD): And this is more or less like this . But I meant to have see @ @ two {disfmarker} two the picture .
Turn 262, A (Professor): Yeah . Yeah .
Turn 263, D (PhD): This is , for example , for one frame .
Turn 264, A (Professor): Yeah
Turn 265, D (PhD): the {disfmarker} the spectrum of the signal . And this is the small version of the spectrum after ML mel filter bank .
Turn 266, A (Professor): Yeah . And this is the difference ?
Turn 267, D (PhD): And this is I don't know . This is not the different . This is trying to obtain {vocalsound} with LPC model the spectrum but using Matlab without going factor and s
Turn 268, A (Professor): No pre - emphasis ? Yeah .
Turn 269, D (PhD): Not pre - emphasis . Nothing .
Turn 270, A (Professor): Yeah so it 's {disfmarker} doesn't do too well there .
Turn 271, D (PhD): And the {disfmarker} I think that this is good . This is quite similar . this is {disfmarker} {vocalsound} this is another frame . ho how I obtained the {vocalsound} envelope , {nonvocalsound} this envelope , with the mel filter bank .
Turn 272, A (Professor): Right . So now I wonder {disfmarker} I mean , do you want to {disfmarker} I know you want to get at something orthogonal from what you get with the smooth spectrum Um . But if you were to really try and get a voiced - unvoiced , do you {disfmarker} do you want to totally ignore that ? I mean , do you {disfmarker} do you {disfmarker} I mean , clearly a {disfmarker} a very big {disfmarker} very big cues {vocalsound} for voiced - unvoiced come from uh spectral slope and so on , right ?
Turn 273, E (PhD): Mm - hmm .
Turn 274, A (Professor): Um .
Turn 275, E (PhD): Yeah . Well , this would be {disfmarker} this would be perhaps an additional parameter ,
Turn 276, A (Professor): Yeah .
Turn 277, E (PhD): simply isn't {disfmarker}
Turn 278, A (Professor): I see .
Turn 279, E (PhD): Yeah .
Turn 280, D (PhD): Yeah because when did noise clear {nonvocalsound} in these section is clear
Turn 281, E (PhD): Uh .
Turn 282, A (Professor): Mm - hmm .
Turn 283, D (PhD): if s @ @ {nonvocalsound} val value is indicative that is a voice frame and it 's low values
Turn 284, A (Professor): Yeah . Yeah . Well , you probably want {disfmarker} I mean , {vocalsound} certainly if {vocalsound} you want to do good voiced - unvoiced detection , you need a few features . Each {disfmarker} each feature is {vocalsound} by itself not enough . But , you know , people look at {disfmarker} at slope and {vocalsound} uh first auto - correlation coefficient , divided by power .
Turn 285, E (PhD): Mmm .
Turn 286, A (Professor): Or {disfmarker} or uh um there 's uh {disfmarker} I guess we prob probably don't have enough computation to do a simple pitch detector or something ? I mean with a pitch detector you could have a {disfmarker} {vocalsound} have a {disfmarker} an estimate of {disfmarker} of what the {disfmarker}
Turn 287, E (PhD): Mmm .
Turn 288, A (Professor): Uh . Or maybe you could you just do it going through the P FFT 's figuring out some um probable {vocalsound} um harmonic structure . Right . And {disfmarker} and uh .
Turn 289, E (PhD): Mmm .
Turn 290, D (PhD): you have read up and {disfmarker} you have a paper , {vocalsound} the paper that you s give me yesterday . they say that yesterday {vocalsound} they are some {nonvocalsound} problem
Turn 291, E (PhD): Oh , yeah . But {disfmarker} Yeah , but it 's not {disfmarker} it 's , yeah , it 's {disfmarker} it 's another problem .
Turn 292, D (PhD): and the {disfmarker} Is another problem .
Turn 293, E (PhD): Yeah Um . Yeah , there is th this fact actually . If you look at this um spectrum ,
Turn 294, A (Professor): Yeah .
Turn 295, E (PhD): What 's this again ? Is it {vocalsound} the mel - filters ?
Turn 296, D (PhD): Yeah like this . Of kind like this .
Turn 297, E (PhD): Yeah . OK . So the envelope here is the output of the mel - filters
Turn 298, A (Professor): Mm - hmm .
Turn 299, E (PhD): and what we clearly see is that in some cases , and it clearly appears here , and the {disfmarker} the harmonics are resolved by the f Well , there are still appear after mel - filtering ,
Turn 300, A (Professor): Mm - hmm .
Turn 301, E (PhD): and it happens {vocalsound} for high pitched voice because the width of the lower frequency mel - filters {vocalsound} is sometimes even smaller than the pitch .
Turn 302, A (Professor): Yeah .
Turn 303, E (PhD): It 's around one hundred , one hundred and fifty hertz {vocalsound} Nnn .
Turn 304, A (Professor): Right .
Turn 305, E (PhD): And so what happens is that this uh , add additional variability to this envelope and {vocalsound} {vocalsound} um
Turn 306, A (Professor): Yeah .
Turn 307, E (PhD): so we were thinking to modify the mel - spectrum to have something that {disfmarker} that 's smoother on low frequencies .
Turn 308, A (Professor): That 's as {disfmarker} as a separate thing .
Turn 309, E (PhD): i
Turn 310, A (Professor): Yeah .
Turn 311, E (PhD): Yeah . This is a separate thing .
Turn 312, A (Professor): Separate thing ?
Turn 313, D (PhD): Yeah .
Turn 314, A (Professor): Yeah .
Turn 315, E (PhD): And .
Turn 316, A (Professor): Yeah . Maybe so . Um . Yeah . So , what {disfmarker} Yeah . What I was talking about was just , starting with the FFT you could {disfmarker} you could uh do a very rough thing to estimate {disfmarker} estimate uh pitch .
Turn 317, E (PhD): Yeah . Mm - hmm .
Turn 318, A (Professor): And uh uh , given {disfmarker} you know , given that , uh {vocalsound} you could uh uh come up with some kind of estimate of how much of the low frequency energy was {disfmarker} was explained by {disfmarker} {vocalsound} by uh uh those harmonics .
Turn 319, E (PhD): Mm - hmm .
Turn 320, A (Professor): Uh . It 's uh a variant on what you 're s what you 're doing . The {disfmarker} I mean , the {disfmarker} the {vocalsound} the mel does give a smooth thing . But as you say it 's not that smooth here . And {disfmarker} and so if you {disfmarker} {vocalsound} if you just you know subtracted off uh your guess of the harmonics then something like this would end up with {vocalsound} quite a bit lower energy in the first fifteen hundred hertz or so and {disfmarker} and our first kilohertz , even .
Turn 321, E (PhD): Mm - hmm .
Turn 322, A (Professor): And um {vocalsound} if was uh noisy , the proportion that it would go down would be if it was {disfmarker} if it was unvoiced or something .
Turn 323, E (PhD): Mm - hmm .
Turn 324, A (Professor): So you oughta be able to {vocalsound} pick out voiced segments . At least it should be another {disfmarker} another cue . So . {vocalsound} Anyway .
Turn 325, E (PhD): Mm - hmm .
Turn 326, A (Professor): OK ? That 's what 's going on . Uh . What 's up with you ?
Turn 327, B (Grad): Um {vocalsound} our t I went to {vocalsound} talk with uh Mike Jordan this {disfmarker} this week
Turn 328, A (Professor): Mm - hmm .
Turn 329, B (Grad): um {nonvocalsound} and uh {vocalsound} shared with him the ideas about um {vocalsound} extending the Larry Saul work and um I asked him some questions about factorial H M so like later down the line when {vocalsound} we 've come up with these {disfmarker} these feature detectors , how do we {disfmarker} {vocalsound} how do we uh {vocalsound} you know , uh model the time series that {disfmarker} that happens um {vocalsound} {vocalsound} and {vocalsound} and we talked a little bit about {vocalsound} factorial H M Ms and how {vocalsound} um when you 're doing inference {disfmarker} or w when you 're doing recognition , there 's like simple Viterbi stuff that you can do for {disfmarker} {vocalsound} for these H M and {vocalsound} the uh {disfmarker} {vocalsound} the great advantages that um a lot of times the factorial H M Ms don't {vocalsound} um {vocalsound} don't over - alert the problem there they have a limited number of parameters and they focus directly on {disfmarker} {vocalsound} on uh the sub - problems at hand so {vocalsound} you can imagine {vocalsound} um {vocalsound} five or so parallel {vocalsound} um features um transitioning independently and then {vocalsound} at the end you {disfmarker} you uh couple these factorial H M Ms with uh {disfmarker} {vocalsound} with uh undirected links um based on {disfmarker} {vocalsound} based on some more data .
Turn 330, A (Professor): Hmm .
Turn 331, B (Grad): So he {disfmarker} he seemed {disfmarker} he seemed like really interested in {disfmarker} {vocalsound} in um {disfmarker} in this and said {disfmarker} said this is {disfmarker} this is something very do - able and can learn a lot and um yeah , I 've just been {vocalsound} continue reading um about certain things .
Turn 332, A (Professor): Mm - hmm .
Turn 333, B (Grad): um thinking of maybe using um {vocalsound} um m modulation spectrum stuff to {vocalsound} um {disfmarker} as features um also in the {disfmarker} in the sub - bands
Turn 334, A (Professor): Mm - hmm .
Turn 335, B (Grad): because {vocalsound} it seems like {vocalsound} the modulation um spectrum tells you a lot about the intelligibility of {disfmarker} of certain um words and stuff So , um . Yeah . Just that 's about it .
Turn 336, A (Professor): OK .
Turn 337, C (Grad): OK . And um so I 've been looking at Avendano 's work and um uh I 'll try to write up in my next stat status report a nice description of {vocalsound} what he 's doing , but it 's {disfmarker} it 's an approach to deal with {vocalsound} reverberation or that {disfmarker} the aspect of his work that I 'm interested in the idea is that um {vocalsound} {vocalsound} {vocalsound} normally an analysis frames are um {vocalsound} too short to encompass reverberation effects um in full . You miss most of the reverberation tail in a ten millisecond window and so {vocalsound} {vocalsound} you {disfmarker} you 'd like it to be that {vocalsound} um {vocalsound} the reverberation responses um simply convolved um in , but it 's not really with these ten millisecond frames cuz you j But if you take , say , a two millisecond {vocalsound} um window {disfmarker} I 'm sorry a two second window then in a room like this , most of the reverberation response {vocalsound} is included in the window and the {disfmarker} then it um {vocalsound} then things are l more linear . It is {disfmarker} it is more like the reverberation response is simply c convolved and um {disfmarker} {vocalsound} and you can use channel normalization techniques {vocalsound} like uh in his thesis he 's assuming that the reverberation response is fixed . He just does um {vocalsound} mean subtraction , which is like removing the DC component of the modulation spectrum and {vocalsound} that 's supposed to d um deal {disfmarker} uh deal pretty well with the um reverberation and um {vocalsound} the neat thing is you can't take these two second frames and feed them to a speech recognizer um {vocalsound} so he does this {vocalsound} um {vocalsound} method training trading the um {vocalsound} the spectral resolution for time resolution {vocalsound} and um {vocalsound} come ca uh synthesizes a new representation which is with say ten second frames but a lower s um {vocalsound} frequency resolution . So I don't really know the theory . I guess it 's {disfmarker} these are called " time frequency representations " and h he 's making the {disfmarker} the time sh um finer grained and the frequency resolution um less fine grained .
Turn 338, E (PhD): Mm - hmm .
Turn 339, C (Grad): s so I 'm {disfmarker} I guess my first stab actually in continuing {vocalsound} his work is to um {vocalsound} re - implement this {disfmarker} this thing which um {vocalsound} changes the time and frequency resolutions cuz he doesn't have code for me . So that that 'll take some reading about the theory . I don't really know the theory .
Turn 340, E (PhD): Mm - hmm .
Turn 341, C (Grad): Oh , and um , {vocalsound} another f first step is um , so the {disfmarker} the way I want to extend his work is make it able to deal with a time varying reverberation response um {vocalsound} and um we don't really know {vocalsound} how fast the um {disfmarker} the reverberation response is varying the Meeting Recorder data um so um {vocalsound} we {disfmarker} we have this um block least squares um imp echo canceller implementation and um {vocalsound} I want to try {vocalsound} finding {vocalsound} the {disfmarker} the response , say , between a near mike and the table mike for someone using the echo canceller and looking at the echo canceller taps and then {vocalsound} see how fast that varies {vocalsound} from block to block .
Turn 342, E (PhD): Mm - hmm .
Turn 343, C (Grad): That should give an idea of how fast the reverberation response is changing .
Turn 344, E (PhD): Mm - hmm .
Turn 345, A (Professor): OK . Um . I think we 're {vocalsound} sort of done .
Turn 346, E (PhD): Yeah .
Turn 347, A (Professor): So let 's read our digits and go home .
Turn 348, C (Grad): Um . S so um y you do {disfmarker} I think you read some of the {disfmarker} the zeros as O 's and some as zeros .
Turn 349, A (Professor): Yeah .
Turn 350, C (Grad): Is there a particular way we 're supposed to read them ?
Turn 351, E (PhD): There are only zeros here . Well .
Turn 352, A (Professor): No . " O " {disfmarker} " O " {disfmarker} " O " " O " {disfmarker} " O " {disfmarker} " O " and " zero " are two ways that we say that digit .
Turn 353, E (PhD): Eee . Yeah .
Turn 354, A (Professor): So it 's {disfmarker}
Turn 355, B (Grad): Ha !
Turn 356, E (PhD): But {disfmarker}
Turn 357, A (Professor): so it 's {disfmarker} i
Turn 358, E (PhD): Perhaps in the sheets there should be another sign for the {disfmarker} if we want to {disfmarker} the {disfmarker} the guy to say " O " or
Turn 359, A (Professor): No . I mean . I think people will do what they say .
Turn 360, E (PhD): It 's {disfmarker}
Turn 361, A (Professor): It 's OK .
Turn 362, E (PhD): Yeah .
Turn 363, A (Professor): I mean in digit recognition we 've done before , you have {disfmarker} you have two pronunciations for that value , " O " and " zero " .
Turn 364, C (Grad): Alright .
Turn 365, E (PhD): OK .
Turn 366, C (Grad): OK .
Turn 367, E (PhD): But it 's perhaps more difficult for the people to prepare the database then , if {disfmarker} because here you only have zeros
Turn 368, A (Professor): No , they just write {disfmarker}
Turn 369, E (PhD): and {disfmarker} and people pronounce " O " or zero {disfmarker}
Turn 370, A (Professor): they {disfmarker} they write down OH . or they write down ZERO a and they {disfmarker} and they each have their own pronunciation .
Turn 371, E (PhD): Yeah but if the sh the sheet was prepared with a different sign for the " O " .
Turn 372, A (Professor): But people wouldn't know what that wa I mean {vocalsound} there is no convention for it .
Turn 373, E (PhD): OK . Yeah .
Turn 374, A (Professor): See . I mean , you 'd have to tell them {vocalsound} " OK when we write this , say it tha " ,
Turn 375, E (PhD): OK .
Turn 376, A (Professor): you know , and you just {disfmarker} They just want people to read the digits as you ordinarily would
Turn 377, E (PhD): Mm - hmm . Yeah .
Turn 378, A (Professor): and {disfmarker} and people say it different ways .
Turn 379, E (PhD): Yep .
Turn 380, C (Grad): OK . Is this a change from the last batch of {disfmarker} of um forms ? Because in the last batch it was spelled out which one you should read .
Turn 381, E (PhD): Yeah , it was orthographic , so .
Turn 382, A (Professor): Yes . That 's right . It was {disfmarker} it was spelled out , and they decided they wanted to get at more the way people would really say things .
Turn 383, C (Grad): Oh . OK .
Turn 384, A (Professor): That 's also why they 're {disfmarker} they 're bunched together in these different groups . So {disfmarker} so it 's {disfmarker}
Turn 385, C (Grad): OK .
Turn 386, A (Professor): Yeah . So it 's {disfmarker} it 's {disfmarker} Everything 's fine .
Turn 387, C (Grad): OK .
Turn 388, A (Professor): OK . Actually , let me just s since {disfmarker} since you brought it up , I was just {disfmarker} it was hard not to be self - conscious about that when it {vocalsound} after we {disfmarker} since we just discussed it . But I realized that {disfmarker} that um {vocalsound} when I 'm talking on the phone , certainly , and {disfmarker} and saying these numbers , {vocalsound} I almost always say zero . And uh {disfmarker} cuz {disfmarker} because uh i it 's two syllables . It 's {disfmarker} it 's more likely they 'll understand what I said . So that {disfmarker} that {disfmarker} that 's the habit I 'm in , but some people say " O " and {disfmarker}
Turn 389, B (Grad): Yeah I normally say " O " cuz it 's easier to say .
Turn 390, A (Professor): Yeah it 's shorter . Yeah . So it 's {disfmarker} So . {vocalsound} So uh .
Turn 391, B (Grad): " O "
Turn 392, A (Professor): Now , don't think about it .
Turn 393, B (Grad): Oh , no !
Turn 394, A (Professor): OK . We 're done .
