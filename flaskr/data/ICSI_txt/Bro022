Turn 0, B (Professor): I think for two years we were two months , uh , away from being done .
Turn 1, A (PhD): And what was that , Morgan ? What project ?
Turn 2, B (Professor): Uh , the , uh , TORRENT chip .
Turn 3, A (PhD): Oh .
Turn 4, B (Professor): Yeah . We were two {disfmarker} we were {disfmarker}
Turn 5, C (PhD): Yeah .
Turn 6, B (Professor): Uh , uh , we went through it {disfmarker} Jim and I went through old emails at one point and {disfmarker} and for two years there was this thing saying , yeah , we 're {disfmarker} we 're two months away from being done . It was very {disfmarker} very believable schedules , too . I mean , we went through and {disfmarker} with the schedules {disfmarker} and we {disfmarker}
Turn 7, A (PhD): It was true for two years .
Turn 8, B (Professor): Yeah . Oh , yeah . It was very true .
Turn 9, A (PhD): So , should we just do the same kind of deal where we {pause} go around and do , uh , status report {pause} kind of things ? OK . And I guess when Sunil gets here he can do his last or something . So .
Turn 10, B (Professor): Yeah . So we {pause} probably should wait for him to come before we do his .
Turn 11, C (PhD): Mm - hmm .
Turn 12, A (PhD): OK . That 's a good idea .
Turn 13, B (Professor): Yeah .
Turn 14, F (Grad): OK .
Turn 15, B (Professor): Yeah .
Turn 16, A (PhD): Any objection ? Do y OK , M
Turn 17, B (Professor): All in favor
Turn 18, A (PhD): Do you want to start , Morgan ? Do you have anything , or {disfmarker} ?
Turn 19, B (Professor): Uh , I don't do anything . I {disfmarker} No , I mean , I {disfmarker} I 'm involved in discussions with {disfmarker} with people about what they 're doing , but I think they 're {disfmarker} since they 're here , they can talk about it themselves .
Turn 20, F (Grad): OK . So should I go so that , uh ,
Turn 21, A (PhD): Yeah . Why don't you go ahead , Barry ?
Turn 22, F (Grad): you 're gonna talk about Aurora stuff , per se ?
Turn 23, A (PhD): OK .
Turn 24, F (Grad): OK . Um . Well , this past week I 've just been , uh , getting down and dirty into writing my {disfmarker} my proposal . So , um {disfmarker} Mmm . I just finished a section on , uh {disfmarker} on talking about these intermediate categories that I want to classify , um , as a {disfmarker} as a middle step . And , um , I hope to {disfmarker} hope to get this , um {disfmarker} a full rough draft done by , uh , Monday so I can give it to Morgan .
Turn 25, A (PhD): When is your , uh , meeting ?
Turn 26, F (Grad): Um , my meeting
Turn 27, A (PhD): Yeah .
Turn 28, F (Grad): with , uh {disfmarker} ? Oh , oh , you mean the {disfmarker} the quals .
Turn 29, A (PhD): The quals . Yeah .
Turn 30, F (Grad): Uh , the quals are happening in July twenty - fifth .
Turn 31, A (PhD): Oh . Soon .
Turn 32, F (Grad): Yeah .
Turn 33, A (PhD): Uh - huh .
Turn 34, F (Grad): D - Day .
Turn 35, A (PhD): Yeah .
Turn 36, F (Grad): Uh - huh .
Turn 37, A (PhD): So , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and {disfmarker} ?
Turn 38, F (Grad): Right , right . So , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . And , um , and then , um {disfmarker} then everybody asks you questions .
Turn 39, A (PhD): Hmm .
Turn 40, F (Grad): Yeah .
Turn 41, A (PhD): I remember now .
Turn 42, F (Grad): Yep . So , um .
Turn 43, A (PhD): Have you d ? I was just gonna ask , do you want to say any {disfmarker} a little bit about it ,
Turn 44, F (Grad): Y s
Turn 45, A (PhD): or {disfmarker} ? Mmm .
Turn 46, F (Grad): Oh . Uh , a little bit about {disfmarker} ?
Turn 47, A (PhD): Wh - what you 're {disfmarker} what you 're gonna {disfmarker} You said {disfmarker} you were talking about the , uh , particular features that you were looking at ,
Turn 48, F (Grad): Oh , the {disfmarker} the {disfmarker}
Turn 49, A (PhD): or {disfmarker}
Turn 50, F (Grad): Right . Well , I was , um , I think one of the perplexing problems is , um , for a while I was thinking that I had to come up with a complete set of intermediate features {disfmarker} in intermediate categories to {disfmarker} to classify right away . But what I 'm thinking now is , I would start with {disfmarker} with a reasonable set . Something {disfmarker} something like , um , um {disfmarker} like , uh , re regular phonetic features , just to {disfmarker} just to start off that way . And do some phone recognition . Um , build a system that , uh , classifies these , um {disfmarker} these feat uh , these intermediate categories using , uh , multi - band techniques . Combine them and do phon phoneme recognition . Look at {disfmarker} then I would look at the errors produced in the phoneme recognition and say , OK , well , I could probably reduce the errors if I included this extra feature or this extra intermediate category . That would {disfmarker} that would reduce certain confusions over other confusions . And then {disfmarker} and then {vocalsound} reiterate . Um , build the intermediate classifiers . Uh , do phoneme recognition . Look at the errors . And then postulate new {disfmarker} or remove , um , intermediate categories . And then do it again .
Turn 51, A (PhD): So you 're gonna use TIMIT ?
Turn 52, F (Grad): Um , for that {disfmarker} for that part of the {disfmarker} the process , yeah , I would use TIMIT .
Turn 53, A (PhD): Mm - hmm .
Turn 54, F (Grad): And , um , then {disfmarker} after {disfmarker} after , uh , um , doing TIMIT . Right ?
Turn 55, A (PhD): Mm - hmm .
Turn 56, F (Grad): Um , that 's {disfmarker} {vocalsound} that 's , um {disfmarker} that 's just the ph the phone recognition task .
Turn 57, A (PhD): Yeah .
Turn 58, F (Grad): Uh , I wanted to take a look at , um , things that I could model within word . So , I would mov I would then shift the focus to , um , something like Schw - Switchboard , uh , where I 'd {disfmarker} I would be able to , um {disfmarker} to model , um , intermediate categories that span across phonemes ,
Turn 59, A (PhD): Mm - hmm .
Turn 60, F (Grad): not just within the phonemes , themselves , um , and then do the same process there , um , on {disfmarker} on a large vocabulary task like Switchboard . Uh , and for that {disfmarker} for that part I would {disfmarker} I 'd use the SRI recognizer since it 's already set up for {disfmarker} for Switchboard . And I 'd run some {disfmarker} some sort of tandem - style processing with , uh , my intermediate classifiers .
Turn 61, A (PhD): Oh . So that 's why you were interested in getting your own features into the SRI files .
Turn 62, F (Grad): Yeah . That 's why I {disfmarker} I was asking about that .
Turn 63, A (PhD): Yeah . Yeah .
Turn 64, F (Grad): Yeah . Um , and I guess that 's {disfmarker} that 's it . Any {disfmarker} any questions ?
Turn 65, A (PhD): Sounds good . So you just have a few more weeks , huh ?
Turn 66, F (Grad): Um , yeah . A few more .
Turn 67, A (PhD): It 's about a month from now ?
Turn 68, F (Grad): It 's a {disfmarker} it 's a month and {disfmarker} and a week .
Turn 69, A (PhD): Yeah .
Turn 70, F (Grad): Yeah .
Turn 71, A (PhD): So , uh , you want to go next , Dave ? And we 'll do {disfmarker}
Turn 72, E (Grad): Oh . OK , sure . So , um , last week I finally got results from the SRI system about this mean subtraction approach . And , um , we {disfmarker} we got an improvement , uh , in word error rate , training on the TI - digits data set and testing on Meeting Recorder digits of , um , {vocalsound} six percent to four point five percent , um , on the n on the far - mike data using PZM F , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . And , um , wh why would that be , um , {vocalsound} considering that we actually got an improvement in near - mike performance using HTK ? And so , uh , with some input from , uh , Andreas , I have a theory in two parts . Um , first of all HTK {disfmarker} sorry , SR - the SRI system is doing channel adaptation , and so HTK wasn't . Um , so this , um {disfmarker} This mean subtraction approach will do a kind of channel {pause} normalization and so that might have given the HTK use of it a boost that wouldn't have been applied in the SRI case . And also , um , the {disfmarker} Andreas pointed out the SRI system is using more parameters . It 's got finer - grained acoustic models . So those finer - grained acoustic models could be more sensitive to the artifacts {pause} in the re - synthesized audio . Um . And me and Barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . And so that seems like it could be difficult for training , cuz you could have {pause} different phones {pause} lined up with a different foreground phone , {vocalsound} um , {vocalsound} depending on {pause} the timing of the echo . So , um , I 'm gonna try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . So I 'm planning to use the Macrophone set of , um , read speech , and , um {disfmarker} Hmm .
Turn 73, B (Professor): I had another thought just now , which is , uh , remember we were talking before about {disfmarker} we were talking in our meeting about , uh , this stuff that {disfmarker} some of the other stuff that Avendano did , where they were , um , getting rid of low - energy {pause} sections ? Um , uh , if you {disfmarker} if you did a high - pass filtering , as Hirsch did in {pause} late eighties to reduce some of the effects of reverberation , uh , uh , Avendano and Hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a {disfmarker} an all - positive power spectrum you get some negative values , and you gotta figure out what to do with them if you 're gonna continue treating this as a power spectrum . So , what {disfmarker} what Hirsch did was , uh , set them to zero {disfmarker} set the negative values to zero . So if you imagine a {disfmarker} a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . And it 's the low - energy parts of the speech where the reverberation is most audible . You know , you have the reverberation from higher - energy things showing up in {disfmarker} So in this case you have some artificially imposed {pause} reverberation - like thing . I mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n And , um , what if you did {disfmarker} ? I mean , there 's nothing to say that the {disfmarker} the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . I mean , you also could , uh , just try to make it nicer .
Turn 74, E (Grad): Uh - huh .
Turn 75, B (Professor): And one of the things you could do is , you could do some sort of VAD - like thing
Turn 76, E (Grad): Mm - hmm .
Turn 77, B (Professor): and you actually could take very low - energy sections and set them to some {disfmarker} some , uh , very low or {disfmarker} or near zero {pause} value . I mean , uh , I 'm just saying if in fact it turns out that {disfmarker} that these echoes that you 're hearing are , uh {disfmarker}
Turn 78, E (Grad): Uh - huh .
Turn 79, B (Professor): or pre - echoes , whichever they are {disfmarker} are {disfmarker} are , uh , part of what 's causing the problem , you actually could get rid of them .
Turn 80, E (Grad): Uh - huh .
Turn 81, B (Professor): Be pretty simple . I mean , you do it in a pretty conservative way
Turn 82, E (Grad): OK .
Turn 83, B (Professor): so that if you made a mistake you were more likely to {pause} keep in an echo than to throw out speech .
Turn 84, E (Grad): Hmm .
Turn 85, G (PhD): Um , what is the reverberation time {pause} like {pause} there ?
Turn 86, E (Grad): In thi in this room ? Uh {disfmarker}
Turn 87, G (PhD): On , uh , the {disfmarker} the one what {disfmarker} the s in the speech that you are {disfmarker} you are using like ?
Turn 88, E (Grad): Y Yeah . I {disfmarker} I {disfmarker} I {disfmarker} I don't know .
Turn 89, B (Professor): So , it 's this room .
Turn 90, G (PhD): It 's , uh {disfmarker}
Turn 91, B (Professor): It 's {disfmarker} it 's this room .
Turn 92, G (PhD): Oh , this room ?
Turn 93, B (Professor): So {disfmarker}
Turn 94, G (PhD): OK .
Turn 95, B (Professor): so it 's {disfmarker} these are just microphone {disfmarker} this micro close microphone and a distant microphone , he 's doing these different tests on .
Turn 96, F (Grad): Oh .
Turn 97, B (Professor): Uh , we should do a measurement in here . I g think we never have . I think it 's {disfmarker} I would guess , uh , point seven , point eight seconds f uh , R T
Turn 98, F (Grad): Hmm !
Turn 99, B (Professor): something like that ? But it 's {disfmarker} you know , it 's this room .
Turn 100, G (PhD): Mm - hmm .
Turn 101, B (Professor): So .
Turn 102, G (PhD): OK . Mm - hmm .
Turn 103, B (Professor): Uh . But the other thing is , he 's putting in {disfmarker} w I was using the word " reverberation " in two ways . He 's also putting in , uh , a {disfmarker} he 's taking out some reverberation , but he 's putting in something , because he has {pause} averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . And since , you know , what you subtract , sometimes you 'll be {disfmarker} you 'll be subtracting from some larger number and sometimes you won't . And {disfmarker}
Turn 104, G (PhD): Mm - hmm . Mm - hmm .
Turn 105, B (Professor): So you can end up with some components in it that are affected by things that are seconds away . Uh , and if it 's a low {pause} energy compo portion , you might actually hear some {pause} funny things .
Turn 106, G (PhD): Yeah .
Turn 107, E (Grad): O o one thing , um , I noticed is that , um , the mean subtraction seems to make the PZM signals louder after they 've been re - synthesized . So I was wondering , is it possible that one reason it helped with the Aurora baseline system is {pause} just as a kind of gain control ? Cuz some of the PZM signals sound pretty quiet if you don't amplify them .
Turn 108, C (PhD): Mm - hmm . I don't see why {disfmarker} why your signal is louder after processing , because yo
Turn 109, E (Grad): Yeah . I don't know why - y , uh , either .
Turn 110, C (PhD): Yeah .
Turn 111, B (Professor): I don't think just multiplying the signal by two would have any effect .
Turn 112, C (PhD): Mm - hmm .
Turn 113, E (Grad): Oh , OK .
Turn 114, B (Professor): Yeah . I mean , I think if you really have louder signals , what you mean is that you have {pause} better signal - to - noise ratio .
Turn 115, C (PhD): Well , well {disfmarker}
Turn 116, B (Professor): So if what you 're doing is improving the signal - to - noise ratio , then it would be better .
Turn 117, C (PhD): Mm - hmm .
Turn 118, B (Professor): But just it being bigger if {disfmarker} with the same signal - to - noise ratio {disfmarker}
Turn 119, E (Grad): It w i i it wouldn't affect things .
Turn 120, B (Professor): No .
Turn 121, C (PhD): Yeah .
Turn 122, E (Grad): OK .
Turn 123, C (PhD): Well , the system is {disfmarker} use {pause} the absolute energy , so it 's a little bit dependent on {disfmarker} on the {pause} signal level . But , not so much , I guess .
Turn 124, B (Professor): Well , yeah . But it 's trained and tested on the same thing .
Turn 125, C (PhD): Mmm .
Turn 126, B (Professor): So if the {disfmarker} if the {disfmarker} if you change {vocalsound} in both training and test , the absolute level by a factor of two , it will n have no effect .
Turn 127, C (PhD): Mm - hmm . Yeah .
Turn 128, A (PhD): Did you add {pause} this data to the training set , for the Aurora ? Or you just tested on this ?
Turn 129, E (Grad): Uh {disfmarker} Um . Did I w what ?
Turn 130, A (PhD): Well , Morgan was just saying that , uh , as long as you do it in both training and testing , it shouldn't have any effect .
Turn 131, E (Grad): Sorry ? Yeah .
Turn 132, A (PhD): But I {disfmarker} I was {pause} sort of under the impression that you just tested with this data .
Turn 133, E (Grad): I {disfmarker} I b
Turn 134, A (PhD): You didn't {pause} train it also .
Turn 135, E (Grad): I {disfmarker} Right . I trained on clean TI - digits . I {disfmarker} I did the mean subtraction on clean TI - digits . But I didn't {disfmarker} I 'm not sure if it made the clean ti TI - digits any louder .
Turn 136, B (Professor): Oh , I see .
Turn 137, E (Grad): I only remember noticing it made the , um , PZM signal louder .
Turn 138, B (Professor): OK . Well , I don't understand then . Yeah .
Turn 139, E (Grad): Huh . I don't know . If it 's {disfmarker} if it 's {disfmarker} like , if it 's trying to find a {disfmarker} a reverberation filter , it could be that this reverberation filter is making things quieter . And then if you take it out {disfmarker} that taking it out makes things louder . I mean .
Turn 140, B (Professor): Uh , no . I mean , {vocalsound} uh , there 's {disfmarker} there 's nothing inherent about removing {disfmarker} if you 're really removing ,
Turn 141, E (Grad): Nuh - huh .
Turn 142, B (Professor): uh , r uh , then I don't {pause} see how that would make it louder .
Turn 143, E (Grad): The mean . OK . Yeah , I see .
Turn 144, B (Professor): So it might be just some {disfmarker}
Turn 145, E (Grad): Yeah . OK . So I should maybe listen to that stuff again .
Turn 146, B (Professor): Yeah . It might just be some artifact of the processing that {disfmarker} that , uh , if you 're {disfmarker} Uh , yeah . I don't know .
Turn 147, E (Grad): Oh . OK .
Turn 148, A (PhD): I wonder if there could be something like , uh {disfmarker} for s for the PZM data ,
Turn 149, C (PhD): Eh
Turn 150, A (PhD): uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . Uh . I 'm just wondering if there 's something about the , um {disfmarker} you know , doing the mean normalization where , uh , it {disfmarker} it could cause {pause} you to have better signal - to - noise ratio . Um .
Turn 151, B (Professor): Well , you know , there is this . Wait a minute . It {disfmarker} it {disfmarker} i maybe {disfmarker} i If , um {disfmarker} Subtracting the {disfmarker} the mean log spectrum is {disfmarker} is {disfmarker} is like dividing by the spectrum . So , depending what you divide by , if your {disfmarker} if s your estimate is off and sometimes you 're {disfmarker} you 're {disfmarker} you 're getting a small number , you could make it bigger .
Turn 152, A (PhD): Mm - hmm .
Turn 153, E (Grad): Mm - hmm .
Turn 154, B (Professor): So , it 's {disfmarker} it 's just a {disfmarker} a question of {disfmarker} there 's {disfmarker} It {disfmarker} it could be that there 's some normalization that 's missing , or something to make it {disfmarker}
Turn 155, E (Grad): Mm - hmm .
Turn 156, B (Professor): Uh , y you 'd think it shouldn't be larger , but maybe in practice it is . That 's something to think about .
Turn 157, E (Grad): Hmm .
Turn 158, B (Professor): I don't know .
Turn 159, C (PhD): I had a question about the system {disfmarker} the SRI system . So , {vocalsound} you trained it on TI - digits ? But except this , it 's exactly the same system as the one that was tested before and that was trained on {pause} Macrophone . Right ? So on TI - digits it gives you one point two percent error rate and on Macrophone it 's still O point eight . Uh , but is it {pause} exactly the same system ?
Turn 160, E (Grad): Uh . I think so .
Turn 161, C (PhD): Hmm .
Turn 162, E (Grad): If you 're talking about the Macrophone results that Andreas had about , um , a week and a half ago , I think it 's the same system .
Turn 163, C (PhD): Mm - hmm . So you use VTL - uh , vocal tract length normalization and , um , like MLLR transformations also ,
Turn 164, E (Grad): Mm - hmm .
Turn 165, C (PhD): and {disfmarker}
Turn 166, B (Professor): I 'm sorry , was his point eight percent , er , a {disfmarker} a result on testing on Macrophone or {disfmarker} or training ?
Turn 167, C (PhD): all that stuff .
Turn 168, E (Grad): That 's {disfmarker}
Turn 169, C (PhD): It was {pause} training on Macrophone and testing {disfmarker} yeah , on {disfmarker} on meeting digits .
Turn 170, B (Professor): Oh . So that was done already . So we were {disfmarker} Uh , and it 's point eight ? OK .
Turn 171, C (PhD): Mm - hmm .
Turn 172, B (Professor): OK .
Turn 173, C (PhD): Yeah . I {disfmarker} I 've just been text {comment} testing the new {pause} Aurora front - end with {disfmarker} well , Aurora system actually {disfmarker} so front - end and HTK , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . We have {disfmarker} I have two point seven percent error rate . And before with the system that was proposed , it 's what ? It was three point nine . So .
Turn 174, B (Professor): Oh , that 's a lot better .
Turn 175, C (PhD): We are getting better .
Turn 176, B (Professor): So , what {disfmarker} w ?
Turn 177, C (PhD): And {disfmarker}
Turn 178, G (PhD): With the {disfmarker} with the HTK back - end ? What we have for Aurora ?
Turn 179, C (PhD): Yeah . Two point seven .
Turn 180, G (PhD): I know in the meeting , like {disfmarker}
Turn 181, C (PhD): On the meeting we have two point seven .
Turn 182, G (PhD): Right . Oh .
Turn 183, F (Grad): That 's with the new IIR filters ?
Turn 184, C (PhD): Uh . Yeah , yeah . So , yeah ,
Turn 185, F (Grad): OK .
Turn 186, C (PhD): we have {pause} the new LDA filters , and {disfmarker} I think , maybe {disfmarker} I didn't look , but one thing that makes a difference is this DC offset compensation . Uh , eh {disfmarker} Do y did you have a look at {disfmarker} at the meet uh , meeting digits , if they have a DC component , or {disfmarker} ?
Turn 187, E (Grad): I {disfmarker} I didn't . No .
Turn 188, C (PhD): Oh .
Turn 189, B (Professor): Hmm .
Turn 190, G (PhD): No . The DC component could be negligible . I mean , if you are {pause} recording it through a mike . I mean , any {disfmarker} all of the mikes have the DC removal {disfmarker} some capacitor sitting right in {pause} that bias it .
Turn 191, B (Professor): Yeah . But this {disfmarker} uh , uh , uh , no . Because , uh , there 's a sample and hold in the A - toD. And these period these typically do have a DC offset .
Turn 192, G (PhD): Oh , OK .
Turn 193, B (Professor): And {disfmarker} and they can be surprisingly large . It depends on the electronics .
Turn 194, G (PhD): Oh , so it is the digital {disfmarker} OK . It 's the A - toD that introduces the DC in .
Turn 195, B (Professor): Yeah . The microphone isn't gonna pass any DC .
Turn 196, G (PhD): Yeah . Yeah . Yeah .
Turn 197, B (Professor): But {disfmarker} but ,
Turn 198, G (PhD): OK .
Turn 199, B (Professor): typi you know , unless {disfmarker} Actually , there are {pause} instrumentation mikes that {disfmarker} that do pass {disfmarker} go down to DC . But {disfmarker} but ,
Turn 200, G (PhD): Mm - hmm .
Turn 201, B (Professor): uh , no , it 's the electronics . And they {disfmarker} and {disfmarker}
Turn 202, G (PhD): Mm - hmm .
Turn 203, B (Professor): then there 's amplification afterwards . And you can get , I think it was {disfmarker} I think it was in the {pause} Wall Street Journal data that {disfmarker} that {disfmarker} I can't remember , one of the DARPA things . There was this big DC - DC offset
Turn 204, A (PhD): Mm - hmm .
Turn 205, B (Professor): we didn't {disfmarker} we didn't know about for a while , while we were {pause} messing with it . And we were getting these terrible results . And then we were talking to somebody and they said , " Oh , yeah . Didn't you know ? Everybody knows that . There 's all this DC offset in th " So , yes . You can have DC offset in the data .
Turn 206, G (PhD): Oh , OK .
Turn 207, B (Professor): Yeah .
Turn 208, G (PhD): OK .
Turn 209, A (PhD): So was that {disfmarker} was that everything , Dave ?
Turn 210, E (Grad): Oh . And I also , um , did some experiments {pause} about normalizing the phase . Um . So I c I came up with a web page that people can take a look at . And , um , the interesting thing that I tried was , um , Adam and Morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , didn't work . Um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . They {disfmarker} they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum wasn't really {pause} mathematically correct . So , {vocalsound} what I did instead is I {vocalsound} took the mean of the FFT spectrum without taking the log or anything , and then I took the phase of that , and I subtracted that phase {pause} off to normalize . But that , um , didn't work either .
Turn 211, B (Professor): See , we have a different interpretation of this . He says it doesn't work . I said , I think it works magnificently , but just not for the task we intended . Uh , it gets rid of the speech .
Turn 212, A (PhD): What does it leave ?
Turn 213, F (Grad): Uh , gets rid of the speech .
Turn 214, B (Professor): Uh , it leaves {disfmarker} you know , it leaves the junk . I mean , I {disfmarker} I think it 's {disfmarker} it 's tremendous .
Turn 215, F (Grad): Oh , wow .
Turn 216, B (Professor): You see , all he has to do is go back and reverse what he did before , and he 's really got something .
Turn 217, A (PhD): Well , could you take what was left over and then subtract that ?
Turn 218, B (Professor): Ex - exactly . Yeah , you got it .
Turn 219, F (Grad): Yeah .
Turn 220, G (PhD): Yeah .
Turn 221, B (Professor): So , it 's {disfmarker} it 's a general rule .
Turn 222, G (PhD): Oh , it 's {disfmarker}
Turn 223, B (Professor): Just listen very carefully to what I say and do the opposite . Including what I just said .
Turn 224, E (Grad): And , yeah , that 's everything .
Turn 225, A (PhD): All set ? Do you want to go , Stephane ?
Turn 226, C (PhD): Um . Yeah . Maybe , concerning these d still , these meeting digits . I 'm more interested in trying to figure out what 's still the difference between the SRI system and the Aurora system . And {disfmarker} Um . Yeah . So , I think I will maybe train , like , gender - dependent models , because {pause} this is also one big difference between {pause} the two systems . Um , the other differences were {pause} the fact that maybe the acoustic models of the SRI are more {disfmarker} SRI system are more complex . But , uh , Chuck , you did some experiments with this and
Turn 227, A (PhD): It didn't seem to help in the HTK system .
Turn 228, C (PhD): it was hard t to {disfmarker} to have some exper some improvement with this . Um .
Turn 229, B (Professor): Well , it sounds like they also have {disfmarker} he {disfmarker} he 's saying they have all these , uh , uh , different kinds of adaptation .
Turn 230, C (PhD): Mm - hmm .
Turn 231, B (Professor): You know , they have channel adaptation . They have speaker adaptation .
Turn 232, C (PhD): Yeah . Right .
Turn 233, A (PhD): Well , there 's also the normalization .
Turn 234, B (Professor): Yeah . Yeah .
Turn 235, C (PhD): Yeah .
Turn 236, F (Grad): Yeah .
Turn 237, A (PhD): Like they do , um {disfmarker} I 'm not sure how they would do it when they 're working with the digits ,
Turn 238, C (PhD): The vocal tr
Turn 239, A (PhD): but , like , in the Switchboard data , there 's , um {disfmarker} conversation - side normalization for the {pause} non - C - zero components ,
Turn 240, C (PhD): Yeah . Yeah . This is another difference . Their normalization works like on {disfmarker} on the utterance levels .
Turn 241, A (PhD): Mm - hmm .
Turn 242, C (PhD): But we have to do it {disfmarker} We have a system that does it on - line .
Turn 243, A (PhD): Right .
Turn 244, C (PhD): So , it might be {disfmarker} it might be better with {disfmarker} it might be worse if the {pause} channel is constant ,
Turn 245, A (PhD): Yeah .
Turn 246, C (PhD): or {disfmarker} Nnn .
Turn 247, G (PhD): And the acoustic models are like - k triphone models or {disfmarker} or is it the whole word ?
Turn 248, C (PhD): SRI {disfmarker} it 's {disfmarker} it 's tr
Turn 249, F (Grad): SRI .
Turn 250, G (PhD): Yeah .
Turn 251, C (PhD): Yeah . I guess it 's triphones .
Turn 252, G (PhD): It 's triphone .
Turn 253, B (Professor): I think it 's probably more than that .
Turn 254, C (PhD): Huh .
Turn 255, B (Professor): I mean , so they {disfmarker} they have {disfmarker} I {disfmarker} I thin think they use these , uh , uh , genone things . So there 's {disfmarker} there 's these kind of , uh , uh , pooled models and {disfmarker} and they can go out to all sorts of dependencies .
Turn 256, G (PhD): Oh . It 's like the tied state .
Turn 257, B (Professor): So .
Turn 258, A (PhD): Mm - hmm .
Turn 259, B (Professor): They have tied states and I think {disfmarker} I {disfmarker} I {disfmarker} I don't real I 'm talk I 'm just guessing here . But I think {disfmarker} I think they {disfmarker} they don't just have triphones .
Turn 260, G (PhD): OK .
Turn 261, B (Professor): I think they have a range of {disfmarker} of , uh , dependencies .
Turn 262, C (PhD): Mm - hmm .
Turn 263, G (PhD): Mm - hmm .
Turn 264, C (PhD): Mm - hmm .
Turn 265, F (Grad): Hmm .
Turn 266, C (PhD): And {disfmarker} Yeah . Well . Um . Well , the first thing I {disfmarker} that I want to do is just maybe these gender things . Uh . And maybe see with {pause} Andreas if {disfmarker} Well , I {disfmarker} I don't know {pause} how much it helps , what 's the model .
Turn 267, A (PhD): So {disfmarker} so the n stuff on the numbers you got , the two point seven , is that using the same training data that the SRI system used and got one point two ?
Turn 268, C (PhD): That 's right . So it 's the clean {pause} TI - digits training set .
Turn 269, A (PhD): So exact same training data ?
Turn 270, C (PhD): Right .
Turn 271, A (PhD): OK .
Turn 272, C (PhD): Mm - hmm . I guess you used the clean training set .
Turn 273, E (Grad): Right .
Turn 274, C (PhD): Mm - hmm .
Turn 275, E (Grad): For {disfmarker} with the SRI system {disfmarker}
Turn 276, C (PhD): Well .
Turn 277, E (Grad): You know , the {disfmarker} the Aurora baseline is set up with these , um {disfmarker} {vocalsound} this version of the clean training set that 's been filtered with this G - seven - one - two filter , and , um , to train the SRI system on digits S - Andreas used the original TI - digits , um , under U doctor - speech data TI - digits , which don't have this filter . But I don't think there 's any other difference .
Turn 278, C (PhD): Mm - hmm . Mm - hmm . Yeah .
Turn 279, B (Professor): So is that {disfmarker} ? Uh , are {disfmarker} are these results comparable ? So you {disfmarker} you were getting with the , uh , Aurora baseline something like two point four percent {pause} on clean TI - digits , when , uh , training the SRI system with clean TR digits {disfmarker} {comment} TI - digits . Right ? And {disfmarker}
Turn 280, E (Grad): Um . Uh - huh .
Turn 281, B (Professor): Yeah . And , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ?
Turn 282, C (PhD): Yeah . I think so .
Turn 283, B (Professor): OK .
Turn 284, C (PhD): Yeah .
Turn 285, B (Professor): So it 's {pause} about the same ,
Turn 286, C (PhD): Mm - hmm .
Turn 287, B (Professor): maybe a little worse .
Turn 288, E (Grad): W w it was one {disfmarker} one point two
Turn 289, C (PhD): Ye
Turn 290, E (Grad): with the SRI system ,
Turn 291, B (Professor): I 'm sorry .
Turn 292, C (PhD): Yeah .
Turn 293, E (Grad): I {disfmarker}
Turn 294, C (PhD): The complete SRI system is one point two .
Turn 295, B (Professor): You {disfmarker} you were HTK .
Turn 296, C (PhD): Yeah .
Turn 297, B (Professor): Right ? OK . That 's right . So {disfmarker}
Turn 298, C (PhD): Mm - hmm .
Turn 299, B (Professor): OK , so {pause} the comparable number then , uh {pause} for what you were talking about then , since it was HTK , would be the {pause} um , two point f
Turn 300, C (PhD): It was four point something . Right ? The HTK system with , uh , b
Turn 301, E (Grad): D d
Turn 302, B (Professor): Oh , right , right , right , right .
Turn 303, C (PhD): MFCC features {disfmarker}
Turn 304, E (Grad): Do you mean the b ? The baseline Aurora - two system , trained on TI - digits , tested on Meeting Recorder near , I think we saw in it today , and it was about six point six percent .
Turn 305, B (Professor): Right . Right , right , right .
Turn 306, C (PhD): Oh .
Turn 307, B (Professor): OK . Alright . So {disfmarker} He 's doing some {pause} different things .
Turn 308, C (PhD): So {disfmarker} Yeah . The only difference is the features , right now , between this and {disfmarker}
Turn 309, B (Professor): Yes . OK , good . So they are helping .
Turn 310, C (PhD): Mm - hmm .
Turn 311, B (Professor): That 's good to hear . Yeah .
Turn 312, C (PhD): They are helping . Yeah . Um . Yeah . And another thing I {disfmarker} I maybe would like to do is to {pause} just test the SRI system that 's trained on Macrophone {disfmarker} test it on , uh , the noisy TI - digits ,
Turn 313, B (Professor): Yeah .
Turn 314, C (PhD): cuz I 'm still wondering {pause} where this {pause} improvement comes from . When you train on Macrophone , it seems better on meeting digits . But I wonder if it 's just because maybe {pause} Macrophone is acoustically closer to the meeting digits than {disfmarker} than TI - digit is , which is {disfmarker} TI - digits are very {pause} clean recorded digits
Turn 315, B (Professor): Mm - hmm .
Turn 316, C (PhD): and {disfmarker}
Turn 317, A (PhD): You know , it would also be interesting to see , uh {disfmarker} to do the regular Aurora test ,
Turn 318, C (PhD): Uh , f s
Turn 319, A (PhD): um , but use the SRI system instead of HTK .
Turn 320, C (PhD): That 's {disfmarker} Yeah . That 's what {pause} I wanted , just , uh {disfmarker} Yeah . So , just using the SRI system , test it on {disfmarker} and test it on {pause} Aurora TI - digits . Right .
Turn 321, A (PhD): Why not the full Aurora , uh , test ?
Turn 322, C (PhD): Um . Yeah . There is this problem of multilinguality yet .
Turn 323, A (PhD): Mm - hmm .
Turn 324, C (PhD): So we don't {disfmarker}
Turn 325, B (Professor): You 'd have to train the SRI system with {disfmarker} with all the different languages .
Turn 326, C (PhD): i i
Turn 327, A (PhD): Right .
Turn 328, C (PhD): We would have to train on {disfmarker}
Turn 329, A (PhD): Yeah . That 's what I mean .
Turn 330, C (PhD): Yeah .
Turn 331, A (PhD): So , like , comple
Turn 332, B (Professor): It 'd be a {pause} lot of work . That 's the only thing .
Turn 333, C (PhD): Yeah .
Turn 334, A (PhD): Mmm .
Turn 335, C (PhD): It 's {disfmarker}
Turn 336, A (PhD): Well , I mean ,
Turn 337, C (PhD): Mmm .
Turn 338, A (PhD): uh , uh , I guess the work would be into getting the {disfmarker} the files in the right formats , or something . Right ? I mean {disfmarker}
Turn 339, C (PhD): Mm - hmm .
Turn 340, A (PhD): Because when you train up the Aurora system , you 're , uh {disfmarker} you 're also training on all the data .
Turn 341, C (PhD): That 's right .
Turn 342, A (PhD): I mean , it 's {disfmarker}
Turn 343, C (PhD): Yeah . Yeah . I see . Oh , so , OK . Right . I see what you mean .
Turn 344, B (Professor): That 's true , but I think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things
Turn 345, A (PhD): Mm - hmm .
Turn 346, B (Professor): because {disfmarker} on {disfmarker} on whatever it is they 're trying , because it 's a lot of work , even just with the HTK .
Turn 347, A (PhD): Mm - hmm .
Turn 348, B (Professor): So , it 's {disfmarker} it 's a good idea , but it seems like {pause} it makes sense to do some pruning
Turn 349, A (PhD): Mm - hmm .
Turn 350, B (Professor): first with a {disfmarker} a test or two that makes sense for you ,
Turn 351, A (PhD): Yeah .
Turn 352, B (Professor): and then {pause} take the likely candidates and go further .
Turn 353, A (PhD): Yeah .
Turn 354, C (PhD): Mm - hmm . Yeah . But , just testing on TI - digits would already give us some information {pause} about what 's going on . And {disfmarker} mm - hmm . Uh , yeah . OK . Uh , the next thing is this {disfmarker} this VAD problem that , um , um {disfmarker} So , I 'm just talking about the {disfmarker} the curves that I {disfmarker} I sent {disfmarker} {vocalsound} I sent you {disfmarker} so , whi that shows that {vocalsound} when the SNR decrease , {vocalsound} uh , the current {pause} VAD approach doesn't drop much frames {pause} for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically .
Turn 355, B (Professor): I i Just to clarify something for me . I They were supp Supposedly , in the next evaluation , they 're going to be supplying us with boundaries .
Turn 356, C (PhD): Mm - hmm .
Turn 357, B (Professor): So does any of this matter ? I mean , other than our interest in it . Uh {disfmarker}
Turn 358, C (PhD): Uh {disfmarker} Well . First of all , the boundaries might be , uh {disfmarker} like we would have t two hundred milliseconds or {disfmarker} before and after speech . Uh . So removing more than that might still make {pause} a difference {pause} in the results .
Turn 359, B (Professor): Do we {disfmarker} ? I mean , is there some reason that we think that 's the case ?
Turn 360, C (PhD): And {disfmarker} No . Because we don't {disfmarker} didn't looked {pause} that much at that .
Turn 361, B (Professor): Yeah .
Turn 362, C (PhD): But , {vocalsound} still , I think it 's an interesting problem .
Turn 363, B (Professor): Oh , yeah .
Turn 364, C (PhD): And {disfmarker} Um . Yeah .
Turn 365, B (Professor): But maybe we 'll get some insight on that when {disfmarker} when , uh , the gang gets back from Crete . Because {pause} there 's lots of interesting problems , of course .
Turn 366, C (PhD): Mm - hmm .
Turn 367, B (Professor): And then the thing is if {disfmarker} if they really are going to have some means of giving us {pause} fairly tight , uh , boundaries , then that won't be so much the issue .
Turn 368, C (PhD): Yeah , yeah . Mm - hmm . Mm - hmm .
Turn 369, B (Professor): Um But {vocalsound} I don't know .
Turn 370, G (PhD): Because w we were wondering whether that {pause} VAD is going to be , like , a realistic one or is it going to be some manual segmentation . And then , like , if {disfmarker} if that VAD is going to be a realistic one , then we can actually use their markers to shift the point around , I mean , the way we want
Turn 371, B (Professor): Mm - hmm .
Turn 372, G (PhD): to find a {disfmarker} I mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more {pause} suitable for us .
Turn 373, B (Professor): Right .
Turn 374, G (PhD): But if that is going to be something like a manual , uh , segmenter , then we can't {pause} use that information anymore ,
Turn 375, C (PhD): Mm - hmm .
Turn 376, G (PhD): because that 's not going to be the one that is used in the final evaluation .
Turn 377, B (Professor): Right .
Turn 378, G (PhD): So . We don't know what is the type of {pause} {vocalsound} {pause} VAD which they 're going to provide .
Turn 379, B (Professor): Yeah .
Turn 380, C (PhD): Yeah . And actually there 's {disfmarker} Yeah . There 's an {disfmarker} uh , I think it 's still for {disfmarker} even for the evaluation , uh , it might still be interesting to {vocalsound} work on this because {pause} the boundaries apparently that they would provide is just , {vocalsound} um , starting of speech and end of speech {pause} uh , at the utterance level . And {disfmarker} Um .
Turn 381, G (PhD): With some {disfmarker} some gap .
Turn 382, C (PhD): So {disfmarker}
Turn 383, G (PhD): I mean , with some pauses in the center , provided they meet that {disfmarker} whatever the hang - over time which they are talking .
Turn 384, C (PhD): Yeah . But when you have like , uh , five or six frames , both {disfmarker}
Turn 385, G (PhD): Yeah . Then the they will just fill {disfmarker} fill it up .
Turn 386, C (PhD): it {disfmarker} it {disfmarker} with {disfmarker}
Turn 387, G (PhD): I mean , th {disfmarker} Yeah .
Turn 388, C (PhD): Yeah .
Turn 389, B (Professor): So if you could get at some of that , uh {disfmarker}
Turn 390, C (PhD): So {disfmarker}
Turn 391, B (Professor): although that 'd be hard .
Turn 392, C (PhD): Yeah . It might be useful for , like , noise estimation , and a lot of other {pause} things that we want to work on .
Turn 393, B (Professor): But {disfmarker} but {disfmarker} Yeah .
Turn 394, G (PhD): Yeah .
Turn 395, B (Professor): Right . OK .
Turn 396, C (PhD): But {disfmarker} Mmm . Yeah . So I did {disfmarker} I just {pause} started to test {pause} putting together two VAD which was {disfmarker} was not much work actually . Um , I im re - implemented a VAD that 's very close to the , {vocalsound} um , energy - based VAD {vocalsound} that , uh , the other Aurora guys use . Um . So , which is just putting a threshold on {pause} the noise energy ,
Turn 397, B (Professor): Mm - hmm .
Turn 398, C (PhD): and , detect detecting the first {pause} group of four frames {pause} that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . So it removes {vocalsound} the first silent portion {disfmarker} portion of each utterance . And it really removes it , um , still o on the noises where {pause} our MLP VAD doesn't {pause} work a lot .
Turn 399, B (Professor): Mmm .
Turn 400, C (PhD): Uh ,
Turn 401, B (Professor): Cuz I would have thought that having some kind of spectral {pause} information ,
Turn 402, C (PhD): and {disfmarker}
Turn 403, B (Professor): uh {disfmarker} uh , you know , in the old days people would use energy and zero crossings , for instance {disfmarker} uh , would give you some {pause} better performance . Right ? Cuz you might have low - energy fricatives or {disfmarker} or , uh {pause} stop consonants , or something like that .
Turn 404, C (PhD): Mm - hmm .
Turn 405, B (Professor): Uh .
Turn 406, C (PhD): Yeah . So , your point is {disfmarker} will be to u use whatever {disfmarker}
Turn 407, B (Professor): Oh , that if you d if you use purely energy and don't look at anything spectral , then you don't have a good way of distinguishing between low - energy speech components and {pause} nonspeech . And , um ,
Turn 408, C (PhD): Mm - hmm .
Turn 409, B (Professor): just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . And {disfmarker} and most , um , low - energy speech components that are unvoiced have a {disfmarker} a high - pass kind of characteristic {disfmarker}
Turn 410, C (PhD): Mm - hmm .
Turn 411, B (Professor): an upward slope . So having some kind of a {disfmarker}
Turn 412, C (PhD): Yeah .
Turn 413, B (Professor): uh , you know , at the beginning of a {disfmarker} of a {disfmarker} of an S sound for instance , just starting in , it might be pretty low - energy ,
Turn 414, C (PhD): Mm - hmm .
Turn 415, B (Professor): but it will tend to have this high - frequency component . Whereas , {vocalsound} a {disfmarker} a lot of rumble , and background noises , and so forth will be predominantly low - frequency . Uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of {disfmarker}
Turn 416, C (PhD): Yeah .
Turn 417, B (Professor): it plus energy plus timing information is sort of {disfmarker}
Turn 418, C (PhD): Mm - hmm .
Turn 419, B (Professor): I mean , if you look up in Rabiner and Schafer from like twenty - five years ago or something , that 's sort of {pause} what they were using then .
Turn 420, C (PhD): Mm - hmm .
Turn 421, B (Professor): So it 's {disfmarker} it 's not a {disfmarker}
Turn 422, C (PhD): Mm - hmm .
Turn 423, F (Grad): Hmm .
Turn 424, C (PhD): So , yeah . It {disfmarker} it might be that what I did is {disfmarker} so , removes like {vocalsound} low , um , {vocalsound} uh {disfmarker} low - energy , uh , speech frames . Because {pause} the way I do it is I just {disfmarker} I just combine the two decisions {disfmarker} so , the one from the MLP and the one from the energy - based {disfmarker} with the {disfmarker} with the and {pause} operator . So , I only {pause} keep the frames where the two agree {pause} that it 's speech . So if the energy - based dropped {disfmarker} dropped low - energy speech , mmm , they {disfmarker} they are {disfmarker} they are lost . Mmm .
Turn 425, B (Professor): Mm - hmm .
Turn 426, C (PhD): But s still , the way it 's done right now it {disfmarker} it helps on {disfmarker} on the noises where {disfmarker} it seems to help on the noises where {vocalsound} our VAD was not very {pause} good .
Turn 427, B (Professor): Well , I guess {disfmarker} I mean , one could imagine combining them in different ways . But {disfmarker} but , I guess what you 're saying is that the {disfmarker} the MLP - based one has the spectral information . So .
Turn 428, C (PhD): Yeah . But {disfmarker} Yeah . But the way it 's combined wi is maybe done {disfmarker} Well , yeah .
Turn 429, B (Professor): Well , you can imagine {disfmarker}
Turn 430, C (PhD): The way I use a an a " AND " operator is {disfmarker} So , it {disfmarker} I , uh {disfmarker}
Turn 431, B (Professor): Is {disfmarker} ?
Turn 432, C (PhD): The frames that are dropped by the energy - based system are {disfmarker} are , uh , dropped , even if the , um , MLP decides to keep them .
Turn 433, B (Professor): Right . Right . And that might not be optimal ,
Turn 434, C (PhD): But , yeah .
Turn 435, B (Professor): but {disfmarker}
Turn 436, C (PhD): Mm - hmm .
Turn 437, A (PhD): No
Turn 438, B (Professor): but {disfmarker} I mean , I guess in principle what you 'd want to do is have a {disfmarker} {vocalsound} uh , a probability estimated by each one and {disfmarker} and put them together .
Turn 439, C (PhD): Yeah . Mmm . M Yeah .
Turn 440, A (PhD): Something that {disfmarker} that I 've used in the past is , um {disfmarker} when just looking at the energy , is to look at the derivative . And you {pause} make your decision when the derivative is increasing for {pause} so many frames . Then you say that 's beginning of speech .
Turn 441, C (PhD): Uh - huh .
Turn 442, A (PhD): But , I 'm {disfmarker} I 'm trying to remember if that requires that you keep some amount of speech in a buffer . I guess it depends on how you do it . But {pause} I mean , that 's {disfmarker} that 's been a useful thing .
Turn 443, B (Professor): Yeah .
Turn 444, C (PhD): Mm - hmm .
Turn 445, F (Grad): Mm - hmm .
Turn 446, G (PhD): Yeah . Well , every everywhere has a delay associated with it . I mean , you still have to k always keep a buffer ,
Turn 447, A (PhD): Mm - hmm .
Turn 448, G (PhD): then only make a decision because {pause} you still need to smooth the {pause} decision further .
Turn 449, A (PhD): Right . Right .
Turn 450, G (PhD): So that 's always there .
Turn 451, A (PhD): Yeah . OK .
Turn 452, C (PhD): Well , actually if I don't {disfmarker} maybe don't want to work too much of {disfmarker} on it right now . I just wanted to {disfmarker} to see if it 's {disfmarker} {vocalsound} what I observed was the re was caused by this {disfmarker} this VAD problem .
Turn 453, B (Professor): Mm - hmm .
Turn 454, C (PhD): And it seems to be the case . Um . Uh , the second thing is the {disfmarker} this spectral subtraction . Um . Um , which I 've just started yesterday to launch a bunch of , uh , {nonvocalsound} twenty - five experiments , uh , with different , uh , values for the parameters that are used . So , it 's the Makhoul - type spectral subtraction which use {pause} an over - estimation factor . So , we substr I subtract more , {vocalsound} {vocalsound} um , {nonvocalsound} {vocalsound} noise than the noise spectra that {pause} is estimated {pause} on the noise portion of the s uh , the utterances . So I tried several , uh , over - estimation factors . And after subtraction , I also add {pause} a constant noise , and I also try different , uh , {vocalsound} noise , uh , values and we 'll see what happen .
Turn 455, B (Professor): Hmm . OK .
Turn 456, C (PhD): Mm - hmm . Mm - hmm . But st still when we look at the , um {disfmarker} Well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . Um . On the other hand , when you {pause} subtract more and when you add more noise , you get rid of this musical noise but {pause} maybe you distort a lot of speech . So . Well . Mmm . Well , it {disfmarker} until now , it doesn't seem to help . But We 'll see . So the next thing , maybe I {disfmarker} what I will {pause} try to {disfmarker} to do is just {pause} to try to smooth mmm , {vocalsound} the , um {disfmarker} to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or {disfmarker}
Turn 457, G (PhD): Can smooth the SNR estimate , also .
Turn 458, C (PhD): Yeah . Right . Mmm .
Turn 459, G (PhD): Your filter is a function of SNR . Hmm ?
Turn 460, C (PhD): Yeah . So , to get something that 's {disfmarker} would be closer to {pause} what you tried to do with Wiener filtering .
Turn 461, G (PhD): Yeah .
Turn 462, C (PhD): And {disfmarker} Mm - hmm . Yeah .
Turn 463, G (PhD): Actually , it 's , uh {disfmarker} Uh . I don't know , it 's {disfmarker} go ahead .
Turn 464, C (PhD): It {disfmarker}
Turn 465, G (PhD): And it 's {disfmarker}
Turn 466, C (PhD): Maybe you can {disfmarker}
Turn 467, G (PhD): go ahead .
Turn 468, C (PhD): I think it 's {disfmarker} That 's it for me .
Turn 469, G (PhD): OK . So , uh {disfmarker} u th I 've been playing with this Wiener filter , like . And there are {disfmarker} there were some bugs in the program , so I was p initially trying to clear them up . Because one of the bug was {disfmarker} I was assuming that always the VAD {disfmarker} uh , the initial frames were silence . It always started in the silence state , but it wasn't for some utterances . So the {disfmarker} it wasn't estimating the noise initially , and then it never estimated , because I assumed that it was always silence .
Turn 470, C (PhD): Mm - hmm . So this is on SpeechDat - Car Italian ?
Turn 471, G (PhD): Yeah .
Turn 472, C (PhD): So , in some cases s there are also {disfmarker}
Turn 473, G (PhD): SpeechDat - Car Italian . Yeah . There 're a few cases , actually , which I found later , that there are .
Turn 474, C (PhD): o Uh - huh .
Turn 475, G (PhD): So that was one of the {pause} bugs that was there in estimating the noise . And , uh , so once it was cleared , uh , I ran a few experiments with {pause} different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the SNR also . And so the {disfmarker} the trend seems to be like , {vocalsound} uh , smoothing the {pause} current estimate of the clean speech for deriving the SNR , which is like {pause} deriving the Wiener filter , seems to be helping . Then updating it quite fast using a very small time constant . So we 'll have , like , a few results where the {disfmarker} estimating the {disfmarker} the {disfmarker} More smoothing is helping . But still it 's like {disfmarker} it 's still comparable to the baseline . I haven't got anything beyond the baseline . But that 's , like , not using any Wiener filter . And , uh , so I 'm {disfmarker} I 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing SNR . So there are three time constants that I have . So , I 'm just playing around . So , one is fixed in the line , like {pause} Smoothing the clean speech is {disfmarker} is helping , so I 'm not going to change it that much . But , the way I 'm estimating the noise and the way I 'm estimating the SNR , I 'm just trying {disfmarker} trying a little bit . So , that h And the other thing is , like , putting a floor on the , uh , SNR , because that {disfmarker} if some {disfmarker} In some cases the clean speech is , like {disfmarker} when it 's estimated , it goes to very low values , so the SNR is , like , very low . And so that actually creates a lot of variance in the low - energy region of the speech . So , I 'm thinking of , like , putting a floor also for the SNR so that it doesn't {pause} vary a lot in the low - energy regions . And , uh . So . The results are , like {disfmarker} So far I 've been testing only with the {pause} baseline , which is {disfmarker} which doesn't have any LDA filtering and on - line normalization . I just want to separate the {disfmarker} the contributions out . So it 's just VAD , plus the Wiener filter , plus the baseline system , which is , uh , just the spectral {disfmarker} I mean , the mel sp mel , uh , frequency coefficients . Um . And the other thing that I tried was {disfmarker} but I just {vocalsound} took of those , uh , {pause} {vocalsound} Carlos filters , which Hynek had , to see whether it really h helps or not . I mean , it was just a {disfmarker} a run to see whether it really degrades or it helps . And it 's {disfmarker} it seems to be like it 's not {vocalsound} hurting a lot by just blindly picking up one filter which is nothing but a {pause} four hertz {disfmarker} a band - pass m m filter on the cubic root of the power spectrum . So , that was the filter that Hy - uh , Carlos had . And so {disfmarker} Yeah . Just {disfmarker} just to see whether it really {disfmarker} it 's {disfmarker} it 's {disfmarker} is it worth trying or not . So , it doesn't seems to be degrading a lot on that . So there must be something that I can {disfmarker} that can be done with that type of noise compensation also , which {disfmarker} {vocalsound} I guess I would ask Carlos about that . I mean , how {disfmarker} how he derived those filters and {disfmarker} and where d if he has any filters which are derived on OGI stories , added with some type of noise which {disfmarker} what we are using currently , or something like that . So maybe I 'll {disfmarker}
Turn 476, B (Professor): This is cubic root of power spectra ?
Turn 477, G (PhD): Yeah . Cubic root of power spectrum .
Turn 478, B (Professor): So , if you have this band - pass filter , you probably get n you get negative values . Right ?
Turn 479, G (PhD): Yeah . And I 'm , like , floating it to z zeros right now .
Turn 480, B (Professor): OK .
Turn 481, G (PhD): So it has , like {disfmarker} the spectrogram has , like {disfmarker} Uh , it actually , uh , enhances the onset and offset of {disfmarker} I mean , the {disfmarker} the begin and the end of the speech . So it 's {disfmarker} there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions ,
Turn 482, B (Professor): Mm - hmm .
Turn 483, G (PhD): because the filter has , like , a sort of Mexican - hat type structure .
Turn 484, B (Professor): Mm - hmm .
Turn 485, G (PhD): So , those are the regions where there are , like {disfmarker} when I look at the spectrogram , there are those deep valleys on the begin and the end of the speech . But the rest of it seems to be , like , pretty nice .
Turn 486, B (Professor): Mm - hmm .
Turn 487, G (PhD): So . That 's {pause} something I observe using that filter . And {disfmarker} Yeah . There are a few {disfmarker} very {disfmarker} not a lot of {disfmarker} because the filter doesn't have a {disfmarker} really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . So , I 'll {disfmarker} I 'll s may continue with that for some w I 'll {disfmarker} I 'll {disfmarker} Maybe I 'll ask Carlos a little more about how to play with those filters , and {disfmarker} but while {pause} making this Wiener filter better . So . Yeah . That {disfmarker} that 's it , Morgan .
Turn 488, B (Professor): Uh , last week you were also talking about building up the subspace {pause} stuff ?
Turn 489, G (PhD): Yeah . I {disfmarker} I {disfmarker} I would actually m m didn't get enough time to work on the subspace last week . It was mostly about {pause} finding those bugs and
Turn 490, B (Professor): OK .
Turn 491, G (PhD): th you know , things , and I didn't work much on that .
Turn 492, A (PhD): How about you , Carmen ?
Turn 493, D (PhD): Well , I am still working with , eh , VTS . And , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy .
Turn 494, B (Professor): Hmm ?
Turn 495, D (PhD): And , maybe , talking with Stephane and with Sunil , we decide that maybe it was interesting to {disfmarker} to apply on - line normalization before applying VTS . But then {vocalsound} we decided that that 's {disfmarker} it doesn't work absolutely , because we modified also the noise . And {disfmarker} Well , thinking about that , we {disfmarker} we then {disfmarker} we decide that maybe is a good idea . We don't know . I don't hav I don't {disfmarker} this is {disfmarker} I didn't {pause} do the experiment yet {disfmarker} to apply VTS in cepstral domain .
Turn 496, B (Professor): The other thing {pause} is {disfmarker} So {disfmarker} so , in {disfmarker} i i and {disfmarker} Not {disfmarker} and C - zero would be a different {disfmarker} So you could do a different normalization for C - zero than for other things anyway . I mean , the other thing I was gonna suggest is that you could have {pause} two kinds of normalization with {disfmarker} with , uh , different time constants . So , uh , you could do some normalization {vocalsound} s uh , before the VTS , and then do some other normalization after . I don't know . But {disfmarker} but C - zero certainly acts differently than the others do ,
Turn 497, D (PhD): Uh .
Turn 498, B (Professor): so that 's {disfmarker}
Turn 499, C (PhD): Mm - hmm .
Turn 500, D (PhD): Well , we s decide to m to {disfmarker} to obtain the new expression if we work in the cepstral domain . And {disfmarker} Well . I am working in that now ,
Turn 501, B (Professor): Uh - huh .
Turn 502, D (PhD): but {vocalsound} I 'm not sure if that will be usefu useful . I don't know . It 's k it 's k It 's quite a lot {disfmarker} It 's a lot of work .
Turn 503, B (Professor): Uh - huh .
Turn 504, D (PhD): Well , it 's not too much , but this {disfmarker} it 's work .
Turn 505, B (Professor): Yeah .
Turn 506, D (PhD): And I want to know if {disfmarker} if we have some {pause} feeling that {pause} the result {disfmarker} I {disfmarker} I would like to know if {disfmarker} I don't have any feeling if this will work better than apply VTS aft in cepstral domain will work better than apply in m mel {disfmarker} in filter bank domain . I r I 'm not sure . I don't {disfmarker} I don't know absolutely nothing .
Turn 507, C (PhD): Mm - hmm .
Turn 508, B (Professor): Yeah . Well , you 're {disfmarker} I think you 're the first one here to work with VTS , so , uh , maybe we could call someone else up who has , ask them their opinion . Uh ,
Turn 509, C (PhD): Mm - hmm .
Turn 510, B (Professor): I don't {disfmarker} I don't have a good feeling for it . Um .
Turn 511, G (PhD): Pratibha .
Turn 512, C (PhD): Actually , the VTS that you tested before was in the log domain and so {pause} the codebook is e e kind of dependent on the {pause} level of the speech signal .
Turn 513, D (PhD): Yeah ?
Turn 514, C (PhD): And {disfmarker} So I expect it {disfmarker} If {disfmarker} if you have something that 's independent of this , I expect it to {disfmarker} it {disfmarker} to , uh , be a better model of speech .
Turn 515, D (PhD): To have better {disfmarker}
Turn 516, C (PhD): And . Well .
Turn 517, B (Professor): You {disfmarker} you wouldn't even need to switch to cepstra . Right ? I mean , you can just sort of normalize the {disfmarker}
Turn 518, C (PhD): No . We could normali norm I mean , remove the median .
Turn 519, B (Professor): Yeah . Yeah . And then you have {pause} one number which is very dependent on the level cuz it is the level ,
Turn 520, D (PhD): Mm - hmm .
Turn 521, B (Professor): and the other which isn't .
Turn 522, C (PhD): Mm - hmm . Yeah . But here also we would have to be careful about removing the mean {pause} of speech and not of noise .
Turn 523, D (PhD): Ye
Turn 524, C (PhD): Because it 's like {pause} first doing general normalization
Turn 525, D (PhD): Yea
Turn 526, C (PhD): and then noise removal , which is {disfmarker}
Turn 527, D (PhD): Yeah . We {disfmarker} I was thinking to {disfmarker} to {disfmarker} to estimate the noise {pause} with the first frames and then apply the VAD ,
Turn 528, B (Professor): Mm - hmm .
Turn 529, C (PhD): Mm - hmm .
Turn 530, D (PhD): before the on - line normalization .
Turn 531, C (PhD): Mm - hmm .
Turn 532, D (PhD): We {disfmarker} we see {disfmarker} Well , I am thinking {vocalsound} about that and working about that ,
Turn 533, B (Professor): Yeah .
Turn 534, D (PhD): but I don't have result this week .
Turn 535, B (Professor): Sure . I mean , one of the things we 've talked about {disfmarker} maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? Because {pause} we 've talked about potentially doing some combination of a couple of them . Maybe {disfmarker} maybe pretty soon we 'll have some sense of what their {pause} characteristics are ,
Turn 536, D (PhD): Mm - hmm .
Turn 537, B (Professor): so we can see what should be combined .
Turn 538, C (PhD): Mm - hmm .
Turn 539, A (PhD): Is that it ? OK ?
Turn 540, B (Professor): OK . Why don't we read some digits ?
Turn 541, A (PhD): Yep . Want to go ahead , Morgan ?
Turn 542, B (Professor): Sure .
Turn 543, A (PhD): Transcript L dash two one five .
Turn 544, B (Professor): O K .
