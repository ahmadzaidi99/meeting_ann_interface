Turn 0, C (Professor): OK . So uh , he 's not here ,
Turn 1, D (PhD): So .
Turn 2, C (Professor): so you get to {disfmarker}
Turn 3, D (PhD): Yeah , I will try to explain the thing that I did this {disfmarker} this week {disfmarker} during this week .
Turn 4, C (Professor): Yeah .
Turn 5, D (PhD): Well eh you know that I work {disfmarker} I begin to work with a new feature to detect voice - unvoice .
Turn 6, E (PhD): Mm - hmm .
Turn 7, D (PhD): What I trying two MLP to {disfmarker} to the {disfmarker} with this new feature and the fifteen feature uh from the eh bus base system
Turn 8, E (PhD): The {disfmarker} the mel cepstrum ?
Turn 9, D (PhD): No , satly the mes the Mel Cepstrum , the new base system {disfmarker} the new base system .
Turn 10, E (PhD): Oh the {disfmarker}
Turn 11, D (PhD): Yeah , we {disfmarker}
Turn 12, E (PhD): OK , the Aurora system .
Turn 13, D (PhD): yeah the Aurora system with the new filter , VAD or something like that .
Turn 14, E (PhD): OK .
Turn 15, D (PhD): And I 'm trying two MLP , one one that only have t three output , voice , unvoice , and silence ,
Turn 16, C (Professor): Mm - hmm .
Turn 17, D (PhD): and other one that have fifty - six output . The probabilities of the allophone . And I tried to do some experiment of recognition with that and only have result with {disfmarker} with the MLP with the three output . And I put together the fifteen features and the three MLP output . And , well , the result are li a little bit better , but more or less similar .
Turn 18, C (Professor): Uh , I {disfmarker} I 'm {disfmarker} I 'm slightly confused .
Turn 19, E (PhD): Hmm .
Turn 20, C (Professor): What {disfmarker} what feeds the uh {disfmarker} the three - output net ?
Turn 21, D (PhD): Voice , unvoice , and si
Turn 22, C (Professor): No no , what feeds it ? What features does it see ?
Turn 23, D (PhD): The feature {disfmarker} the input ? The inputs are the fifteen {disfmarker} the fifteen uh bases feature .
Turn 24, C (Professor): Uh - huh .
Turn 25, D (PhD): the {disfmarker} with the new code . And the other three features are R , the variance of the difference between the two spectrum ,
Turn 26, C (Professor): Uh - huh .
Turn 27, D (PhD): the variance of the auto - correlation function , except the {disfmarker} the first point , because half the height value is R - zero
Turn 28, C (Professor): Mm - hmm . Mm - hmm . Mm - hmm . Mm - hmm .
Turn 29, D (PhD): and also R - zero , the first coefficient of the auto - correlation function . That is like the energy with these three feature ,
Turn 30, C (Professor): Right .
Turn 31, D (PhD): also these three feature .
Turn 32, C (Professor): You wouldn't do like R - one over R - zero or something like that ? I mean usually for voiced - unvoiced you 'd do {disfmarker} yeah , you 'd do something {disfmarker} you 'd do energy
Turn 33, D (PhD): Yeah .
Turn 34, C (Professor): but then you have something like spectral slope , which is you get like R - one ov over R - zero or something like that .
Turn 35, D (PhD): Uh yeah .
Turn 36, E (PhD): What are the R 's ?
Turn 37, C (Professor): R correlations .
Turn 38, E (PhD): I 'm sorry I missed it .
Turn 39, D (PhD): No , R c No .
Turn 40, E (PhD): Oh .
Turn 41, D (PhD): Auto - correlation ? Yes , yes , the variance of the auto - correlation function that uses that
Turn 42, C (Professor): Ye - Well that 's the variance , but if you just say " what is {disfmarker} " I mean , to first order , um yeah one of the differences between voiced , unvoiced and silence is energy . Another one is {disfmarker} but the other one is the spectral shape .
Turn 43, D (PhD): Yeah , I I 'll {disfmarker} The spectral shape ,
Turn 44, C (Professor): Yeah , and so R - one over R - zero is what you typically use for that .
Turn 45, D (PhD): yeah . No , I don't use that {disfmarker} I can't use {disfmarker}
Turn 46, C (Professor): No , I 'm saying that 's what people us typically use .
Turn 47, D (PhD): Mmm .
Turn 48, C (Professor): See , because it {disfmarker} because this is {disfmarker} this is just like a single number to tell you um " does the spectrum look like that or does it look like that " .
Turn 49, D (PhD): Mm - hmm .
Turn 50, A (Grad): Oh . R {disfmarker} R {disfmarker} R - zero .
Turn 51, C (Professor): Right ?
Turn 52, D (PhD): Mm - hmm .
Turn 53, C (Professor): So if it 's {disfmarker} if it 's um {disfmarker} if it 's low energy uh but the {disfmarker} but the spectrum looks like that or like that , it 's probably silence .
Turn 54, D (PhD): Mm - hmm .
Turn 55, C (Professor): Uh but if it 's low energy and the spectrum looks like that , it 's probably unvoiced .
Turn 56, D (PhD): Yeah .
Turn 57, C (Professor): So if you just {disfmarker} if you just had to pick two features to determine voiced - unvoiced , you 'd pick something about the spectrum like uh R - one over R - zero , um and R - zero
Turn 58, D (PhD): Mm - hmm , OK .
Turn 59, C (Professor): or i i you know you 'd have some other energy measure and like in the old days people did like uh zero crossing counts .
Turn 60, D (PhD): Yeah , yeah .
Turn 61, C (Professor): Right . S S
Turn 62, D (PhD): Well , I can also th use this .
Turn 63, C (Professor): Yeah . Um ,
Turn 64, D (PhD): Bec - because the result are a little bit better but we have in a point that everything is more or less the similar {disfmarker} more or less similar .
Turn 65, C (Professor): Yeah . But um
Turn 66, D (PhD): It 's not quite better .
Turn 67, C (Professor): Right , but it seemed to me that what you were what you were getting at before was that there is something about the difference between the original signal or the original FFT and with the filter which is what {disfmarker} and the variance was one take uh on it .
Turn 68, D (PhD): Yeah , I used this too .
Turn 69, C (Professor): Right . But it {disfmarker} it could be something else . Suppose you didn't have anything like that . Then in that case , if you have two nets , Alright , and this one has three outputs , and this one has f
Turn 70, D (PhD): Mm - hmm .
Turn 71, C (Professor): whatever , fifty - six , or something ,
Turn 72, D (PhD): Mm - hmm .
Turn 73, C (Professor): if you were to sum up the probabilities for the voiced and for the unvoiced and for the silence here , we 've found in the past you 'll do better at voiced - unvoiced - silence than you do with this one . So just having the three output thing doesn't {disfmarker} doesn't really buy you anything . The issue is what you feed it .
Turn 74, D (PhD): Yeah . Yeah , I have {disfmarker} yeah .
Turn 75, C (Professor): So uh
Turn 76, D (PhD): No {disfmarker}
Turn 77, E (PhD): So you 're saying take the features that go into the voiced - unvoiced - silence net and feed those into the other one , as additional inputs , rather than having a separate {disfmarker}
Turn 78, C (Professor): w W well that 's another way .
Turn 79, D (PhD): Yeah .
Turn 80, C (Professor): That wasn't what I was saying but yeah that 's certainly another thing to do . No I was just trying to say if you b if you bring this into the picture over this , what more does it buy you ?
Turn 81, E (PhD): Mmm .
Turn 82, C (Professor): And what I was saying is that the only thing I think that it buys you is um based on whether you feed it something different . And something different in some fundamental way . And so the kind of thing that {disfmarker} that she was talking about before , was looking at something uh ab um {disfmarker} something uh about the difference between the {disfmarker} the uh um log FFT uh log power uh and the log magnitude uh F F - spectrum uh and the um uh filter bank .
Turn 83, D (PhD): Yeah .
Turn 84, C (Professor): And so the filter bank is chosen in fact to sort of integrate out the effects of pitch and she 's saying you know trying {disfmarker} So the particular measure that she chose was the variance of this m of this difference , but that might not be the right number .
Turn 85, D (PhD): Mm - hmm . Maybe .
Turn 86, C (Professor): Right ? I mean maybe there 's something about the variance that 's {disfmarker} that 's not enough or maybe there 's something else that {disfmarker} that one could use , but I think that , for me , the thing that {disfmarker} that struck me was that uh you wanna get something back here , so here 's {disfmarker} here 's an idea . uh What about it you skip all the {disfmarker} all the really clever things , and just fed the log magnitude spectrum into this ?
Turn 87, D (PhD): Ah {disfmarker} I 'm sorry .
Turn 88, C (Professor): This is f You have the log magnitude spectrum , and you were looking at that and the difference between the filter bank and {disfmarker} and c c computing the variance .
Turn 89, D (PhD): Yeah . Mm - hmm .
Turn 90, C (Professor): That 's a clever thing to do .
Turn 91, D (PhD): Mm - hmm .
Turn 92, C (Professor): What if you stopped being clever ? And you just took this thing in here because it 's a neural net and neural nets are wonderful
Turn 93, D (PhD): Mm - hmm .
Turn 94, C (Professor): and figure out what they can {disfmarker} what they most need from things , and I mean that 's what they 're good at .
Turn 95, D (PhD): Yeah .
Turn 96, C (Professor): So I mean you 're {disfmarker} you 're {disfmarker} you 're trying to be clever and say what 's the statistic that should {disfmarker} we should get about this difference but uh in fact , you know maybe just feeding this in or {disfmarker} or feeding both of them in
Turn 97, E (PhD): Hmm .
Turn 98, C (Professor): you know , another way , saying let it figure out what 's the {disfmarker} what is the interaction , especially if you do this over multiple frames ?
Turn 99, D (PhD): Mm - hmm .
Turn 100, C (Professor): Then you have this over time , and {disfmarker} and both kinds of measures and uh you might get uh something better .
Turn 101, D (PhD): Mm - hmm .
Turn 102, C (Professor): Um .
Turn 103, E (PhD): So {disfmarker} so don't uh {disfmarker} don't do the division , but let the net have everything .
Turn 104, C (Professor): That 's another thing you could do yeah . Yeah .
Turn 105, D (PhD): Yeah .
Turn 106, C (Professor): Um . I mean , it seems to me , if you have exactly the right thing then it 's better to do it without the net because otherwise you 're asking the net to learn this {disfmarker} you know , say if you wanted to learn how to do multiplication .
Turn 107, E (PhD): Mm - hmm .
Turn 108, C (Professor): I mean you could feed it a bunch of s you could feed two numbers that you wanted to multiply into a net and have a bunch of nonlinearities in the middle and train it to get the product of the output and it would work . But , it 's kind of crazy , cuz we know how to multiply and you {disfmarker} you 'd be you know much lower error usually {vocalsound} if you just multiplied it out . But suppose you don't really know what the right thing is . And that 's what these sort of dumb machine learning methods are good at . So . Um . Anyway . It 's just a thought .
Turn 109, E (PhD): How long does it take , Carmen , to train up one of these nets ?
Turn 110, D (PhD): Oh , not too much .
Turn 111, E (PhD): Yeah .
Turn 112, D (PhD): Mmm , one day or less .
Turn 113, E (PhD): Hmm .
Turn 114, C (Professor): Yeah , it 's probably worth it .
Turn 115, A (Grad): What are {disfmarker} what are your f uh frame error rates for {disfmarker} for this ?
Turn 116, D (PhD): Eh fifty - f six uh no , the frame error rate ?
Turn 117, A (Grad): O
Turn 118, D (PhD): Fifty - six I think .
Turn 119, C (Professor): Is that {disfmarker} maybe that 's accuracy ?
Turn 120, D (PhD): Percent .
Turn 121, A (Grad): Fif - fifty - six percent accurate for v voice - unvoice
Turn 122, D (PhD): The accuracy . Mm - hmm . No for , yes f I don't remember for voice - unvoice ,
Turn 123, A (Grad): Oh , OK .
Turn 124, D (PhD): maybe for the other one .
Turn 125, A (Grad): OK .
Turn 126, C (Professor): Yeah , voiced - unvoiced hopefully would be a lot better .
Turn 127, D (PhD): for voiced . I don't reme
Turn 128, A (Grad): Should be in nineties somewhere .
Turn 129, D (PhD): Better . Maybe for voice - unvoice .
Turn 130, A (Grad): Right .
Turn 131, D (PhD): This is for the other one . I should {disfmarker} I can't show that .
Turn 132, A (Grad): OK .
Turn 133, D (PhD): But I think that fifty - five was for the {disfmarker} when the output are the fifty - six phone .
Turn 134, A (Grad): Mm - hmm .
Turn 135, D (PhD): That I look in the {disfmarker} with the other {disfmarker} nnn the other MLP that we have are more or less the same number . Silence will be better but more or less the same .
Turn 136, C (Professor): I think at the frame level for fifty - six that was the kind of number we were getting for {disfmarker} for uh um reduced band width uh stuff .
Turn 137, D (PhD): I think that {disfmarker} I {disfmarker} I {disfmarker} I think that for the other one , for the three output , is sixty sixty - two , sixty three more or less .
Turn 138, A (Grad): Mm - hmm .
Turn 139, C (Professor): That 's all ?
Turn 140, D (PhD): It 's {disfmarker} Yeah .
Turn 141, C (Professor): That 's pretty bad .
Turn 142, D (PhD): Yeah , because it 's noise also .
Turn 143, A (Grad): Oh yeah .
Turn 144, C (Professor): Aha !
Turn 145, D (PhD): And we have
Turn 146, C (Professor): Aha ! Yeah . Yeah . OK .
Turn 147, D (PhD): I know .
Turn 148, C (Professor): But even i in {disfmarker} Oh yeah , in training . Still , Uh . Well actually , so this is a test that you should do then . Um , if you 're getting fifty - six percent over here , uh that 's in noise also , right ?
Turn 149, D (PhD): Yeah , yeah , yeah .
Turn 150, C (Professor): Oh OK . If you 're getting fifty - six here , try adding together the probabilities of all of the voiced phones here and all of the unvoiced phones
Turn 151, D (PhD): will be {disfmarker}
Turn 152, C (Professor): and see what you get then .
Turn 153, D (PhD): Yeah .
Turn 154, C (Professor): I bet you get better than sixty - three .
Turn 155, D (PhD): Well I don't know , but {disfmarker} I th I {disfmarker} I think that we {disfmarker} I have the result more or less . Maybe . I don't know . I don't {disfmarker} I 'm not sure but I remember @ @ that I can't show that .
Turn 156, C (Professor): OK , but that 's a {disfmarker} That is a {disfmarker} a good check point , you should do that anyway ,
Turn 157, D (PhD): Yeah .
Turn 158, C (Professor): OK ? Given this {disfmarker} this uh regular old net that 's just for choosing for other purposes , uh add up the probabilities of the different subclasses and see {disfmarker} see how well you do . Uh and that {disfmarker} you know anything that you do over here should be at least as good as that .
Turn 159, D (PhD): Mm - hmm .
Turn 160, C (Professor): OK .
Turn 161, D (PhD): I will do that . But {disfmarker}
Turn 162, E (PhD): The targets for the neural net , uh , they come from forced alignments ?
Turn 163, D (PhD): Uh , {comment} no .
Turn 164, A (Grad): TIMIT canonical ma mappings .
Turn 165, D (PhD): TIMIT .
Turn 166, C (Professor): Oh . So , this is trained on TIMIT .
Turn 167, E (PhD): Ah ! OK .
Turn 168, A (Grad): Yeah , noisy TIMIT .
Turn 169, D (PhD): Yeah .
Turn 170, C (Professor): OK .
Turn 171, D (PhD): Yeah this for TIMIT .
Turn 172, C (Professor): But noisy TIMIT ?
Turn 173, A (Grad): Right .
Turn 174, D (PhD): Noisy TIMIT . We have noisy TIMIT with the noise of the {disfmarker} the TI - digits . And now we have another noisy TIMIT also with the noise of uh Italian database .
Turn 175, C (Professor): I see . Yeah . Well there 's gonna be {disfmarker} it looks like there 's gonna be a noisy uh {disfmarker} some large vocabulary noisy stuff too . Somebody 's preparing .
Turn 176, E (PhD): Really ?
Turn 177, C (Professor): Yeah . I forget what it 'll be , resource management , Wall Street Journal , something . Some {disfmarker} some read task actually , that they 're {disfmarker} preparing .
Turn 178, A (Grad): Hmm !
Turn 179, E (PhD): For what {disfmarker} For Aurora ?
Turn 180, C (Professor): Yeah .
Turn 181, E (PhD): Oh !
Turn 182, C (Professor): Yeah , so the uh {disfmarker} Uh , the issue is whether people make a decision now based on what they 've already seen , or they make it later . And one of the arguments for making it later is let 's make sure that whatever techniques that we 're using work for something more than {disfmarker} than connected digits .
Turn 183, E (PhD): Hmm .
Turn 184, C (Professor): So .
Turn 185, E (PhD): When are they planning {disfmarker} When would they do that ?
Turn 186, C (Professor): Mmm , I think late {disfmarker} uh I think in the summer sometime .
Turn 187, E (PhD): Hmm .
Turn 188, C (Professor): So . OK , thanks .
Turn 189, D (PhD): This is the work that I did during this date
Turn 190, C (Professor): Uh - huh .
Turn 191, D (PhD): and also mmm I {disfmarker} H Hynek last week say that if I have time I can to begin to {disfmarker} to study well seriously the France Telecom proposal
Turn 192, C (Professor): Mm - hmm .
Turn 193, D (PhD): to look at the code and something like that to know exactly what they are doing because maybe that we can have some ideas
Turn 194, C (Professor): Mm - hmm .
Turn 195, D (PhD): but not only to read the proposal . Look insi look i carefully what they are doing with the program @ @ and I begin to {disfmarker} to work also in that . But the first thing that I don't understand is that they are using R - the uh log energy that this quite {disfmarker} I don't know why they have some constant in the expression of the lower energy . I don't know what that means .
Turn 196, E (PhD): They have a constant in there , you said ?
Turn 197, D (PhD): Yeah .
Turn 198, C (Professor): Oh , at the front it says uh " log energy is equal to the rounded version of sixteen over the log of two "
Turn 199, D (PhD): This {disfmarker} Yeah .
Turn 200, C (Professor): Uh . uh times the {disfmarker}
Turn 201, D (PhD): Then maybe I can understand .
Turn 202, C (Professor): Well , this is natural log , and maybe it has something to do with the fact that this is {disfmarker} I {disfmarker} I have no idea .
Turn 203, E (PhD): Is that some kind of base conversion , or {disfmarker} ?
Turn 204, C (Professor): Yeah , that 's what I was thinking , but {disfmarker} but um , then there 's the sixty - four , Uh , {vocalsound} I don't know .
Turn 205, D (PhD): Because maybe they 're {disfmarker} the threshold that they are using on the basis of this value {disfmarker}
Turn 206, E (PhD): Experimental results .
Turn 207, A (Grad): Mc - McDonald 's constant .
Turn 208, D (PhD): I don't know exactly , because well th I thought maybe they have a meaning . But I don't know what is the meaning of take exactly this value .
Turn 209, C (Professor): Yeah , it 's pretty funny looking .
Turn 210, E (PhD): So they 're taking the number inside the log and raising it to sixteen over log base two .
Turn 211, C (Professor): I don't know . Yeah , I {disfmarker} um Right . Sixteen over {comment} two .
Turn 212, E (PhD): Does it have to do with those sixty - fours , or {disfmarker} ?
Turn 213, C (Professor): Um . If we ignore the sixteen , the natural log of t one over the natural log of two times the natu I don't know . Well , maybe somebody 'll think of something ,
Turn 214, E (PhD): 
Turn 215, C (Professor): but this is uh {disfmarker} It may just be that they {disfmarker} they want to have {disfmarker} for very small energies , they want to have some kind of a {disfmarker}
Turn 216, D (PhD): Yeah , the e The effect I don't {disfmarker} @ @ I can understand the effect of this , no ? because it 's to {disfmarker} to do something like that .
Turn 217, C (Professor): Well , it says , since you 're taking a natural log , it says that when {disfmarker} when you get down to essentially zero energy , this is gonna be the natural log of one , which is zero .
Turn 218, D (PhD): No ? Mm - hmm .
Turn 219, C (Professor): So it 'll go down to uh to {nonvocalsound} the natural log being {disfmarker} So the lowest value for this would be zero . So y you 're restricted to being positive . And this sort of smooths it for very small energies . Uh , why they chose sixty - four and something else , that was probably just experimental . And the {disfmarker} the {disfmarker} the constant in front of it , I have no idea .
Turn 220, D (PhD): Yeah .
Turn 221, C (Professor): um
Turn 222, D (PhD): Well . I {disfmarker} I will look to try if I move this parameter in their code what happens , maybe everything is {disfmarker} Maybe they tres hole are on basis of this .
Turn 223, C (Professor): uh {disfmarker} I mean {disfmarker} it {disfmarker} {vocalsound} they {disfmarker} they probably have some fi particular s fixed point arithmetic that they 're using ,
Turn 224, D (PhD): I don't know .
Turn 225, C (Professor): and then it just {disfmarker}
Turn 226, E (PhD): Yeah , I was just gonna say maybe it has something to do with hardware ,
Turn 227, C (Professor): Yeah .
Turn 228, E (PhD): something they were doing .
Turn 229, C (Professor): Yeah , I mean that {disfmarker} they 're s probably working with fixed point or integer or something . I think you 're supposed to on this stuff anyway , and {disfmarker} and so maybe that puts it in the right realm somewhere .
Turn 230, E (PhD): Well it just , yeah , puts it in the right range , or {disfmarker}
Turn 231, C (Professor): Yeah . I think , given at the level you 're doing things in floating point on the computer , I don't think it matters , would be my guess ,
Turn 232, D (PhD): Mm - hmm .
Turn 233, C (Professor): but .
Turn 234, D (PhD): I {disfmarker} this more or less anything
Turn 235, C (Professor): Yeah . OK , and wh when did Stephane take off ? He took off {disfmarker}
Turn 236, D (PhD): I think that Stephane will arrive today or tomorrow .
Turn 237, C (Professor): Oh , he was gone these first few days , and then he 's here for a couple days before he goes to Salt Lake City .
Turn 238, D (PhD): Mm - hmm .
Turn 239, C (Professor): OK .
Turn 240, D (PhD): He 's {disfmarker} I think that he is in Las Vegas or something like that .
Turn 241, C (Professor): Yeah . Yeah . So he 's {disfmarker} he 's going to ICASSP which is good . I {disfmarker} I don't know if there are many people who are going to ICASSP
Turn 242, D (PhD): Yeah .
Turn 243, C (Professor): so {disfmarker} so I thought , make sure somebody go .
Turn 244, D (PhD): Yeah .
Turn 245, E (PhD): Do {disfmarker} have {disfmarker} Have people sort of stopped going to ICASSP in recent years ?
Turn 246, C (Professor): Um , people are less consistent about going to ICASSP and I think it 's still {disfmarker} it 's still a reasonable forum for students to {disfmarker} to present things . Uh , it 's {disfmarker} I think for engineering students of any kind , I think it 's {disfmarker} it 's if you haven't been there much , it 's good to go to , uh to get a feel for things , a range of things , not just speech . Uh . But I think for {disfmarker} for sort of dyed - in - the - wool speech people , um I think that ICSLP and Eurospeech are much more targeted .
Turn 247, E (PhD): Mm - hmm .
Turn 248, C (Professor): Uh . And then there 's these other meetings , like HLT and {disfmarker} and uh ASRU {disfmarker}
Turn 249, E (PhD): 
Turn 250, C (Professor): so there 's {disfmarker} there 's actually plenty of meetings that are really relevant to {disfmarker} to uh computational uh speech processing of one sort or another .
Turn 251, E (PhD): Mm - hmm . 
Turn 252, C (Professor): Um . So . I mean , I mostly just ignored it because I was too busy and {vocalsound} didn't get to it . So uh Wanna talk a little bit about what we were talking about this morning ?
Turn 253, A (Grad): Oh ! um {pause} uh {pause} Yeah .
Turn 254, C (Professor): Just briefly , or {pause} Or anything else ?
Turn 255, A (Grad): So . I {disfmarker} I guess some of the progress , I {disfmarker} I 've been getting a {disfmarker} getting my committee members for the quals . And um so far I have Morgan and Hynek , {vocalsound} Mike Jordan , and I asked John Ohala and he agreed . Yeah . Yeah .
Turn 256, E (PhD): Cool .
Turn 257, A (Grad): So I 'm {disfmarker} I {disfmarker} I just need to ask um Malek . One more . Um . Tsk . Then uh I talked a little bit about {vocalsound} um continuing with these dynamic ev um acoustic events , and um {vocalsound} {vocalsound} we 're {disfmarker} we 're {disfmarker} we 're {vocalsound} thinking about a way to test the completeness of a {disfmarker} a set of um dynamic uh events . Uh , completeness in the {disfmarker} in the sense that {vocalsound} um if we {disfmarker} if we pick these X number of acoustic events , {vocalsound} do they provide sufficient coverage {vocalsound} for the phones that we 're trying to recognize {vocalsound} or {disfmarker} or the f the words that we 're gonna try to recognize later on . And so Morgan and I were uh discussing {vocalsound} um s uh s a form of a cheating experiment {vocalsound} where we get {disfmarker} {vocalsound} um we have uh {vocalsound} um a chosen set of features , or acoustic events , and we train up a hybrid {vocalsound} um system to do phone recognition on TIMIT . So i i the idea is if we get good phone recognition results , {vocalsound} using um these set of acoustic events , {vocalsound} then {vocalsound} um that {disfmarker} that says that these acoustic events are g sufficient to cover {vocalsound} a set of phones , at least found in TIMIT . Um so i it would be a {disfmarker} {vocalsound} a measure of " are we on the right track with {disfmarker} with the {disfmarker} the choices of our acoustic events " . Um , {vocalsound} So that 's going on . And {vocalsound} also , just uh working on my {vocalsound} uh final project for Jordan 's class , uh which is {disfmarker}
Turn 258, C (Professor): Actually , let me {disfmarker}
Turn 259, A (Grad): Yeah .
Turn 260, C (Professor): Hold that thought .
Turn 261, A (Grad): OK , sure .
Turn 262, C (Professor): Let me back up while we 're still on it . The {disfmarker} the other thing I was suggesting , though , is that given that you 're talking about binary features , uh , maybe the first thing to do is just to count and uh count co - occurrences and get probabilities for a discrete HMM cuz that 'd be pretty simple because it 's just {disfmarker} Say , if you had ten {disfmarker} ten events , uh that you were counting , uh each frame would only have a thousand possible values for these ten bits , and uh so you could make a table that would {disfmarker} say , if you had thirty - nine phone categories , that would be a thousand by thirty - nine , and just count the co - occurrences and divide them by the {disfmarker} the uh {disfmarker} uh uh occ uh count the co - occurrences between the event and the phone and divide them by the number of occurrences of the phone , and that would give you the likelihood of the {disfmarker} of the event given the phone . And um then just use that in a very simple HMM and uh you could uh do phone recognition then and uh wouldn't have any of the issues of the uh training of the net or {disfmarker} I mean , it 'd be on the simple side , but
Turn 263, E (PhD): Mm - hmm .
Turn 264, C (Professor): uh um you know , if {disfmarker} uh uh the example I was giving was that if {disfmarker} if you had um onset of voicing and {disfmarker} and end of voicing as being two kinds of events , then if you had those a all marked correctly , and you counted co - occurrences , you should get it completely right .
Turn 265, E (PhD): Mm - hmm .
Turn 266, C (Professor): So . um {disfmarker} But you 'd get all the other distinctions , you know , randomly wrong . I mean there 'd be nothing to tell you that . So um {vocalsound} uh If you just do this by counting , then you should be able to find out in a pretty straightforward way whether you have a sufficient uh set of events to {disfmarker} to do the kind of level of {disfmarker} {vocalsound} of uh classification of phones that you 'd like . So that was {disfmarker} that was the idea . And then the other thing that we were discussing was {disfmarker} was um {vocalsound} OK , how do you get the {disfmarker} your training data .
Turn 267, E (PhD): Mm - hmm .
Turn 268, C (Professor): Cuz uh the {vocalsound} Switchboard transcription project uh uh you know was half a dozen people , or so working off and on over a couple years , and uh similar {disfmarker} {vocalsound} similar amount of data {vocalsound} to what you 're talking about with TIMIT training . So , it seems to me that the only reasonable starting point is uh to automatically translate the uh current TIMIT markings into the markings you want . And uh {vocalsound} it won't have the kind of characteristic that you 'd like , of catching funny kind of things that maybe aren't there from these automatic markings ,
Turn 269, E (PhD): Mm - hmm .
Turn 270, C (Professor): but {disfmarker} but uh it 's uh {disfmarker}
Turn 271, E (PhD): It 's probably a good place to start .
Turn 272, C (Professor): Yeah .
Turn 273, E (PhD): Yeah .
Turn 274, C (Professor): Yeah and a short {disfmarker} short amount of time , just to {disfmarker} again , just to see if that information is sufficient to uh determine the phones .
Turn 275, E (PhD): Mm - hmm . Hmm .
Turn 276, C (Professor): So .
Turn 277, E (PhD): Yeah , you could even then {disfmarker} to {disfmarker} to get an idea about how different it is , you could maybe take some subset and you know , go through a few sentences , mark them by hand and then see how different it is from you know , the canonical ones ,
Turn 278, C (Professor): Right .
Turn 279, E (PhD): just to get an idea {disfmarker} a rough idea of h if it really even makes a difference .
Turn 280, C (Professor): You can get a little feeling for it that way , yeah that is probably right .
Turn 281, E (PhD): Yeah .
Turn 282, C (Professor): I mean uh my {disfmarker} my guess would be that this is {disfmarker} since TIMIT 's read speech that this would be less of a big deal ,
Turn 283, E (PhD): Mm - hmm .
Turn 284, C (Professor): if you went and looked at spontaneous speech it 'd be more {disfmarker} more of one .
Turn 285, E (PhD): Right . Right .
Turn 286, C (Professor): And the other thing would be , say , if you had these ten events , you 'd wanna see , well what if you took two events or four events or ten events or t and you know , and {disfmarker} and hopefully there should be some point at which {vocalsound} having more information doesn't tell you really all that much more about what the phones are .
Turn 287, E (PhD): Mm - hmm . You could define other events as being sequences of these events too .
Turn 288, C (Professor): Uh , you could , but the thing is , what he 's talking about here is a uh {disfmarker} a translation to a per - frame feature vector , so there 's no sequence in that , I think . I think it 's just a {disfmarker}
Turn 289, E (PhD): Unless you did like a second pass over it or something after you 've got your {disfmarker}
Turn 290, C (Professor): Yeah , but we 're just talking about something simple here , yeah , to see if {disfmarker}
Turn 291, E (PhD): Yeah . Yeah , yeah . Yeah . I 'm adding complexity .
Turn 292, C (Professor): Yeah . Just {disfmarker} You know . The idea is with a {disfmarker} with a very simple statistical structure , could you {disfmarker} could you uh at least verify that you 've chosen features that {vocalsound} are sufficient .
Turn 293, E (PhD): Yeah .
Turn 294, C (Professor): OK , and you were saying something {disfmarker} starting to say something else about your {disfmarker} your class project , or {disfmarker} ?
Turn 295, A (Grad): Oh . Yeah th Um .
Turn 296, C (Professor): Yeah .
Turn 297, A (Grad): So for my class project I 'm {vocalsound} um {vocalsound} {vocalsound} I 'm tinkering with uh support vector machines ? something that we learned in class , and uh um basically just another method for doing classification . And so I 'm gonna apply that to {vocalsound} um compare it with the results by um King and Taylor who did {vocalsound} um these um using recurrent neural nets , they recognized {vocalsound} um {vocalsound} a set of phonological features um and made a mapping from the MFCC 's to these phonological features , so I 'm gonna {vocalsound} do a similar thing with {disfmarker} {vocalsound} with support vector machines and see if {disfmarker}
Turn 298, E (PhD): So what 's the advantage of support vector machines ? What {disfmarker}
Turn 299, A (Grad): Um . So , support vector machines are {disfmarker} are good with dealing with a less amount of data
Turn 300, E (PhD): Hmm .
Turn 301, A (Grad): and um so if you {disfmarker} if you give it less data it still does a reasonable job {vocalsound} in learning the {disfmarker} the patterns .
Turn 302, E (PhD): Hmm .
Turn 303, A (Grad): Um and {vocalsound} um
Turn 304, C (Professor): I guess it {disfmarker} yeah , they 're sort of succinct , and {disfmarker} and they {vocalsound} uh
Turn 305, A (Grad): Yeah .
Turn 306, E (PhD): Does there some kind of a distance metric that they use or how do they {disfmarker} for cla what do they do for classification ?
Turn 307, A (Grad): Um . Right . So , {vocalsound} the {disfmarker} the simple idea behind a support vector machine is {vocalsound} um , {vocalsound} you have {disfmarker} you have this feature space , right ? and then it finds the optimal separating plane , um between these two different um classes ,
Turn 308, E (PhD): Mm - hmm . Mm - hmm . Mm - hmm .
Turn 309, A (Grad): and um {vocalsound} and so {vocalsound} um , what it {disfmarker} i at the end of the day , what it actually does is {vocalsound} it picks {vocalsound} those examples of the features that are closest to the separating boundary , and remembers those
Turn 310, E (PhD): Mm - hmm .
Turn 311, A (Grad): and {disfmarker} {vocalsound} and uses them to recreate the boundary for the test set . So , given these {vocalsound} um these features , or {disfmarker} or these {disfmarker} these examples , {pause} um , {pause} critical examples , {vocalsound} which they call support f support vectors , {vocalsound} then um {vocalsound} given a new example , {vocalsound} if the new example falls {vocalsound} um away from the boundary in one direction then it 's classified as being a part of this particular class
Turn 312, E (PhD): Oh .
Turn 313, A (Grad): and otherwise it 's the other class .
Turn 314, E (PhD): So why save the examples ? Why not just save what the boundary itself is ?
Turn 315, A (Grad): Mm - hmm . Um . Hmm . Let 's see . Uh . Yeah , that 's a good question . I {disfmarker} yeah .
Turn 316, C (Professor): That 's another way of doing it . Right ? So {disfmarker} so it {disfmarker} I mean I {disfmarker} I guess it 's {disfmarker}
Turn 317, E (PhD): Mmm . Sort of an equivalent .
Turn 318, C (Professor): You know , it {disfmarker} it goes back to nearest - neighbor {vocalsound} sort of thing ,
Turn 319, E (PhD): Mm - hmm .
Turn 320, C (Professor): right ? Um , i i if {disfmarker} is it eh w When is nearest - neighbor good ? Well , nearest - neighbor good {disfmarker} is good if you have lots and lots of examples . Um but of course if you have lots and lots of examples , then it can take a while to {disfmarker} to use nearest - neighbor . There 's lots of look ups . So a long time ago people talked about things where you would have uh a condensed nearest - neighbor , where you would {disfmarker} you would {disfmarker} you would pick out uh some representative examples which would uh be sufficient to represent {disfmarker} to {disfmarker} to correctly classify everything that came in .
Turn 321, E (PhD): Oh . Mm - hmm .
Turn 322, C (Professor): I {disfmarker} I think s I think support vector stuff sort of goes back to {disfmarker} {vocalsound} to that kind of thing . Um .
Turn 323, E (PhD): I see . So rather than doing nearest neighbor where you compare to every single one , you just pick a few critical ones , and {disfmarker}
Turn 324, C (Professor): Yeah .
Turn 325, E (PhD): Hmm .
Turn 326, C (Professor): And th the You know , um neural net approach uh or Gaussian mixtures for that matter are sort of {disfmarker} fairly brute force kinds of things , where you sort of {disfmarker} {vocalsound} you predefine that there is this big bunch of parameters and then you {disfmarker} you place them as you best can to define the boundaries , and in fact , as you know , {vocalsound} these things do take a lot of parameters and {disfmarker} and uh {vocalsound} if you have uh only a modest amount of data , you have trouble {vocalsound} uh learning them . Um , so I {disfmarker} I guess the idea to this is that it {disfmarker} it is reputed to uh be somewhat better in that regard .
Turn 327, E (PhD): Mm - hmm .
Turn 328, A (Grad): Right . I it can be a {disfmarker} a reduced um {vocalsound} parameterization of {disfmarker} of the {disfmarker} the model by just keeping {vocalsound} certain selected examples .
Turn 329, E (PhD): Hmm .
Turn 330, A (Grad): Yeah . So .
Turn 331, C (Professor): But I don't know if people have done sort of careful comparisons of this on large tasks or anything . Maybe {disfmarker} maybe they have . I don't know .
Turn 332, A (Grad): Yeah , I don't know either .
Turn 333, C (Professor): Yeah .
Turn 334, B (Grad): S do you get some kind of number between zero and one at the output ?
Turn 335, A (Grad): Actually you don't get a {disfmarker} you don't get a nice number between zero and one . You get {disfmarker} you get either a zero or a one . Um , uh there are {disfmarker} there are pap Well , basically , it 's {disfmarker} it 's um {vocalsound} you {disfmarker} you get a distance measure at the end of the day , and then that distance measure is {disfmarker} is um {disfmarker} {vocalsound} is translated to a zero or one . Um .
Turn 336, C (Professor): But that 's looking at it for {disfmarker} for classification {disfmarker} for binary classification ,
Turn 337, A (Grad): That 's for classification , right .
Turn 338, C (Professor): right ?
Turn 339, E (PhD): And you get that for each class , you get a zero or a one .
Turn 340, A (Grad): Right .
Turn 341, C (Professor): But you have the distances to work with .
Turn 342, A (Grad): You have the distances to work with ,
Turn 343, C (Professor): Cuz actually Mississippi State people did use support vector machines for uh uh speech recognition and they were using it to estimate probabilities .
Turn 344, A (Grad): yeah . Yeah . Yeah , they {disfmarker} {vocalsound} they had a {disfmarker} had a way to translate the distances into {disfmarker} into probabilities with the {disfmarker} with the simple {vocalsound} um {vocalsound} uh sigmoidal function .
Turn 345, C (Professor): Yeah , and d did they use sigmoid or a softmax type thing ?
Turn 346, A (Grad): Um {pause} {vocalsound} Yeah ,
Turn 347, C (Professor): And didn't they like exponentiate or something
Turn 348, A (Grad): there 's some {disfmarker} there 's like one over one plus the exponential or something like that .
Turn 349, C (Professor): and then {vocalsound} divide by the sum of them , or {disfmarker} ? Oh it {disfmarker} i Oh , so it is a sigmoidal .
Turn 350, A (Grad): Yeah .
Turn 351, C (Professor): OK . Alright .
Turn 352, E (PhD): Did the {disfmarker} did they get good results with that ?
Turn 353, C (Professor): I mean , they 're OK , I {disfmarker} I don't {disfmarker} I don't think they were earth {disfmarker} earth shattering , but I think that {vocalsound} uh this was a couple years ago ,
Turn 354, E (PhD): Hmm .
Turn 355, C (Professor): I remember them doing it at some meeting , and {disfmarker} and um I don't think people were very critical because it was interesting just to {disfmarker} to try this and you know , it was the first time they tried it , so {disfmarker} {vocalsound} so the {disfmarker} you know , the numbers were not incredibly good
Turn 356, E (PhD): Hmm .
Turn 357, C (Professor): but there 's you know , it was th reasonable .
Turn 358, E (PhD): Mm - hmm .
Turn 359, C (Professor): I {disfmarker} I don't remember anymore . I don't even remember what the task was , it {comment} was Broadcast News , or {vocalsound} something . I don't know .
Turn 360, E (PhD): Hmm .
Turn 361, A (Grad): Right .
Turn 362, B (Grad): Uh s So Barry , if you just have zero and ones , how are you doing the speech recognition ?
Turn 363, A (Grad): Oh I 'm not do I 'm not planning on doing speech recognition with it . I 'm just doing {vocalsound} detection of phonological features .
Turn 364, B (Grad): Oh . OK .
Turn 365, A (Grad): So uh for example , {vocalsound} this {disfmarker} this uh feature set called the uh sound patterns of English {vocalsound} um is just a bunch of {vocalsound} um {vocalsound} binary valued features . Let 's say , is this voicing , or is this not voicing , is this {vocalsound} sonorants , not sonorants , and {vocalsound} stuff like that .
Turn 366, B (Grad): OK .
Turn 367, A (Grad): So .
Turn 368, E (PhD): Did you find any more mistakes in their tables ?
Turn 369, A (Grad): Oh ! Uh I haven't gone through the entire table , {pause} yet . Yeah , yesterday I brought Chuck {vocalsound} the table and I was like , " wait , this {disfmarker} is {disfmarker} Is the mapping from N to {disfmarker} to this phonological feature called um " coronal " , is {disfmarker} is {disfmarker} should it be {disfmarker} shouldn't it be a one ? or should it {disfmarker} should it be you know coronal instead of not coronal as it was labelled in the paper ? " So I ha haven't hunted down all the {disfmarker} all the mistakes yet ,
Turn 370, C (Professor): Uh - huh .
Turn 371, A (Grad): but {disfmarker}
Turn 372, C (Professor): But a as I was saying , people do get probabilities from these things ,
Turn 373, B (Grad): OK .
Turn 374, C (Professor): and {disfmarker} and uh we were just trying to remember how they do , but people have used it for speech recognition , and they have gotten probabilities . So they have some conversion from these distances to probabilities .
Turn 375, B (Grad): OK .
Turn 376, A (Grad): Right , yeah .
Turn 377, C (Professor): There 's {disfmarker} you have {disfmarker} you have the paper , right ? The Mississippi State paper ?
Turn 378, A (Grad): Mm - hmm . Mm - hmm .
Turn 379, C (Professor): Yeah , if you 're interested y you could look ,
Turn 380, B (Grad): And {disfmarker} OK . OK .
Turn 381, A (Grad): Yeah , I can {disfmarker} I can show you {disfmarker} I {disfmarker}
Turn 382, C (Professor): yeah .
Turn 383, A (Grad): yeah , our {disfmarker}
Turn 384, E (PhD): So in your {disfmarker} in {disfmarker} in the thing that you 're doing , uh you have a vector of ones and zeros for each phone ?
Turn 385, A (Grad): Mm - hmm . Uh , is this the class project , or {disfmarker} ?
Turn 386, E (PhD): Yeah .
Turn 387, A (Grad): OK . um
Turn 388, E (PhD): Is that what you 're {disfmarker}
Turn 389, A (Grad): Right , {comment} Right , right f so for every phone there is {disfmarker} there is a um {disfmarker} a vector of ones and zeros {vocalsound} f uh corresponding to whether it exhibits a particular phonological feature or not .
Turn 390, E (PhD): Mm - hmm . Mm - hmm . And so when you do your wh I 'm {disfmarker} what is the task for the class project ? To come up with the phones ?
Turn 391, A (Grad): Um
Turn 392, E (PhD): or to come up with these vectors to see how closely they match the phones ,
Turn 393, A (Grad): Oh . Right , um to come up with a mapping from um MFCC 's or s some feature set , {vocalsound} um to {vocalsound} uh w to whether there 's existence of a particular phonological feature .
Turn 394, E (PhD): or {disfmarker} ? Mm - hmm .
Turn 395, A (Grad): And um yeah , basically it 's to learn a mapping {vocalsound} from {disfmarker} {vocalsound} from the MFCC 's to {vocalsound} uh phonological features . Is it {disfmarker} did that answer your question ?
Turn 396, E (PhD): I think so .
Turn 397, A (Grad): OK . C
Turn 398, E (PhD): I guess {disfmarker} I mean , uh {disfmarker} I 'm not sure what you {disfmarker} what you 're {disfmarker} what you get out of your system . Do you get out a uh {disfmarker} a vector of these ones and zeros and then try to find the closest matching phoneme to that vector ,
Turn 399, A (Grad): Mm - hmm . Oh .
Turn 400, E (PhD): or {disfmarker} ?
Turn 401, A (Grad): No , no . I 'm not {disfmarker} I 'm not planning to do any {disfmarker} any phoneme mapping yet . Just {disfmarker} {vocalsound} it 's {disfmarker} it 's basically {disfmarker} it 's {disfmarker} it 's really simple , basically a detection {vocalsound} of phonological features .
Turn 402, E (PhD): Uh - huh .
Turn 403, A (Grad): Yeah ,
Turn 404, E (PhD): I see .
Turn 405, A (Grad): and um {vocalsound} {vocalsound} cuz the uh {disfmarker} So King and {disfmarker} and Taylor {vocalsound} um did this with uh recurrent neural nets ,
Turn 406, E (PhD): Yeah .
Turn 407, A (Grad): and this i their {disfmarker} their idea was to first find {vocalsound} a mapping from MFCC 's to {vocalsound} uh phonological features
Turn 408, E (PhD): Mm - hmm .
Turn 409, A (Grad): and then later on , once you have these {vocalsound} phonological features , {vocalsound} then uh map that to phones .
Turn 410, E (PhD): Mm - hmm .
Turn 411, A (Grad): So I 'm {disfmarker} I 'm sort of reproducing phase one of their stuff .
Turn 412, E (PhD): Mmm . So they had one recurrent net for each particular feature ?
Turn 413, A (Grad): Right . Right . Right . Right .
Turn 414, E (PhD): I see . I wo did they compare that {disfmarker} I mean , what if you just did phone recognition and did the reverse lookup .
Turn 415, A (Grad): Uh .
Turn 416, E (PhD): So you recognize a phone and which ever phone was recognized , you spit out it 's vector of ones and zeros .
Turn 417, A (Grad): Mm - hmm . Uh .
Turn 418, C (Professor): I expect you could do that .
Turn 419, E (PhD): I mean uh {disfmarker}
Turn 420, C (Professor): That 's probably not what he 's going to do on his class project . Yeah .
Turn 421, E (PhD): Yeah . No .
Turn 422, A (Grad): Yeah .
Turn 423, C (Professor): So um have you had a chance to do this um thing we talked about yet with the uh {disfmarker} um
Turn 424, E (PhD): Insertion penalty ?
Turn 425, C (Professor): Uh . No actually I was going a different {disfmarker} That 's a good question , too , but I was gonna ask about the {disfmarker} {vocalsound} the um {vocalsound} changes to the data in comparing PLP and mel cepstrum for the SRI system .
Turn 426, E (PhD): Uh . Well what I 've been {disfmarker} " Changes to the data " , I 'm not sure I {disfmarker}
Turn 427, C (Professor): Right . So we talked on the phone about this , that {disfmarker} that there was still a difference of a {disfmarker} of a few percent
Turn 428, E (PhD): Yeah . Right .
Turn 429, C (Professor): and {vocalsound} you told me that there was a difference in how the normalization was done . And I was asking if you were going to do {disfmarker} {vocalsound} redo it uh for PLP with the normalization done as it had been done for the mel cepstrum .
Turn 430, E (PhD): Mm - hmm . Uh right , no I haven't had a chance to do that .
Turn 431, C (Professor): OK .
Turn 432, E (PhD): What I 've been doing is {vocalsound} uh {vocalsound} trying to figure out {disfmarker} it just seems to me like there 's a um {disfmarker} well it seems like there 's a bug , because the difference in performance is {disfmarker} it 's not gigantic but it 's big enough that it {disfmarker} it seems wrong .
Turn 433, C (Professor): Yeah , I agree , but I thought that the normalization difference was one of the possibilities ,
Turn 434, E (PhD): and {disfmarker} Yeah , but I don't {disfmarker} I 'm not {disfmarker}
Turn 435, C (Professor): right ?
Turn 436, E (PhD): Yeah , I guess I don't think that the normalization difference is gonna account for everything .
Turn 437, C (Professor): OK .
Turn 438, E (PhD): So what I was working on is um just going through and checking the headers of the wavefiles , to see if maybe there was a um {disfmarker} a certain type of compression or something that was done that my script wasn't catching . So that for some subset of the training data , uh the {disfmarker} the {disfmarker} the features I was computing were junk .
Turn 439, C (Professor): OK .
Turn 440, E (PhD): Which would you know cause it to perform OK , but uh , you know , the {disfmarker} the models would be all messed up . So I was going through and just double - checking that kind of think first , to see if there was just some kind of obvious bug in the way that I was computing the features .
Turn 441, C (Professor): Mm - hmm . I see . OK .
Turn 442, E (PhD): Looking at all the sampling rates to make sure all the sampling rates were what {disfmarker} eight K , what I was assuming they were ,
Turn 443, C (Professor): Yeah .
Turn 444, E (PhD): um {disfmarker}
Turn 445, C (Professor): Yeah , that makes sense , to check all that .
Turn 446, E (PhD): Yeah . So I was doing that first , before I did these other things , just to make sure there wasn't something {disfmarker}
Turn 447, C (Professor): Although really , uh uh , a couple three percent uh difference in word error rate uh {comment} could easily come from some difference in normalization , I would think . But
Turn 448, E (PhD): Yeah , and I think , hhh {disfmarker} {comment} I 'm trying to remember but I think I recall that Andreas was saying that he was gonna run sort of the reverse experiment . Uh which is to try to emulate the normalization that we did but with the mel cepstral features . Sort of , you know , back up from the system that he had . I thought he said he was gonna {disfmarker} I have to look back through my {disfmarker} my email from him .
Turn 449, C (Professor): Yeah , he 's probably off at {disfmarker} at uh his meeting now ,
Turn 450, E (PhD): Yeah , he 's gone now .
Turn 451, C (Professor): yeah .
Turn 452, E (PhD): Um .
Turn 453, C (Professor): Yeah . But yeah
Turn 454, E (PhD): But {disfmarker}
Turn 455, C (Professor): the {disfmarker} I sh think they should be {vocalsound} roughly equivalent , um I mean again the Cambridge folk found the PLP actually to be a little better . Uh So it 's {disfmarker} {vocalsound} um
Turn 456, E (PhD): Right .
Turn 457, C (Professor): I mean the other thing I wonder about was whether there was something just in the {disfmarker} the bootstrapping of their system which was based on {disfmarker} but maybe not , since they {disfmarker}
Turn 458, E (PhD): Yeah see one thing that 's a little bit um {disfmarker} I was looking {disfmarker} I 've been studying and going through the logs for the system that um Andreas created . And um his uh {disfmarker} the way that the {disfmarker} {vocalsound} {comment} S R I system looks like it works is that it reads the wavefiles directly , uh and does all of the cepstral computation stuff on the fly .
Turn 459, C (Professor): Right . Right .
Turn 460, E (PhD): And , so there 's no place where these {disfmarker} where the cepstral files are stored , anywhere that I can go look at and compare to the PLP ones , so whereas with our features , he 's actually storing the cepstrum on disk , and he reads those in .
Turn 461, C (Professor): Right .
Turn 462, E (PhD): But it looked like he had to give it {disfmarker} uh even though the cepstrum is already computed , he has to give it uh a front - end parameter file . Which talks about the kind of uh com computation that his mel cepstrum thing does ,
Turn 463, C (Professor): Uh - huh .
Turn 464, E (PhD): so i I {disfmarker} I don't know if that {disfmarker} it probably doesn't mess it up , it probably just ignores it if it determines that it 's already in the right format or something but {disfmarker} the {disfmarker} the {disfmarker} the two processes that happen are a little different .
Turn 465, C (Professor): Yeah .
Turn 466, E (PhD): So .
Turn 467, C (Professor): So anyway , there 's stuff there to sort out .
Turn 468, E (PhD): Yeah . Yeah .
Turn 469, C (Professor): So , OK . Let 's go back to what you thought I was asking you .
Turn 470, E (PhD): Yeah no and I didn't have a chance to do that .
Turn 471, C (Professor): Ha ! Oh ! You had the sa same answer anyway .
Turn 472, E (PhD): Yeah . Yeah . I 've been um , {disfmarker} I 've been working with um Jeremy on his project and then I 've been trying to track down this bug in uh the ICSI front - end features .
Turn 473, C (Professor): Uh - huh .
Turn 474, E (PhD): So one thing that I did notice , yesterday I was studying the um {disfmarker} the uh RASTA code
Turn 475, C (Professor): Uh - huh .
Turn 476, E (PhD): and it looks like we don't have any way to um control the frequency range that we use in our analysis . We basically {disfmarker} it looks to me like we do the FFT , um and then we just take all the bins and we use everything . We don't have any set of parameters where we can say you know , " only process from you know a hundred and ten hertz to thirty - seven - fifty " .
Turn 477, C (Professor): Um {disfmarker}
Turn 478, E (PhD): At least I couldn't see any kind of control for that .
Turn 479, C (Professor): Yeah , I don't think it 's in there , I think it 's in the uh uh uh the filters . So , the F F T is on everything , but the filters um , for instance , ignore the {disfmarker} the lowest bins and the highest bins . And what it does is it {disfmarker} it copies
Turn 480, E (PhD): The {disfmarker} the filters ? Which filters ?
Turn 481, C (Professor): um The filter bank which is created by integrating over F F T bins .
Turn 482, E (PhD): Mm - hmm .
Turn 483, C (Professor): um
Turn 484, E (PhD): When you get the mel {disfmarker} When you go to the mel scale .
Turn 485, C (Professor): Right . Yeah , it 's bark scale , and it 's {disfmarker} it {disfmarker} it um {disfmarker} it actually copies the uh um {disfmarker} the second filters over to the first . So the first filters are always {disfmarker} and you can s you can specify a different number of {vocalsound} uh features {disfmarker} different number of filters , I think , as I recall . So you can specify a different number of filters , and whatever {vocalsound} um uh you specify , the last ones are gonna be ignored . So that {disfmarker} that 's a way that you sort of change what the {disfmarker} what the bandwidth is . Y you can't do it without I think changing the number of filters , but {disfmarker}
Turn 486, E (PhD): I saw something about uh {disfmarker} that looked like it was doing something like that , but I didn't quite understand it . So maybe {disfmarker}
Turn 487, C (Professor): Yeah , so the idea is that the very lowest frequencies and {disfmarker} and typically the veriest {comment} highest frequencies are kind of junk .
Turn 488, E (PhD): Uh - huh .
Turn 489, C (Professor): And so um you just {disfmarker} for continuity you just approximate them by {disfmarker} {vocalsound} by the second to highest and second to lowest . It 's just a simple thing we put in .
Turn 490, E (PhD): Mm - hmm .
Turn 491, C (Professor): And {disfmarker} and so if you h
Turn 492, E (PhD): But {disfmarker} so the {disfmarker} but that 's a fixed uh thing ?
Turn 493, C (Professor): Yeah , {comment} I think that 's a fixed thing .
Turn 494, E (PhD): There 's nothing that lets you {disfmarker}
Turn 495, C (Professor): But see {disfmarker} see my point ? If you had {disfmarker} {vocalsound} If you had ten filters , {vocalsound} then you would be throwing away a lot at the two ends .
Turn 496, E (PhD): Mm - hmm .
Turn 497, C (Professor): And if you had {disfmarker} if you had fifty filters , you 'd be throwing away hardly anything .
Turn 498, E (PhD): Mm - hmm .
Turn 499, C (Professor): Um , I don't remember there being an independent way of saying " we 're just gonna make them from here to here " .
Turn 500, E (PhD): Use this analysis bandwidth or something .
Turn 501, C (Professor): But I {disfmarker} I {disfmarker} I don't know , it 's actually been awhile since I 've looked at it .
Turn 502, E (PhD): Yeah , I went through the Feacalc code and then looked at you know just calling the RASTA libs {comment} and thing like that . And I didn't {disfmarker} I couldn't see any wh place where that kind of thing was done . But um I didn't quite understand everything that I saw ,
Turn 503, C (Professor): Yeah , see I don't know Feacalc at all .
Turn 504, E (PhD): so {disfmarker} Mm - hmm .
Turn 505, C (Professor): But it calls RASTA with some options , and um
Turn 506, E (PhD): Right .
Turn 507, C (Professor): But I {disfmarker} I think in {disfmarker} I don't know . I guess for some particular database you might find that you could tune that and tweak that to get that a little better , but I think that {vocalsound} in general it 's not that critical . I mean there 's {disfmarker}
Turn 508, E (PhD): Yeah .
Turn 509, C (Professor): You can {disfmarker} You can throw away stuff below a hundred hertz or so and it 's just not going to affect phonetic classification at all .
Turn 510, E (PhD): Another thing I was thinking about was um is there a {disfmarker} I was wondering if there 's maybe um {vocalsound} certain settings of the parameters when you compute PLP which would basically cause it to output mel cepstrum . So that , in effect , what I could do is use our code but produce mel cepstrum and compare that directly to {disfmarker}
Turn 511, C (Professor): Well , it 's not precisely . Yeah . I mean ,
Turn 512, E (PhD): Hmm .
Turn 513, C (Professor): um , {vocalsound} um what you can do is um you can definitely change the {disfmarker} the filter bank from being uh a uh trapezoidal integration to a {disfmarker} a {disfmarker} a triangular one ,
Turn 514, E (PhD): Mm - hmm .
Turn 515, C (Professor): which is what the typical mel {disfmarker} mel cepstral uh filter bank does .
Turn 516, E (PhD): Mm - hmm .
Turn 517, C (Professor): And some people have claimed that they got some better performance doing that , so you certainly could do that easily . But the fundamental difference , I mean , there 's other small differences {disfmarker}
Turn 518, E (PhD): There 's a cubic root that happens , right ?
Turn 519, C (Professor): Yeah , but , you know , as opposed to the log in the other case . I mean {vocalsound} the fundamental d d difference that we 've seen any kind of difference from before , which is actually an advantage for the P L P i uh , I think , is that the {disfmarker} the smoothing at the end is auto - regressive instead of being cepstral {disfmarker} uh , {comment} from cepstral truncation . So um it 's a little more noise robust .
Turn 520, E (PhD): Hmm .
Turn 521, C (Professor): Um , and that 's {disfmarker} that 's why when people started getting databases that had a little more noise in it , like {disfmarker} like uh um Broadcast News and so on , that 's why c Cambridge switched to PLP I think .
Turn 522, E (PhD): Mm - hmm .
Turn 523, C (Professor): So um That 's a difference that I don't {vocalsound} think we put any way to get around , since it was an advantage . um {vocalsound} uh
Turn 524, E (PhD): Mm - hmm .
Turn 525, C (Professor): but we did {disfmarker} eh we did hear this comment from people at some point , that {vocalsound} um it uh they got some better results with the triangular filters rather than the trapezoidal . So that is an option in RASTA .
Turn 526, E (PhD): Hmm .
Turn 527, C (Professor): Uh and you can certainly play with that . But I think you 're probably doing the right thing to look for bugs first . I don't know .
Turn 528, E (PhD): Yeah just {disfmarker} it just seems like this kind of behavior could be caused by you know s some of the training data being messed up .
Turn 529, C (Professor): Could be .
Turn 530, E (PhD): You know , you 're sort of getting most of the way there , but there 's a {disfmarker} So I started going through and looking {disfmarker} One of the things that I did notice was that the um log likelihoods coming out of the log recognizer from the PLP data were much lower , much smaller , than for the mel cepstral stuff , and that the average amount of pruning that was happening was therefore a little bit higher for the PLP features .
Turn 531, C (Professor): Oh - huh !
Turn 532, E (PhD): So , since he used the same exact pruning thresholds for both , I was wondering if it could be that we 're getting more pruning .
Turn 533, C (Professor): Oh ! He {disfmarker} he {disfmarker} {vocalsound} He used the identical pruning thresholds even though the s the range of p of the likeli
Turn 534, E (PhD): Yeah .
Turn 535, C (Professor): Oh well that 's {disfmarker} {vocalsound} That 's a pretty good {comment} point right there .
Turn 536, E (PhD): Right . Right .
Turn 537, C (Professor): Yeah .
Turn 538, E (PhD): Yeah ,
Turn 539, C (Professor): I would think that you might wanna do something like uh you know , look at a few points to see where you are starting to get significant search errors .
Turn 540, E (PhD): so {disfmarker} That 's {disfmarker} Right . Well , what I was gonna do is I was gonna take um a couple of the utterances that he had run through , then run them through again but modify the pruning threshold and see if it you know , affects the score .
Turn 541, C (Professor): Yeah . Yeah . But I mean you could {disfmarker} uh if {disfmarker} if {disfmarker} if that looks promising you could , you know , r uh run {vocalsound} the overall test set with a {disfmarker} with a few different uh pruning thresholds for both ,
Turn 542, E (PhD): So . Mm - hmm .
Turn 543, C (Professor): and presumably he 's running at some pruning threshold that 's {disfmarker} that 's uh , you know {disfmarker} gets very few search errors
Turn 544, E (PhD): Right .
Turn 545, C (Professor): but is {disfmarker} is relatively fast
Turn 546, E (PhD): Mm - hmm . Right . I mean , yeah , generally in these things you {disfmarker} you turn back pruning really far ,
Turn 547, C (Professor): and {disfmarker}
Turn 548, E (PhD): so I {disfmarker} I didn't think it would be that big a deal because I was figuring well you have it turned back so far that you know it {disfmarker}
Turn 549, C (Professor): But you may be in the wrong range for the P L P features for some reason .
Turn 550, E (PhD): Yeah . Yeah . Yeah . And the uh the {disfmarker} the run time of the recognizer on the PLP features is longer which sort of implies that the networks are bushier , you know , there 's more things it 's considering which goes along with the fact that the matches aren't as good . So uh , you know , it could be that we 're just pruning too much .
Turn 551, C (Professor): Yeah .
Turn 552, E (PhD): So .
Turn 553, C (Professor): Yeah , maybe just be different kind of distributions and {disfmarker} and
Turn 554, E (PhD): Mm - hmm .
Turn 555, C (Professor): yeah so that 's another possible thing . They {disfmarker} they should {disfmarker} really shouldn't {disfmarker}
Turn 556, E (PhD): Mm - hmm .
Turn 557, C (Professor): There 's no particular reason why they would be exactly {disfmarker} behave exactly the same .
Turn 558, E (PhD): Mm - hmm . Right . Right .
Turn 559, C (Professor): So .
Turn 560, E (PhD): So . There 's lots of little differences .
Turn 561, C (Professor): Yeah .
Turn 562, E (PhD): So . Uh .
Turn 563, C (Professor): Yeah .
Turn 564, E (PhD): Trying to track it down .
Turn 565, C (Professor): Yeah . I guess this was a little bit off topic , I guess , because I was {disfmarker} I was thinking in terms of th this as being a {disfmarker} a {disfmarker} a {disfmarker} a core {vocalsound} item that once we {disfmarker} once we had it going we would use for a number of the front - end things also .
Turn 566, E (PhD): Yeah
Turn 567, C (Professor): So .
Turn 568, E (PhD): Mm - hmm .
Turn 569, C (Professor): um Wanna {disfmarker}
Turn 570, B (Grad): That 's {disfmarker} as far as my stuff goes ,
Turn 571, C (Professor): What 's {disfmarker} what 's on {disfmarker}
Turn 572, B (Grad): yeah , well I {vocalsound} tried this mean subtraction method .
Turn 573, C (Professor): Yeah .
Turn 574, B (Grad): Um . Due to Avendano , {vocalsound} I 'm taking s um {vocalsound} six seconds of speech , um {vocalsound} I 'm using two second {vocalsound} FFT analysis frames , {vocalsound} stepped by a half second so it 's a quarter length step and I {disfmarker} {vocalsound} I take that frame and four f the four {disfmarker} I take {disfmarker} Sorry , I take the current frame and the four past frames and the {vocalsound} four future frames and that adds up to six seconds of speech . And I calculate um {vocalsound} the spectral mean , {vocalsound} of the log magnitude spectrum {pause} over that N . I use that to normalize the s the current center frame {vocalsound} by mean subtraction . And I then {disfmarker} then I move to the next frame and I {disfmarker} {vocalsound} I do it again . Well , actually I calculate all the means first and then I do the subtraction . And um {vocalsound} the {disfmarker} I tried that with HDK , the Aurora setup of HDK training on clean TI - digits , and um {vocalsound} it {disfmarker} it helped um in a phony reverberation case um {vocalsound} where I just used the simulated impulse response um {vocalsound} the error rate went from something like eighty it was from something like eighteen percent {vocalsound} to um four percent . And on meeting rec recorder far mike digits , mike {disfmarker} on channel F , it went from um {vocalsound} {vocalsound} forty - one percent error to eight percent error .
Turn 575, E (PhD): On {disfmarker} on the real data , not with artificial reverb ?
Turn 576, B (Grad): Right .
Turn 577, E (PhD): Uh - huh .
Turn 578, B (Grad): And that {disfmarker} that was um {vocalsound} trained on clean speech only , which I 'm guessing is the reason why the baseline was so bad . And {disfmarker}
Turn 579, C (Professor): That 's ac actually a little side point is I think that 's the first results that we have uh uh uh of any sort on the far field uh {disfmarker} on {disfmarker} on the far field data uh for {disfmarker} recorded in {disfmarker} in meetings .
Turn 580, B (Grad): Oh um actually um Adam ran the SRI recognizer .
Turn 581, C (Professor): Did he ? On the near field , on the ne
Turn 582, B (Grad): On the far field also . He did one PZM channel and one PDA channel .
Turn 583, C (Professor): Oh did he ? Oh ! I didn't recall that . What kind of numbers was he getting with that ?
Turn 584, B (Grad): I {disfmarker} {vocalsound} I 'm not sure , I think it was about five percent error for the PZM channel .
Turn 585, C (Professor): Five .
Turn 586, B (Grad): f I think . Yeah .
Turn 587, C (Professor): So why were you getting forty - one here ? Is this {disfmarker}
Turn 588, B (Grad): Um . I {disfmarker} I 'm g I 'm guessing it was the {disfmarker} the training data . Uh , clean TI - digits is , like , pretty pristine {vocalsound} training data , and if they trained {vocalsound} the SRI system on this TV broadcast type stuff , I think it 's a much wider range of channels and it {disfmarker}
Turn 589, C (Professor): No , but wait a minute . I {disfmarker} I {disfmarker} I th {disfmarker} I think he {disfmarker} What am I saying here ? Yeah , so that was the SRI system . Maybe you 're right . Yeah . Cuz it was getting like one percent {disfmarker} {vocalsound} So it 's still this kind of ratio . It was {disfmarker} it was getting one percent or something on the near field . Wasn't it ?
Turn 590, E (PhD): Mm - hmm , or it wa a it was around one .
Turn 591, C (Professor): Yeah . Yeah . I think it was getting around one percent for the near {disfmarker} for the n for the close mike .
Turn 592, E (PhD): Yeah .
Turn 593, B (Grad): Huh ? OK .
Turn 594, C (Professor): So it was like one to five {disfmarker} So it 's still this kind of ratio . It 's just {disfmarker} yeah , it 's a lot more training data . So So probably it should be something we should try then is to {disfmarker} is to see if {disfmarker} is {vocalsound} at some point just to take {disfmarker} i to transform the data and then {disfmarker} {vocalsound} and then uh use th use it for the SRI system .
Turn 595, B (Grad): b You me you mean um ta
Turn 596, C (Professor): So you 're {disfmarker} so you have a system which for one reason or another is relatively poor ,
Turn 597, B (Grad): Yeah .
Turn 598, C (Professor): and {disfmarker} and uh you have something like forty - one percent error uh and then you transform it to eight by doing {disfmarker} doing this {disfmarker} this work . Um . So here 's this other system , which is a lot better , but there 's still this kind of ratio . It 's something like five percent error {vocalsound} with the {disfmarker} the distant mike , and one percent with the close mike .
Turn 599, B (Grad): OK .
Turn 600, C (Professor): So the question is {vocalsound} how close to that one can you get {vocalsound} if you transform the data using that system .
Turn 601, B (Grad): r Right , so {disfmarker} so I guess this SRI system is trained on a lot of s Broadcast News or Switchboard data . Is that right ?
Turn 602, C (Professor): Yeah .
Turn 603, B (Grad): Do you know which one it is ?
Turn 604, E (PhD): It 's trained on a lot of different things . Um . It 's trained on uh a lot of Switchboard , Call Home ,
Turn 605, B (Grad): Uh - huh .
Turn 606, E (PhD): um a bunch of different sources , some digits , there 's some digits training in there .
Turn 607, B (Grad): OK .
Turn 608, A (Grad): Hmm .
Turn 609, B (Grad): O one thing I 'm wondering about is what this mean subtraction method {vocalsound} um will do if it 's faced with additive noise . Cuz I {disfmarker} I {disfmarker} it 's cuz I don't know what log magnitude spectral subtraction is gonna do to additive noise .
Turn 610, C (Professor): Yeah ,
Turn 611, B (Grad): That 's {disfmarker} that 's the {disfmarker}
Turn 612, C (Professor): well , it 's {disfmarker} it 's not exactly the right thing
Turn 613, B (Grad): Uh - huh .
Turn 614, C (Professor): but {vocalsound} uh {vocalsound} but you 've already seen that cuz there is added noise here .
Turn 615, B (Grad): That 's {disfmarker} that 's {disfmarker} Yeah , that 's true . That 's a good point .
Turn 616, C (Professor): Yeah . So um {disfmarker}
Turn 617, B (Grad): OK , so it 's then {disfmarker} then it 's {disfmarker} it 's {disfmarker} it 's reasonable to expect it would be helpful if we used it with the SRI system and
Turn 618, C (Professor): Yeah , I mean , as helpful {disfmarker} I mean , so that 's the question . Yeah , w we 're often asked this when we work with a system that {disfmarker} that isn't {disfmarker} isn't sort of industry {disfmarker} industry standard great ,
Turn 619, B (Grad): Uh - huh .
Turn 620, C (Professor): uh and we see some reduction in error using some clever method , then , you know , will it work on a {disfmarker} {vocalsound} on a {disfmarker} on a good system . So uh you know , this other one 's {disfmarker} it was a pretty good system . I think , you know , one {disfmarker} one percent word error rate on digits is {disfmarker} uh digit strings is not {vocalsound} uh you know stellar , but {disfmarker} but given that this is real {vocalsound} digits , as opposed to uh sort of laboratory {disfmarker}
Turn 621, B (Grad): Mm - hmm .
Turn 622, C (Professor): Well .
Turn 623, E (PhD): And it wasn't trained on this task either .
Turn 624, C (Professor): And it wasn't trained on this task . Actually one percent is sort of {disfmarker} you know , sort of in a reasonable range .
Turn 625, B (Grad): Mm - hmm .
Turn 626, C (Professor): People would say " yeah , I could {disfmarker} I can imagine getting that " . And uh so the {disfmarker} the four or five percent or something is {disfmarker} is {disfmarker} is quite poor .
Turn 627, B (Grad): Mm - hmm .
Turn 628, C (Professor): Uh , you know , if you 're doing a uh {disfmarker} {vocalsound} a sixteen digit uh credit card number you 'll basically get it wrong almost all the time .
Turn 629, B (Grad): Hmm .
Turn 630, C (Professor): So . So . Uh , {vocalsound} um a significant reduction in the error for that would be great .
Turn 631, B (Grad): Huh , OK .
Turn 632, C (Professor): And {disfmarker} and then , uh Yeah . So . Yeah . Cool .
Turn 633, B (Grad): Sounds good .
Turn 634, C (Professor): Yeah . Alright , um , I actually have to run . So I don't think I can do the digits , but um , {vocalsound} I guess I 'll leave my microphone on ?
Turn 635, E (PhD): Uh , yeah .
Turn 636, C (Professor): Yeah . Thank you .
Turn 637, E (PhD): Yep . Yeah . That 'll work .
Turn 638, C (Professor):  I can be out of here quickly . {comment} {comment} {vocalsound} {vocalsound} That 's I just have to run for another appointment . OK ,  I t Yeah . I left it on . OK .
