{"metadata": {"meeting_name": "Bro016"}, "turns": [{"turn": 1, "name": "Professor", "id": "E", "contribution": " Let 's see . Test ? Test ? Yeah . OK ."}, {"turn": 2, "name": "Grad", "id": "A", "contribution": " Hello ?"}, {"turn": 3, "name": "PhD", "id": "B", "contribution": " Channel one ."}, {"turn": 4, "name": "Grad", "id": "A", "contribution": " Hello ?"}, {"turn": 5, "name": "PhD", "id": "C", "contribution": " Test ."}, {"turn": 6, "name": "Professor", "id": "E", "contribution": " I was saying Hynek 'll be here next week , uh , Wednesday through Friday {disfmarker} uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh , {vocalsound} as far as I know , so {disfmarker} There we go ."}, {"turn": 7, "name": "PhD", "id": "F", "contribution": " OK ."}, {"turn": 8, "name": "Professor", "id": "E", "contribution": " Um . So other than reading digits , what 's our agenda ?"}, {"turn": 9, "name": "PhD", "id": "F", "contribution": " I don't really have , uh , anything new . Been working on {pause} Meeting Recorder stuff . So ."}, {"turn": 10, "name": "Professor", "id": "E", "contribution": " OK . Um . Do you think that would be the case for next week also ? Or is {disfmarker} is , uh {disfmarker} ? What 's your projection on {disfmarker} ?"}, {"turn": 11, "name": "PhD", "id": "F", "contribution": " Um ."}, {"turn": 12, "name": "Professor", "id": "E", "contribution": " Cuz the one thing {disfmarker} the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me {disfmarker} it was sort of an obvious thing {disfmarker} is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff ."}, {"turn": 13, "name": "PhD", "id": "F", "contribution": " I did play with that , actually , a little bit . Um . What happens is , uh , {vocalsound} when you get to the noisy stuff , you start getting lots of insertions ."}, {"turn": 14, "name": "Professor", "id": "E", "contribution": " Right ."}, {"turn": 15, "name": "PhD", "id": "F", "contribution": " And , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that ."}, {"turn": 16, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 17, "name": "PhD", "id": "F", "contribution": " Um . I mean , it {disfmarker} it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um . {vocalsound} I could do more playing with that , though . And , uh {disfmarker}"}, {"turn": 18, "name": "Professor", "id": "E", "contribution": " But you were looking at mel cepstrum ."}, {"turn": 19, "name": "PhD", "id": "F", "contribution": " and see . Yes ."}, {"turn": 20, "name": "Professor", "id": "E", "contribution": " Right ."}, {"turn": 21, "name": "PhD", "id": "F", "contribution": " Oh , you 're talking about for th {vocalsound} for our features ."}, {"turn": 22, "name": "Professor", "id": "E", "contribution": " Right . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the {disfmarker} uh , what 's the best you can do with {disfmarker} with mel cepstrum . But , they raised a very valid point ,"}, {"turn": 23, "name": "PhD", "id": "F", "contribution": " Mmm ."}, {"turn": 24, "name": "Professor", "id": "E", "contribution": " which , I guess {disfmarker} So , to first order {disfmarker} I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @ {comment} with , uh , you know , how many states and so forth , that it {disfmarker} it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,"}, {"turn": 25, "name": "PhD", "id": "F", "contribution": " Right ."}, {"turn": 26, "name": "Professor", "id": "E", "contribution": " but , um , let 's just {disfmarker} If we had to {disfmarker} if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?"}, {"turn": 27, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 28, "name": "Professor", "id": "E", "contribution": " Uh , so the next question to ask , which is I think the one that {disfmarker} that {disfmarker} that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would ."}, {"turn": 29, "name": "PhD", "id": "F", "contribution": " Yeah ."}, {"turn": 30, "name": "Professor", "id": "E", "contribution": " So , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum ."}, {"turn": 31, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 32, "name": "Professor", "id": "E", "contribution": " But , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with {disfmarker} with LDA and KLT and neural nets and {vocalsound} all these things . In the fa past we 've always found that we had to increase the insertion penalty to {disfmarker} to correspond to such things . So , I think that 's , uh , @ @ {comment} that 's kind of a first - order thing that {disfmarker} that we should try ."}, {"turn": 33, "name": "PhD", "id": "F", "contribution": " So for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes"}, {"turn": 34, "name": "Professor", "id": "E", "contribution": " So by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something ."}, {"turn": 35, "name": "PhD", "id": "F", "contribution": " if we were {disfmarker} Mm - hmm ."}, {"turn": 36, "name": "Professor", "id": "E", "contribution": " Um . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How {disfmarker} how much , uh , does it improve if you actually adjust that ?"}, {"turn": 37, "name": "PhD", "id": "F", "contribution": " OK ."}, {"turn": 38, "name": "Professor", "id": "E", "contribution": " But it is interesting . You say you {disfmarker} you have for the noisy {disfmarker} How about for the {disfmarker} for the mismatched or {disfmarker} or {disfmarker} or {disfmarker} or the {disfmarker} or the medium mismatched conditions ? Have you {disfmarker} ? When you adjusted those numbers for mel cepstrum , did it {disfmarker} ?"}, {"turn": 39, "name": "PhD", "id": "F", "contribution": " Uh , I {disfmarker} I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I {disfmarker} I {disfmarker} I don't remember . I would need to {disfmarker} Well , I did write down , um {disfmarker} So , when I was doing {disfmarker} I just wrote down some numbers for the well - matched case ."}, {"turn": 40, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 41, "name": "PhD", "id": "F", "contribution": " Um . Looking at the {disfmarker} I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone ."}, {"turn": 42, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 43, "name": "PhD", "id": "F", "contribution": " Um , but , uh , that {disfmarker} that 's all I wrote down ."}, {"turn": 44, "name": "Professor", "id": "E", "contribution": " OK ."}, {"turn": 45, "name": "PhD", "id": "F", "contribution": " So . I {disfmarker} I would {disfmarker} Yeah . I would need to do that ."}, {"turn": 46, "name": "Professor", "id": "E", "contribution": " OK . So {disfmarker}"}, {"turn": 47, "name": "PhD", "id": "F", "contribution": " I can do that for next week ."}, {"turn": 48, "name": "Professor", "id": "E", "contribution": " Yeah . And , um {disfmarker} Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But {disfmarker} but I think it would be {disfmarker} it 'd be good to know that ."}, {"turn": 49, "name": "PhD", "id": "F", "contribution": " OK . I just need to get , um , {vocalsound} front - end , uh , stuff from you"}, {"turn": 50, "name": "PhD", "id": "B", "contribution": " Hmm ."}, {"turn": 51, "name": "PhD", "id": "F", "contribution": " or you point me to some files {pause} that you 've already calculated ."}, {"turn": 52, "name": "PhD", "id": "B", "contribution": " Yeah . Alright ."}, {"turn": 53, "name": "Professor", "id": "E", "contribution": " OK . Uh ."}, {"turn": 54, "name": "PhD", "id": "F", "contribution": " I probably will have time to do that and time to play a little bit with the silence model ."}, {"turn": 55, "name": "Professor", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 56, "name": "PhD", "id": "F", "contribution": " So maybe I can have that for next week when Hynek 's here ."}, {"turn": 57, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 58, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 59, "name": "Professor", "id": "E", "contribution": " Yeah . Cuz , I mean , the {disfmarker} the other {disfmarker} That , in fact , might have been part of what , uh , the difference was {disfmarker} at least part of it that {disfmarker} that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system ."}, {"turn": 60, "name": "PhD", "id": "F", "contribution": " Hmm ."}, {"turn": 61, "name": "Professor", "id": "E", "contribution": " Part of it might just be that the SRI system , they {disfmarker} they {disfmarker} they always adjust these things to be sort of optimized ,"}, {"turn": 62, "name": "PhD", "id": "F", "contribution": " Is there {disfmarker} ?"}, {"turn": 63, "name": "Professor", "id": "E", "contribution": " and {disfmarker}"}, {"turn": 64, "name": "PhD", "id": "F", "contribution": " I wonder if there 's anything that we could do {vocalsound} to the front - end that would affect the insertion {disfmarker}"}, {"turn": 65, "name": "Professor", "id": "E", "contribution": " Yes . I think you can ."}, {"turn": 66, "name": "PhD", "id": "F", "contribution": " What could you do ?"}, {"turn": 67, "name": "Professor", "id": "E", "contribution": " Well , um {disfmarker} uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root ."}, {"turn": 68, "name": "PhD", "id": "F", "contribution": " Oh . Mm - hmm ."}, {"turn": 69, "name": "Professor", "id": "E", "contribution": " You know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven ."}, {"turn": 70, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 71, "name": "Professor", "id": "E", "contribution": " But {disfmarker} but , um , that has a similar effect because it changes the scale of the numbers {disfmarker} of the differences between different candidates from the acoustic model"}, {"turn": 72, "name": "PhD", "id": "F", "contribution": " Oh , right ."}, {"turn": 73, "name": "Professor", "id": "E", "contribution": " as opposed to what 's coming from the language model ."}, {"turn": 74, "name": "PhD", "id": "F", "contribution": " So that w Right . So , in effect , that 's changing the value of your insertion penalty ."}, {"turn": 75, "name": "Professor", "id": "E", "contribution": " Yeah . I mean , it 's more directly like the {disfmarker} the language scaling or the , uh {disfmarker} the model scaling or acoustic scaling ,"}, {"turn": 76, "name": "PhD", "id": "F", "contribution": " That 's interesting ."}, {"turn": 77, "name": "Professor", "id": "E", "contribution": " but you know that those things have kind of a similar effect to the insertion penalty"}, {"turn": 78, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 79, "name": "Professor", "id": "E", "contribution": " anyway . They 're a slightly different way of {disfmarker} of handling it ."}, {"turn": 80, "name": "PhD", "id": "F", "contribution": " Right ."}, {"turn": 81, "name": "Professor", "id": "E", "contribution": " So , um {disfmarker}"}, {"turn": 82, "name": "PhD", "id": "F", "contribution": " So if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,"}, {"turn": 83, "name": "Professor", "id": "E", "contribution": " I think so ."}, {"turn": 84, "name": "PhD", "id": "F", "contribution": " so that they {pause} match with that ."}, {"turn": 85, "name": "Professor", "id": "E", "contribution": " Yeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing {disfmarker} ? Y y"}, {"turn": 86, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 87, "name": "Professor", "id": "E", "contribution": " I 'm sure you 've already looked at this bu in these noisy cases , are {disfmarker} ? We are seeing lots of insertions . Right ? The insertion number is quite high ?"}, {"turn": 88, "name": "PhD", "id": "B", "contribution": " Yeah ."}, {"turn": 89, "name": "Professor", "id": "E", "contribution": " I know the VAD takes pre care of part of that ,"}, {"turn": 90, "name": "PhD", "id": "F", "contribution": " Yeah ."}, {"turn": 91, "name": "PhD", "id": "B", "contribution": " Yeah ."}, {"turn": 92, "name": "Professor", "id": "E", "contribution": " but {disfmarker}"}, {"turn": 93, "name": "PhD", "id": "F", "contribution": " I 've seen that with the mel cepstrum . I don't {disfmarker} I don't know about {pause} the Aurora front - end , but {disfmarker}"}, {"turn": 94, "name": "PhD", "id": "B", "contribution": " I think it 's much more balanced with , uh {disfmarker} when the front - end is more robust . Yeah . I could look at it {disfmarker} at this . Yeah . Mm - hmm ."}, {"turn": 95, "name": "Professor", "id": "E", "contribution": " Yeah . Wha - what 's a typical number ?"}, {"turn": 96, "name": "PhD", "id": "B", "contribution": " I don't {disfmarker} I don't know ."}, {"turn": 97, "name": "Professor", "id": "E", "contribution": " Do we {disfmarker} ? Oh , you {disfmarker} oh , you don't know ."}, {"turn": 98, "name": "PhD", "id": "B", "contribution": " I don't have this in {disfmarker}"}, {"turn": 99, "name": "Professor", "id": "E", "contribution": " OK . I 'm sure it 's more balanced ,"}, {"turn": 100, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 101, "name": "Professor", "id": "E", "contribution": " but it {disfmarker} it {disfmarker} it wouldn't surprise me if there 's still {disfmarker}"}, {"turn": 102, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 103, "name": "Professor", "id": "E", "contribution": " I mean , in {disfmarker} in the {disfmarker} the {disfmarker} the old systems we used to do , I {disfmarker} I {disfmarker} uh , I remember numbers kind of like insertions being half the number of deletions , as being {disfmarker} and both numbers being {disfmarker} tend to be on the small side comparing to {disfmarker} to , uh , substitutions ."}, {"turn": 104, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 105, "name": "PhD", "id": "F", "contribution": " Well , this {disfmarker} the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down {pause} that one time and {disfmarker} and that was when people were saying , well we should have a , uh , uh , voice activity detector {disfmarker}"}, {"turn": 106, "name": "Professor", "id": "E", "contribution": " Right ."}, {"turn": 107, "name": "PhD", "id": "F", "contribution": " that , because all that stuff {comment} that we 're getting thr the silence that 's getting through is causing insertions . So ."}, {"turn": 108, "name": "PhD", "id": "B", "contribution": " Mmm ."}, {"turn": 109, "name": "Professor", "id": "E", "contribution": " Right ."}, {"turn": 110, "name": "PhD", "id": "F", "contribution": " I 'll bet you there 's still a lot {vocalsound} of insertions ."}, {"turn": 111, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 112, "name": "Professor", "id": "E", "contribution": " Yeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range ."}, {"turn": 113, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 114, "name": "Professor", "id": "E", "contribution": " So , I mean , the insertions is {disfmarker} is a symptom . It 's a symptom that there 's something , uh , wrong with the range ."}, {"turn": 115, "name": "PhD", "id": "F", "contribution": " Right ."}, {"turn": 116, "name": "Professor", "id": "E", "contribution": " But there 's {disfmarker} uh , your {disfmarker} your {disfmarker} your substitutions tend to go up as well . So , uh , I {disfmarker} I {disfmarker} I think that ,"}, {"turn": 117, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 118, "name": "Professor", "id": "E", "contribution": " uh , the most obvious thing is just the insertions , @ @ . But {disfmarker} Uh {disfmarker} um . If you 're operating in the wrong range {disfmarker} I mean , that 's why just in general , if you {vocalsound} change what these {disfmarker} these penalties and scaling factors are , you reach some point that 's a {disfmarker} that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we {disfmarker} if we see {disfmarker} Um , I mean we ca it 's if we actually could pick a {disfmarker} a {disfmarker} a more stable value for the range of these features , it , um , uh , could {disfmarker} Uh {disfmarker} Even though it 's {disfmarker} it 's {disfmarker} it 's true that in a real situation you can in fact adjust the {disfmarker} these {disfmarker} these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range {disfmarker}"}, {"turn": 119, "name": "PhD", "id": "F", "contribution": " Hmm ."}, {"turn": 120, "name": "Professor", "id": "E", "contribution": " I remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a {disfmarker}"}, {"turn": 121, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 122, "name": "Professor", "id": "E", "contribution": " for an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and {disfmarker} Uh , we might just not even be in the right operating range ."}, {"turn": 123, "name": "PhD", "id": "F", "contribution": " So , would the {disfmarker} ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as {disfmarker} ?"}, {"turn": 124, "name": "Professor", "id": "E", "contribution": " No . You don't wanna change it for different conditions . No . No . I {disfmarker} I {disfmarker} I {disfmarker} What {disfmarker} what I 'm saying {disfmarker}"}, {"turn": 125, "name": "PhD", "id": "F", "contribution": " Oh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we {disfmarker} we wanna pick a range that we map our numbers into {disfmarker}"}, {"turn": 126, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 127, "name": "PhD", "id": "F", "contribution": " we should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to {disfmarker} to map everything into ?"}, {"turn": 128, "name": "Professor", "id": "E", "contribution": " Well . It depends how much we wanna do gamesmanship and how much we wanna do {disfmarker} I mean , i if he it {disfmarker} to me , actually , even if you wanna be {disfmarker} play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the {disfmarker} set the scaling factors , uh , so that you got the best number for this point four five times the {disfmarker} {vocalsound} you know , and so on ."}, {"turn": 129, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 130, "name": "Professor", "id": "E", "contribution": " But they might change that {disfmarker} those weightings ."}, {"turn": 131, "name": "PhD", "id": "F", "contribution": " Yeah ."}, {"turn": 132, "name": "Professor", "id": "E", "contribution": " Um . So {disfmarker} Uh {disfmarker} I just sorta think we need to explore the space . Just take a look at it a little bit ."}, {"turn": 133, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 134, "name": "Professor", "id": "E", "contribution": " And we {disfmarker} we {disfmarker} we may just find that {disfmarker} that we 're way off ."}, {"turn": 135, "name": "PhD", "id": "F", "contribution": " OK . Mm - hmm ."}, {"turn": 136, "name": "Professor", "id": "E", "contribution": " Maybe we 're not . You know ? As for these other things , it may turn out that , uh , {vocalsound} it 's kind of reasonable . But then {disfmarker} I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future {disfmarker} of , you know , people {disfmarker} people within this tight - knit community who are doing this evaluation {vocalsound} are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,"}, {"turn": 137, "name": "PhD", "id": "F", "contribution": " Yeah ."}, {"turn": 138, "name": "Professor", "id": "E", "contribution": " when all you could do is just adjust this in the back - end with one s one knob . \""}, {"turn": 139, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 140, "name": "Professor", "id": "E", "contribution": " And so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with {disfmarker} with what we 're doing . And as you say {disfmarker} as you point out {disfmarker} finding ways to then compensate for that in the front - end {vocalsound} also then becomes a priority for this particular test ,"}, {"turn": 141, "name": "PhD", "id": "F", "contribution": " Right ."}, {"turn": 142, "name": "Professor", "id": "E", "contribution": " and saying you don't have to do that ."}, {"turn": 143, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 144, "name": "Professor", "id": "E", "contribution": " So . OK . So , uh {disfmarker} What 's new with you ?"}, {"turn": 145, "name": "PhD", "id": "B", "contribution": " Uh . So there 's nothing {pause} new . Um ."}, {"turn": 146, "name": "Professor", "id": "E", "contribution": " Uh , what 's old with you that 's developed ?"}, {"turn": 147, "name": "PhD", "id": "B", "contribution": " I 'm sorry ?"}, {"turn": 148, "name": "Professor", "id": "E", "contribution": " You {disfmarker} OK . What 's old with you that has developed over the last week or two ?"}, {"turn": 149, "name": "PhD", "id": "B", "contribution": " Mmm . Well , so we 've been mainly working on the report and {disfmarker} and {disfmarker} Yeah ."}, {"turn": 150, "name": "PhD", "id": "F", "contribution": " Mainly working on what ?"}, {"turn": 151, "name": "PhD", "id": "B", "contribution": " On the report {pause} of the work that was already done ."}, {"turn": 152, "name": "PhD", "id": "F", "contribution": " Oh ."}, {"turn": 153, "name": "PhD", "id": "B", "contribution": " Um . Mm - hmm . That 's all ."}, {"turn": 154, "name": "PhD", "id": "F", "contribution": " How about that {disfmarker} ? Any - anything new on the thing that , uh , you were working on with the , uh {disfmarker} ?"}, {"turn": 155, "name": "PhD", "id": "C", "contribution": " I don't have results yet ."}, {"turn": 156, "name": "PhD", "id": "F", "contribution": " No results ? Yeah ."}, {"turn": 157, "name": "Professor", "id": "E", "contribution": " What was that ?"}, {"turn": 158, "name": "PhD", "id": "F", "contribution": " The {disfmarker} the , uh ,"}, {"turn": 159, "name": "Grad", "id": "A", "contribution": " Voicing thing ."}, {"turn": 160, "name": "PhD", "id": "F", "contribution": " voicing detector ."}, {"turn": 161, "name": "Professor", "id": "E", "contribution": " I mean , what what 's {disfmarker} what 's going on now ? What are you {pause} doing ?"}, {"turn": 162, "name": "PhD", "id": "C", "contribution": " Uh , to try to found , nnn , robust feature for detect between voice and unvoice . And we {disfmarker} w we try to use {vocalsound} the variance {vocalsound} of the es difference between the FFT spectrum and mel filter bank spectrum ."}, {"turn": 163, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 164, "name": "PhD", "id": "C", "contribution": " Uh , also the {disfmarker} another parameter is {disfmarker} relates with the auto - correlation function ."}, {"turn": 165, "name": "Professor", "id": "E", "contribution": " Uh - huh ."}, {"turn": 166, "name": "PhD", "id": "C", "contribution": " R - ze energy and the variance a also of the auto - correlation function ."}, {"turn": 167, "name": "Professor", "id": "E", "contribution": " Uh - huh . So , that 's {disfmarker} Yeah . That 's what you were describing , I guess , a week or two ago ."}, {"turn": 168, "name": "PhD", "id": "C", "contribution": " Yeah . But we don't have res we don't have result of the AURO for Aurora yet ."}, {"turn": 169, "name": "Professor", "id": "E", "contribution": " So ."}, {"turn": 170, "name": "PhD", "id": "C", "contribution": " We need to train the neural network"}, {"turn": 171, "name": "Professor", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 172, "name": "PhD", "id": "C", "contribution": " and {disfmarker}"}, {"turn": 173, "name": "Professor", "id": "E", "contribution": " So you 're training neural networks now ?"}, {"turn": 174, "name": "PhD", "id": "C", "contribution": " No , not yet ."}, {"turn": 175, "name": "Professor", "id": "E", "contribution": " So , what {disfmarker} wha {vocalsound} wh wha what what 's going on ?"}, {"turn": 176, "name": "PhD", "id": "C", "contribution": " Well , we work in the report , too , because we have a lot of result ,"}, {"turn": 177, "name": "Professor", "id": "E", "contribution": " Uh - huh ."}, {"turn": 178, "name": "PhD", "id": "C", "contribution": " they are very dispersed , and was necessary to {disfmarker} to look in all the directory to {disfmarker} to {disfmarker} to give some more structure ."}, {"turn": 179, "name": "PhD", "id": "B", "contribution": " Yea"}, {"turn": 180, "name": "Professor", "id": "E", "contribution": " So . B So {disfmarker} Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens ."}, {"turn": 181, "name": "PhD", "id": "C", "contribution": " Hm - hmm ."}, {"turn": 182, "name": "PhD", "id": "B", "contribution": " Uh , y yeah . Basically we we 've stopped , uh , experimenting ,"}, {"turn": 183, "name": "Professor", "id": "E", "contribution": " Yes ?"}, {"turn": 184, "name": "PhD", "id": "B", "contribution": " I mean . We 're just writing some kind of technical report . And {disfmarker}"}, {"turn": 185, "name": "PhD", "id": "F", "contribution": " Is this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,"}, {"turn": 186, "name": "PhD", "id": "C", "contribution": " No ."}, {"turn": 187, "name": "PhD", "id": "B", "contribution": " Yeah ."}, {"turn": 188, "name": "PhD", "id": "C", "contribution": " For ICSI ."}, {"turn": 189, "name": "PhD", "id": "F", "contribution": " or {disfmarker} ? Ah . I see ."}, {"turn": 190, "name": "PhD", "id": "B", "contribution": " Yeah ."}, {"turn": 191, "name": "PhD", "id": "C", "contribution": " Just summary of the experiment and the conclusion and something like that ."}, {"turn": 192, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 193, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 194, "name": "Professor", "id": "E", "contribution": " OK . So , my suggestion , though , is that you {disfmarker} you not necessarily finish that . But that you put it all together so that it 's {disfmarker} you 've got {disfmarker} you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up ."}, {"turn": 195, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 196, "name": "Professor", "id": "E", "contribution": " So that , you know {disfmarker} so that such a thing can be written . And , um {disfmarker} When {disfmarker} when {disfmarker} when do you leave again ?"}, {"turn": 197, "name": "PhD", "id": "C", "contribution": " Uh , in July . First of July ."}, {"turn": 198, "name": "Professor", "id": "E", "contribution": " First of July ? OK . And that you figure on actually finishing it in {disfmarker} in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway ."}, {"turn": 199, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 200, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 201, "name": "Professor", "id": "E", "contribution": " And right now it 's kind of important that we actually go forward with experiments ."}, {"turn": 202, "name": "PhD", "id": "C", "contribution": " It 's not ."}, {"turn": 203, "name": "Professor", "id": "E", "contribution": " So {disfmarker} so , I {disfmarker} I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think {vocalsound} to {disfmarker} to really work on {disfmarker} on fine - tuning the report n at this point is {disfmarker} is probably bad timing , I {disfmarker} I {pause} think ."}, {"turn": 204, "name": "PhD", "id": "B", "contribution": " Mm - hmm . Yeah . Well , we didn't {disfmarker} we just planned to work on it one week on this report , not {disfmarker} no more , anyway . Um ."}, {"turn": 205, "name": "Professor", "id": "E", "contribution": " But you ma you may really wanna add other things later anyway"}, {"turn": 206, "name": "PhD", "id": "B", "contribution": " Yeah . Mm - hmm ."}, {"turn": 207, "name": "Professor", "id": "E", "contribution": " because you {disfmarker}"}, {"turn": 208, "name": "PhD", "id": "B", "contribution": " Mmm ."}, {"turn": 209, "name": "Professor", "id": "E", "contribution": " There 's more to go ?"}, {"turn": 210, "name": "PhD", "id": "B", "contribution": " Yeah . Well , so I don't know . There are small things that we started to {disfmarker} to do . But {disfmarker}"}, {"turn": 211, "name": "PhD", "id": "F", "contribution": " Are you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,"}, {"turn": 212, "name": "PhD", "id": "B", "contribution": " Uh ."}, {"turn": 213, "name": "PhD", "id": "F", "contribution": " or {disfmarker} ?"}, {"turn": 214, "name": "PhD", "id": "B", "contribution": " Yeah . Yeah . And {disfmarker} Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything ."}, {"turn": 215, "name": "PhD", "id": "F", "contribution": " Mmm ."}, {"turn": 216, "name": "PhD", "id": "B", "contribution": " But anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from {pause} the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora {disfmarker} the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises {disfmarker} on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So {disfmarker} adding the noises from {disfmarker} from the SpeechDat - Car . Um ."}, {"turn": 217, "name": "Professor", "id": "E", "contribution": " That 's {disfmarker} that 's , uh {disfmarker} that 's permitted ?"}, {"turn": 218, "name": "PhD", "id": "B", "contribution": " Uh . Well , OGI does {disfmarker} did that . Um . At some point they did that for {disfmarker} for the voice activity detector ."}, {"turn": 219, "name": "PhD", "id": "C", "contribution": " Uh , for a v VAD ."}, {"turn": 220, "name": "PhD", "id": "B", "contribution": " Right ? Um ."}, {"turn": 221, "name": "PhD", "id": "F", "contribution": " Could you say it again ? What {disfmarker} what exactly did they do ?"}, {"turn": 222, "name": "PhD", "id": "B", "contribution": " They used some parts of the , um , Italian database to train the voice activity detector , I think . It {disfmarker}"}, {"turn": 223, "name": "Professor", "id": "E", "contribution": " Yeah . I guess the thing is {disfmarker} Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English {disfmarker} no , Italian and the Finnish and the English ? {disfmarker} were development data"}, {"turn": 224, "name": "PhD", "id": "B", "contribution": " Yeah . And Spanish , yeah ."}, {"turn": 225, "name": "Professor", "id": "E", "contribution": " on which you could adjust things . And the {disfmarker} and the German and Danish were the evaluation data ."}, {"turn": 226, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 227, "name": "Professor", "id": "E", "contribution": " And then when they finally actually evaluated things they used everything ."}, {"turn": 228, "name": "PhD", "id": "B", "contribution": " Yeah . That 's right . Uh {disfmarker}"}, {"turn": 229, "name": "Professor", "id": "E", "contribution": " So {disfmarker} Uh , and it is true that the performance , uh , on the German was {disfmarker} I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good ."}, {"turn": 230, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 231, "name": "Professor", "id": "E", "contribution": " So {disfmarker} And , uh , it {disfmarker} it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that {disfmarker} that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh {disfmarker} I mean they were different drives ."}, {"turn": 232, "name": "PhD", "id": "B", "contribution": " Different cars . Yeah ."}, {"turn": 233, "name": "Professor", "id": "E", "contribution": " I mean , it was {disfmarker} it was actual different cars and so on ."}, {"turn": 234, "name": "PhD", "id": "B", "contribution": " Yeah ."}, {"turn": 235, "name": "Professor", "id": "E", "contribution": " So . Um , it 's somewhat tuned . It 's tuned more than , you know , a {disfmarker} a {disfmarker} a {disfmarker} a {disfmarker}"}, {"turn": 236, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 237, "name": "Professor", "id": "E", "contribution": " You 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most ."}, {"turn": 238, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 239, "name": "Professor", "id": "E", "contribution": " But that 's not really what this contest is . So . Um , I guess it 's OK ."}, {"turn": 240, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 241, "name": "Professor", "id": "E", "contribution": " That 's something I 'd like to understand before we actually use something from it ,"}, {"turn": 242, "name": "PhD", "id": "F", "contribution": " I think it 's {disfmarker}"}, {"turn": 243, "name": "Professor", "id": "E", "contribution": " because it would {disfmarker}"}, {"turn": 244, "name": "PhD", "id": "F", "contribution": " it 's probably something that , mmm , the {disfmarker} you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just {pause} doing signal - processing ."}, {"turn": 245, "name": "PhD", "id": "B", "contribution": " Yeah ."}, {"turn": 246, "name": "Professor", "id": "E", "contribution": " Well , it 's true ,"}, {"turn": 247, "name": "PhD", "id": "F", "contribution": " So ."}, {"turn": 248, "name": "Professor", "id": "E", "contribution": " except that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that ."}, {"turn": 249, "name": "PhD", "id": "F", "contribution": " Yeah . That 's true ."}, {"turn": 250, "name": "Professor", "id": "E", "contribution": " Um ."}, {"turn": 251, "name": "PhD", "id": "F", "contribution": " And they didn't forbid us {disfmarker} right ? {disfmarker} to build models on the data ?"}, {"turn": 252, "name": "Professor", "id": "E", "contribution": " No . But , I think {disfmarker} I think that it {disfmarker} it {disfmarker} it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that {disfmarker} that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would ."}, {"turn": 253, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 254, "name": "Professor", "id": "E", "contribution": " Um . But , uh , it 's true . You know , maybe there 's parameters that other people have used {disfmarker} you know , th that they have tuned in some way for other things . So it 's {disfmarker} it 's , uh {disfmarker} We should {disfmarker} we should {disfmarker} Maybe {disfmarker} that 's maybe a topic {disfmarker} Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek"}, {"turn": 255, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 256, "name": "Professor", "id": "E", "contribution": " to , you know , double check it 's OK ."}, {"turn": 257, "name": "PhD", "id": "F", "contribution": " Do we know anything about {pause} the speakers for each of the , uh , training utterances ?"}, {"turn": 258, "name": "PhD", "id": "B", "contribution": " What do you mean ? We {disfmarker} we {disfmarker}"}, {"turn": 259, "name": "PhD", "id": "F", "contribution": " Do you have speaker information ?"}, {"turn": 260, "name": "Professor", "id": "E", "contribution": " Social security number"}, {"turn": 261, "name": "PhD", "id": "F", "contribution": " That would be good ."}, {"turn": 262, "name": "PhD", "id": "B", "contribution": " Like , we have {pause} male , female ,"}, {"turn": 263, "name": "PhD", "id": "C", "contribution": " Hmm ."}, {"turn": 264, "name": "PhD", "id": "F", "contribution": " Bank PIN ."}, {"turn": 265, "name": "PhD", "id": "B", "contribution": " at least ."}, {"turn": 266, "name": "PhD", "id": "F", "contribution": " Just male f female ?"}, {"turn": 267, "name": "PhD", "id": "B", "contribution": " Mmm ."}, {"turn": 268, "name": "Professor", "id": "E", "contribution": " What kind of information do you mean ?"}, {"turn": 269, "name": "PhD", "id": "F", "contribution": " Well , I was thinking about things like , you know , gender , uh {disfmarker} you know , gender - specific nets and , uh , vocal tract length normalization ."}, {"turn": 270, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 271, "name": "PhD", "id": "F", "contribution": " Things like that . I d I don't {disfmarker} I didn't know what information we have about the speakers that we could try to take advantage of ."}, {"turn": 272, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 273, "name": "Professor", "id": "E", "contribution": " Hmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're {vocalsound} supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure {disfmarker} I mean , having the two nets {disfmarker} Suppose you detected that it was male , it was female {disfmarker} you come up with different {disfmarker}"}, {"turn": 274, "name": "PhD", "id": "F", "contribution": " Well , you could put them both in as separate streams or something . Uh ."}, {"turn": 275, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 276, "name": "Professor", "id": "E", "contribution": " Maybe ."}, {"turn": 277, "name": "PhD", "id": "F", "contribution": " I don't know . I was just wondering if there was other information we could exploit ."}, {"turn": 278, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 279, "name": "Professor", "id": "E", "contribution": " Hmm . Yeah , it 's an interesting thought . Maybe having something along the {disfmarker} I mean , you can't really do vocal tract normalization . But something that had some of that effect"}, {"turn": 280, "name": "PhD", "id": "F", "contribution": " Yeah ."}, {"turn": 281, "name": "Professor", "id": "E", "contribution": " being applied to the data in some way ."}, {"turn": 282, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 283, "name": "Professor", "id": "E", "contribution": " Um ."}, {"turn": 284, "name": "PhD", "id": "B", "contribution": " Do you have something simple in mind for {disfmarker} I mean , vocal tract length normalization ?"}, {"turn": 285, "name": "PhD", "id": "F", "contribution": " Uh no . I hadn't {disfmarker} I hadn't thought {disfmarker} it was {disfmarker} thought too much about it , really . It just {disfmarker} something that popped into my head just now . And so I {disfmarker} I {disfmarker} I mean , you could maybe use the ideas {disfmarker} a similar {pause} idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance {disfmarker} like , the likelihood of each utterance . You divide the {disfmarker} the range of the likelihoods up into discrete bins and then each bin 's got some knob {disfmarker} uh , setting ."}, {"turn": 286, "name": "Professor", "id": "E", "contribution": " Yeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that {disfmarker} and where you 're not adjusting the statistical engine at all ."}, {"turn": 287, "name": "PhD", "id": "F", "contribution": " Yeah . Yeah ."}, {"turn": 288, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 289, "name": "PhD", "id": "F", "contribution": " Yeah . That 's true ."}, {"turn": 290, "name": "Professor", "id": "E", "contribution": " You know , that just {disfmarker}"}, {"turn": 291, "name": "PhD", "id": "F", "contribution": " Right ."}, {"turn": 292, "name": "PhD", "id": "B", "contribution": " Hmm ."}, {"turn": 293, "name": "Professor", "id": "E", "contribution": " I mean {disfmarker} Yeah ."}, {"turn": 294, "name": "PhD", "id": "F", "contribution": " Could be expensive ."}, {"turn": 295, "name": "Professor", "id": "E", "contribution": " No . Well not just expensive . I {disfmarker} I {disfmarker} I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only {disfmarker} Right ?"}, {"turn": 296, "name": "PhD", "id": "F", "contribution": " Oh ,"}, {"turn": 297, "name": "Professor", "id": "E", "contribution": " Each frame comes in and it 's gotta go out the other end ."}, {"turn": 298, "name": "PhD", "id": "F", "contribution": " right ."}, {"turn": 299, "name": "Professor", "id": "E", "contribution": " So , uh {disfmarker}"}, {"turn": 300, "name": "PhD", "id": "F", "contribution": " Right . So whatever it was , it would have to be uh sort of on a per frame basis ."}, {"turn": 301, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 302, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 303, "name": "Professor", "id": "E", "contribution": " Yeah . I mean , you can do , um {disfmarker} Fairly quickly you can do male female {disfmarker} f male female stuff ."}, {"turn": 304, "name": "PhD", "id": "F", "contribution": " Yeah . Yeah ."}, {"turn": 305, "name": "Professor", "id": "E", "contribution": " But as far as , I mean {disfmarker} Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With {disfmarker} with , uh , uh , l trying to identify third formant {disfmarker} average third formant {disfmarker} {vocalsound} using that as an indicator of {disfmarker}"}, {"turn": 306, "name": "PhD", "id": "F", "contribution": " I don't know ."}, {"turn": 307, "name": "Professor", "id": "E", "contribution": " So . You know , third formant {disfmarker} I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion {disfmarker}"}, {"turn": 308, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 309, "name": "Professor", "id": "E", "contribution": " So , if you had a first formant that was one hundred hertz before , if the fifty {disfmarker} if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at {disfmarker} So , although , you frequently get less distinct higher formants , it 's still {disfmarker} third formant 's kind of a reasonable compromise , and {disfmarker}"}, {"turn": 310, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 311, "name": "Professor", "id": "E", "contribution": " So , I think , eh , if I recall correctly , they did something like that . And {disfmarker} and {disfmarker}"}, {"turn": 312, "name": "PhD", "id": "F", "contribution": " Hmm ."}, {"turn": 313, "name": "Professor", "id": "E", "contribution": " But {disfmarker} Um , that doesn't work for just having one frame or something ."}, {"turn": 314, "name": "PhD", "id": "F", "contribution": " Yeah ."}, {"turn": 315, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 316, "name": "Professor", "id": "E", "contribution": " You know ? That 's more like looking at third formant over {disfmarker} over a turn or something like that ,"}, {"turn": 317, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 318, "name": "Professor", "id": "E", "contribution": " and {disfmarker}"}, {"turn": 319, "name": "PhD", "id": "F", "contribution": " Right ."}, {"turn": 320, "name": "Professor", "id": "E", "contribution": " Um . So . But on the other hand , male female is a {disfmarker} is a {disfmarker} is a much simpler categorization than figuring out a {disfmarker} a factor to , uh , squish or expand the {disfmarker} the spectrum ."}, {"turn": 321, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 322, "name": "Professor", "id": "E", "contribution": " So , um . Y you could imagine that {disfmarker} I mean , just like we 're saying voiced - unvoiced is good to know {disfmarker} uh , male female is good to know also . Um ."}, {"turn": 323, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 324, "name": "Professor", "id": "E", "contribution": " But , you 'd have to figure out a way to {disfmarker} to {disfmarker} to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the {disfmarker} the male and female output vectors {disfmarker} you know , tr nets trained only on males and n trained only on females or {disfmarker} or , uh , you know . But {disfmarker} Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it {disfmarker} ?"}, {"turn": 325, "name": "PhD", "id": "F", "contribution": " Is it balanced , um , in terms of gender {disfmarker} the data ?"}, {"turn": 326, "name": "PhD", "id": "B", "contribution": " Mmm ."}, {"turn": 327, "name": "Professor", "id": "E", "contribution": " Do you know ?"}, {"turn": 328, "name": "PhD", "id": "B", "contribution": " Almost , yeah ."}, {"turn": 329, "name": "PhD", "id": "F", "contribution": " Hmm ."}, {"turn": 330, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 331, "name": "Professor", "id": "E", "contribution": " Hmm . OK . Y you 're {disfmarker} you were saying before {disfmarker} ?"}, {"turn": 332, "name": "PhD", "id": "B", "contribution": " Uh . Yeah . So , this noise , um {disfmarker} Yeah . The MSG {disfmarker} Um . Mmm . There is something {disfmarker} perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on {disfmarker} let 's say , on TIMIT with MSG features , they {disfmarker} they look as good as networks trained on PLP . But , um , when they are used on {disfmarker} on the SpeechDat - Car data , it 's not the case {disfmarker} oh , well . The MSG features are much worse , and so maybe they 're , um , less {disfmarker} more sensitive to different recording conditions , or {disfmarker} Shou"}, {"turn": 333, "name": "Professor", "id": "E", "contribution": " Shouldn't be . They should be less so ."}, {"turn": 334, "name": "PhD", "id": "B", "contribution": " Yeah . But {disfmarker}"}, {"turn": 335, "name": "Professor", "id": "E", "contribution": " R right ?"}, {"turn": 336, "name": "PhD", "id": "B", "contribution": " Mmm ."}, {"turn": 337, "name": "Professor", "id": "E", "contribution": " Wh - ? But let me ask you this . What {disfmarker} what 's the , um {disfmarker} ? Do you kno recall if the insertions were {disfmarker} were higher with MSG ?"}, {"turn": 338, "name": "PhD", "id": "B", "contribution": " I don't know . I cannot tell . But {disfmarker} It 's {disfmarker} it {disfmarker} the {disfmarker} the error rate is higher . So , I don"}, {"turn": 339, "name": "Professor", "id": "E", "contribution": " Yeah . But you should always look at insertions , deletions , and substitutions ."}, {"turn": 340, "name": "PhD", "id": "B", "contribution": " Yeah . Mm - hmm ."}, {"turn": 341, "name": "Professor", "id": "E", "contribution": " So {disfmarker}"}, {"turn": 342, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 343, "name": "Professor", "id": "E", "contribution": " so , uh {disfmarker} MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them ."}, {"turn": 344, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 345, "name": "Professor", "id": "E", "contribution": " So , if it 's very different , then this is the sort of thing {disfmarker} I mean I 'm really glad Andreas brought this point up . I {pause} sort of had forgotten to discuss it . Um . You always have to look at how this {disfmarker} uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features ."}, {"turn": 346, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 347, "name": "Professor", "id": "E", "contribution": " So if it {disfmarker} if in fact , uh {disfmarker} The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum ."}, {"turn": 348, "name": "PhD", "id": "B", "contribution": " Mm - hmm . Mm - hmm ."}, {"turn": 349, "name": "Professor", "id": "E", "contribution": " And you might wanna change that ."}, {"turn": 350, "name": "PhD", "id": "B", "contribution": " But {disfmarker} Yeah . But , it 's d it 's after {disfmarker} Well , it 's tandem features , so {disfmarker} Mmm ."}, {"turn": 351, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 352, "name": "PhD", "id": "B", "contribution": " Yeah . We {disfmarker} we have estimation of post posteriors with PLP and with MSG as input ,"}, {"turn": 353, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 354, "name": "PhD", "id": "B", "contribution": " so I don Well . I don't know ."}, {"turn": 355, "name": "Professor", "id": "E", "contribution": " That means they 're between zero and one ."}, {"turn": 356, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 357, "name": "Professor", "id": "E", "contribution": " But i it {disfmarker} it {disfmarker} it {disfmarker} it doesn't necessarily {disfmarker} You know , they could be , um {disfmarker} Do - doesn't tell you what the variance of the things is ."}, {"turn": 358, "name": "PhD", "id": "B", "contribution": " Mmm . Mm - hmm ."}, {"turn": 359, "name": "Professor", "id": "E", "contribution": " Right ? Cuz if you 're taking the log of these things , it could be , uh {disfmarker} Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are ."}, {"turn": 360, "name": "PhD", "id": "B", "contribution": " Mm - hmm . Yeah ."}, {"turn": 361, "name": "Professor", "id": "E", "contribution": " So ."}, {"turn": 362, "name": "PhD", "id": "B", "contribution": " Yeah . So we should look at the likelihood , or {disfmarker} or what ? Or {disfmarker} well , at the log , perhaps , and {disfmarker}"}, {"turn": 363, "name": "Professor", "id": "E", "contribution": " Yeah . Yeah ."}, {"turn": 364, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 365, "name": "Professor", "id": "E", "contribution": " Or what {disfmarker} you know , what you 're uh {disfmarker} the thing you 're actually looking at ."}, {"turn": 366, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 367, "name": "Professor", "id": "E", "contribution": " So your {disfmarker} your {disfmarker} the values that are {disfmarker} are actually being fed into HTK ."}, {"turn": 368, "name": "PhD", "id": "B", "contribution": " Mm - hmm . But {disfmarker}"}, {"turn": 369, "name": "Professor", "id": "E", "contribution": " What do they look like ?"}, {"turn": 370, "name": "PhD", "id": "F", "contribution": " No And so th the , uh {disfmarker} for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?"}, {"turn": 371, "name": "PhD", "id": "B", "contribution": " Yes ."}, {"turn": 372, "name": "Professor", "id": "E", "contribution": " Right . So they 're {pause} kinda like log probabilities is what I was saying ."}, {"turn": 373, "name": "PhD", "id": "F", "contribution": " And those {disfmarker} OK . And tho that 's what goes {pause} into {pause} HTK ?"}, {"turn": 374, "name": "Professor", "id": "E", "contribution": " Uh , almost . But then you actually do a KLT on them ."}, {"turn": 375, "name": "PhD", "id": "F", "contribution": " OK ."}, {"turn": 376, "name": "Professor", "id": "E", "contribution": " Um . They aren't normalized after that , are they ?"}, {"turn": 377, "name": "PhD", "id": "B", "contribution": " Mmm . No , they are not {disfmarker} no ."}, {"turn": 378, "name": "Professor", "id": "E", "contribution": " No . OK . So , um . Right . So the question is {disfmarker} Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is {disfmarker} is gonna be a good or a bad thing ? So ."}, {"turn": 379, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 380, "name": "Professor", "id": "E", "contribution": " Uh , and that 's something that nothing {disfmarker} nothing else after that is gonna {disfmarker} Uh , things are gonna scale it {disfmarker} Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh {disfmarker}"}, {"turn": 381, "name": "PhD", "id": "F", "contribution": " Yeah . Cuz if {disfmarker} if the log probs that are coming out of the MSG are really big , the standard {pause} insertion penalty is gonna have very little effect"}, {"turn": 382, "name": "Professor", "id": "E", "contribution": " Well , the {disfmarker} Right ."}, {"turn": 383, "name": "PhD", "id": "F", "contribution": " compared to , you know , a smaller set of log probs ."}, {"turn": 384, "name": "Professor", "id": "E", "contribution": " Yeah . No . Again you don't really {pause} look at that . It 's something {disfmarker} that , and then it 's going through this transformation that 's probably pretty close to {disfmarker} It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a {disfmarker} a {disfmarker} a discrete cosine transformation is doing ."}, {"turn": 385, "name": "PhD", "id": "F", "contribution": " Yeah ."}, {"turn": 386, "name": "Professor", "id": "E", "contribution": " But still it 's {disfmarker} it 's not gonna probably radically change the scale of things . I would think . And , uh {disfmarker} Yeah . It may be entirely off and {disfmarker} and it may be {disfmarker} at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be {disfmarker} So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the {disfmarker} if the , uh {disfmarker} i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might {disfmarker} might be in that direction ."}, {"turn": 387, "name": "PhD", "id": "B", "contribution": " Mm - hmm . Mm - hmm . Yeah . But ,"}, {"turn": 388, "name": "Professor", "id": "E", "contribution": " Anything else ?"}, {"turn": 389, "name": "PhD", "id": "B", "contribution": " my {disfmarker} my point was more that it {disfmarker} it works sometimes and {disfmarker} but sometimes it doesn't work ."}, {"turn": 390, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 391, "name": "PhD", "id": "B", "contribution": " So ."}, {"turn": 392, "name": "Professor", "id": "E", "contribution": " Well ."}, {"turn": 393, "name": "PhD", "id": "B", "contribution": " And it works on TI - digits and on SpeechDat - Car it doesn't work , and {disfmarker}"}, {"turn": 394, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 395, "name": "PhD", "id": "B", "contribution": " Mm - hmm . Yeah . Well ."}, {"turn": 396, "name": "Professor", "id": "E", "contribution": " But , you know , some problems are harder than others ,"}, {"turn": 397, "name": "PhD", "id": "B", "contribution": " Mm - hmm . Yeah ."}, {"turn": 398, "name": "Professor", "id": "E", "contribution": " and {disfmarker} And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,"}, {"turn": 399, "name": "PhD", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 400, "name": "Professor", "id": "E", "contribution": " so it 's {disfmarker} But it {disfmarker} but , um , i it {disfmarker} it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?"}, {"turn": 401, "name": "PhD", "id": "B", "contribution": " Yeah . Yeah , sure ."}, {"turn": 402, "name": "Professor", "id": "E", "contribution": " So ."}, {"turn": 403, "name": "PhD", "id": "B", "contribution": " Uh ."}, {"turn": 404, "name": "Professor", "id": "E", "contribution": " Hmm ? Yeah ."}, {"turn": 405, "name": "PhD", "id": "B", "contribution": " Yeah . Well , there is also the spectral subtraction , which , um {disfmarker} I think maybe we should , uh , try to integrate it in {disfmarker} in our system ."}, {"turn": 406, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 407, "name": "PhD", "id": "B", "contribution": " Mmm . Mm - hmm ."}, {"turn": 408, "name": "Professor", "id": "E", "contribution": " Right ."}, {"turn": 409, "name": "PhD", "id": "B", "contribution": " But ,"}, {"turn": 410, "name": "Professor", "id": "E", "contribution": " O"}, {"turn": 411, "name": "PhD", "id": "B", "contribution": " I think that would involve to {disfmarker} {vocalsound} to mmm {vocalsound} use a big {disfmarker} a {disfmarker} al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by , {vocalsound} um , other kind of processing that 's {disfmarker} are dependent on the {disfmarker} uh , if it 's speech or noi or silence ."}, {"turn": 412, "name": "Professor", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 413, "name": "PhD", "id": "B", "contribution": " And there is this kind of spectral flattening after {disfmarker} if it 's silence , and {disfmarker} and s I {disfmarker} I think it 's important , um , {vocalsound} to reduce this musical noise and this {disfmarker} this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from {disfmarker} from the {disfmarker} this proposal and {disfmarker} and then just add some kind of on - line normalization in {disfmarker} in the neural network . Mmm ."}, {"turn": 414, "name": "Professor", "id": "E", "contribution": " OK . Well , this 'll be , I think , something for discussion with Hynek next week ."}, {"turn": 415, "name": "PhD", "id": "B", "contribution": " Yeah . Mm - hmm ."}, {"turn": 416, "name": "Professor", "id": "E", "contribution": " Yeah . OK . Right . So . How are , uh , uh {disfmarker} how are things going with what you 're doing ?"}, {"turn": 417, "name": "Grad", "id": "D", "contribution": " Oh . Well , um , I took a lot of time just getting my taxes out of the way {disfmarker} multi - national taxes . So , I 'm {disfmarker} I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here ."}, {"turn": 418, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 419, "name": "Grad", "id": "D", "contribution": " Do you know what his schedule will be like ?"}, {"turn": 420, "name": "Professor", "id": "E", "contribution": " Uh , he 'll be around for three days ."}, {"turn": 421, "name": "Grad", "id": "D", "contribution": " OK . So , y"}, {"turn": 422, "name": "Professor", "id": "E", "contribution": " Uh , we 'll have a lot of time ."}, {"turn": 423, "name": "Grad", "id": "D", "contribution": " OK ."}, {"turn": 424, "name": "Professor", "id": "E", "contribution": " So , uh {disfmarker} Um . I 'll , uh {disfmarker} You know , he 's {disfmarker} he 'll {disfmarker} he 'll be talking with everybody in this room So ."}, {"turn": 425, "name": "PhD", "id": "F", "contribution": " But you said you won't {disfmarker} you won't be here next Thursday ?"}, {"turn": 426, "name": "Professor", "id": "E", "contribution": " Not Thursday and Friday . Yeah . Cuz I will be at faculty retreat ."}, {"turn": 427, "name": "PhD", "id": "F", "contribution": " Hmm ."}, {"turn": 428, "name": "Professor", "id": "E", "contribution": " So . I 'll try to {vocalsound} connect with him and people as {disfmarker} as I can on {disfmarker} on Wednesday . But {disfmarker} Um . Oh , how 'd taxes go ? Taxes go OK ?"}, {"turn": 429, "name": "Grad", "id": "D", "contribution": " Mmm . Yeah ."}, {"turn": 430, "name": "Professor", "id": "E", "contribution": " Yeah . Oh , good . Yeah . Yeah . That 's just {disfmarker} that 's {disfmarker} that 's one of the big advantages of not making much money is {vocalsound} the taxes are easier . Yeah ."}, {"turn": 431, "name": "PhD", "id": "F", "contribution": " Unless you 're getting money in two countries ."}, {"turn": 432, "name": "Professor", "id": "E", "contribution": " I think you are . Aren't you ?"}, {"turn": 433, "name": "PhD", "id": "F", "contribution": " They both want their cut ."}, {"turn": 434, "name": "PhD", "id": "B", "contribution": " Hmm ."}, {"turn": 435, "name": "Grad", "id": "D", "contribution": " Hmm . Yeah ."}, {"turn": 436, "name": "PhD", "id": "F", "contribution": " Right ?"}, {"turn": 437, "name": "Professor", "id": "E", "contribution": " Yeah . Yeah . Huh . Canada w Canada wants a cut ?"}, {"turn": 438, "name": "Grad", "id": "D", "contribution": " Mm - hmm ."}, {"turn": 439, "name": "Professor", "id": "E", "contribution": " Have to do {disfmarker} So you {disfmarker} you have to do two returns ?"}, {"turn": 440, "name": "Grad", "id": "D", "contribution": " Mmm . W uh , for two thousand I did . Yeah ."}, {"turn": 441, "name": "Professor", "id": "E", "contribution": " Oh , oh . Yeah . For tw That 's right , ju"}, {"turn": 442, "name": "PhD", "id": "F", "contribution": " But not for this next year ?"}, {"turn": 443, "name": "Professor", "id": "E", "contribution": " Two thousand . Yeah . Probably not this next year , I guess ."}, {"turn": 444, "name": "Grad", "id": "D", "contribution": " Ye"}, {"turn": 445, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 446, "name": "Grad", "id": "D", "contribution": " Um ."}, {"turn": 447, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 448, "name": "Grad", "id": "D", "contribution": " Uh , I 'll {disfmarker} I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a {disfmarker} considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return ."}, {"turn": 449, "name": "Professor", "id": "E", "contribution": " OK . Alright . Uh . Barry , do you wanna {pause} say something about your stuff here ?"}, {"turn": 450, "name": "Grad", "id": "A", "contribution": " Oh , um . Right . I {pause} just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um {disfmarker} Yeah . It 's {disfmarker} that 's pretty much it ."}, {"turn": 451, "name": "Professor", "id": "E", "contribution": " Oh , well . No Um , why don't you say something about what it is ?"}, {"turn": 452, "name": "Grad", "id": "A", "contribution": " Oh , you {disfmarker} oh , you want {disfmarker} you want details . Hmm . OK ."}, {"turn": 453, "name": "Professor", "id": "E", "contribution": " Well , we 're all gathered here together . I thought we 'd , you know {disfmarker}"}, {"turn": 454, "name": "Grad", "id": "A", "contribution": " I was hoping I could wave my hands . Um . So , um . So , once wa I {disfmarker} I was thinking getting {disfmarker} getting us a set of acoustic events to {disfmarker} um , to be able to distinguish between , uh , phones and words and stuff . And {vocalsound} um , once we {disfmarker} we would figure out a set of these events that can be , you know , um , hand - labeled or {disfmarker} or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um , {vocalsound} do some cheating experiments , um , where we feed , um , these events into {pause} an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah ."}, {"turn": 455, "name": "Grad", "id": "D", "contribution": " Hey , Barry ? Can you give an example of an event ?"}, {"turn": 456, "name": "Grad", "id": "A", "contribution": " Yeah . Sure . Um , I {disfmarker} I can give you an example of {pause} twenty - odd events . Um {disfmarker} So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality ."}, {"turn": 457, "name": "Professor", "id": "E", "contribution": " Whose paper is it ?"}, {"turn": 458, "name": "Grad", "id": "A", "contribution": " Um , this is a paper by Hubener and Cardson {pause} Benson {disfmarker} Bernds - Berndsen ."}, {"turn": 459, "name": "Professor", "id": "E", "contribution": " Yeah . Huh . From , uh , University of Hamburg and Bielefeld ."}, {"turn": 460, "name": "Grad", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 461, "name": "Professor", "id": "E", "contribution": " OK ."}, {"turn": 462, "name": "Grad", "id": "A", "contribution": " Um ."}, {"turn": 463, "name": "PhD", "id": "F", "contribution": " Yeah . I think the {disfmarker} just to expand a little bit on the idea of acoustic event ."}, {"turn": 464, "name": "Grad", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 465, "name": "PhD", "id": "F", "contribution": " There 's , um {disfmarker} in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um {disfmarker}"}, {"turn": 466, "name": "Professor", "id": "E", "contribution": " So , stuff that 's not based on data ."}, {"turn": 467, "name": "PhD", "id": "F", "contribution": " Stuff that 's not based on data , necessarily ."}, {"turn": 468, "name": "Professor", "id": "E", "contribution": " Yeah . Oh , OK . Yeah . Yeah , OK ."}, {"turn": 469, "name": "PhD", "id": "F", "contribution": " Right . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,"}, {"turn": 470, "name": "Grad", "id": "A", "contribution": " Yeah ."}, {"turn": 471, "name": "PhD", "id": "F", "contribution": " its tenseness , laxness , things like that ,"}, {"turn": 472, "name": "Grad", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 473, "name": "PhD", "id": "F", "contribution": " which may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um {disfmarker} it 's a little different , in {disfmarker} at least in my mind ."}, {"turn": 474, "name": "Professor", "id": "E", "contribution": " I mean , when we did the SPAM work {disfmarker} I mean , there we had {disfmarker} we had this notion of an , uh , auditory {disfmarker} @ @ {comment} auditory event ."}, {"turn": 475, "name": "Grad", "id": "A", "contribution": " Good . That 's great ."}, {"turn": 476, "name": "Professor", "id": "E", "contribution": " And , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front ."}, {"turn": 477, "name": "PhD", "id": "F", "contribution": " Mm - hmm ."}, {"turn": 478, "name": "Professor", "id": "E", "contribution": " Uh . And the {disfmarker} the {disfmarker} the idea was something that occurred that is important to a bunch of neurons somewhere . So ."}, {"turn": 479, "name": "Grad", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 480, "name": "Professor", "id": "E", "contribution": " Um . A sudden change or a relatively rapid change in some spectral characteristic will {disfmarker} will do sort of this . I mean , there 's certainly a bunch of {disfmarker} a bunch of places where you know that neurons are gonna fire because something novel has happened . That was {disfmarker} that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but {disfmarker}"}, {"turn": 481, "name": "PhD", "id": "F", "contribution": " It 's kinda like the difference between top - down and bottom - up ."}, {"turn": 482, "name": "Professor", "id": "E", "contribution": " Yeah ."}, {"turn": 483, "name": "PhD", "id": "F", "contribution": " I think of the acoustic {disfmarker} you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be {disfmarker} you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event ."}, {"turn": 484, "name": "Grad", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 485, "name": "PhD", "id": "F", "contribution": " What {disfmarker} ? And then that {disfmarker} you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that ."}, {"turn": 486, "name": "Professor", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 487, "name": "PhD", "id": "F", "contribution": " And so it 's sort of a different way of looking ."}, {"turn": 488, "name": "Professor", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 489, "name": "Grad", "id": "A", "contribution": " Yeah . So . Yeah ."}, {"turn": 490, "name": "Grad", "id": "D", "contribution": " OK ."}, {"turn": 491, "name": "Grad", "id": "A", "contribution": " Mm - hmm . Um {disfmarker} Using these {disfmarker} these events , um , you know , we can {disfmarker} we can perform these {disfmarker} these , uh , cheating experiments . See how {disfmarker} how {disfmarker} how good they are , um , in , um {disfmarker} in terms of phoneme recognition or word recognition . And , um {disfmarker} and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this {disfmarker} this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um {disfmarker} to account for other {disfmarker} other phenomena like , um , CMR co - modulation release . And , um {disfmarker} and maybe also investigate ways to {disfmarker} to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff {disfmarker} Jeff , uh , Bilmes did his work . Um , and while I 'm {disfmarker} I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and {disfmarker} So {disfmarker} so , once we have these {disfmarker} these , uh , event detectors , um , we could put them together and {disfmarker} and feed the outputs of the event detectors into {disfmarker} into the SRI , um , HMM {disfmarker} HMM system , and , um {disfmarker} and test it on {disfmarker} on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the {disfmarker} the big picture of {disfmarker} of um , the plan ."}, {"turn": 492, "name": "Professor", "id": "E", "contribution": " By the way , um , there 's , uh , a couple people who are gonna be here {disfmarker} I forget if I already told you this , but , a couple people who are gonna be here for six months ."}, {"turn": 493, "name": "Grad", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 494, "name": "Professor", "id": "E", "contribution": " Uh {disfmarker} uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at {vocalsound} auditory properties inspired by various , uh , brain function things ."}, {"turn": 495, "name": "Grad", "id": "A", "contribution": " Hmm ."}, {"turn": 496, "name": "Professor", "id": "E", "contribution": " So , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are {disfmarker} are , uh , developing ."}, {"turn": 497, "name": "Grad", "id": "A", "contribution": " Hmm . OK ."}, {"turn": 498, "name": "Professor", "id": "E", "contribution": " So , he looks at interesting {disfmarker} interesting things in {disfmarker} in the {disfmarker} {vocalsound} different ways of looking at spectra in order to {disfmarker} to get various speech properties out . So ."}, {"turn": 499, "name": "Grad", "id": "A", "contribution": " OK ."}, {"turn": 500, "name": "Professor", "id": "E", "contribution": " OK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I {disfmarker} I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll {disfmarker} I 'll start . It 's , uh , one thirty - five . seventeen OK"}]}