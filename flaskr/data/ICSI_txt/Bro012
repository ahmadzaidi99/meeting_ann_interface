Turn 0, B (PhD): OK . We 're on .
Turn 1, E (Grad): Hello ?
Turn 2, A (Professor): OK , so uh {vocalsound} had some interesting mail from uh Dan Ellis . Actually , I think he {disfmarker} he {vocalsound} redirected it to everybody also so uh {vocalsound} the PDA mikes uh have a big bunch of energy at {disfmarker} at uh five hertz uh where this came up was that uh I was showing off these wave forms that we have on the web and {disfmarker} and uh {vocalsound} I just sort of hadn't noticed this , but that {disfmarker} the major , major component in the wave {disfmarker} in the second wave form in that pair of wave forms is actually the air conditioner .
Turn 3, C (Grad): Huh .
Turn 4, A (Professor): So . So . I {vocalsound} {vocalsound} I have to be more careful about using that as a {disfmarker} as a {disfmarker} {vocalsound} as a good illustration , uh , in fact it 's not , of uh {disfmarker} {vocalsound} of the effects of room reverberation . It is isn't a bad illustration of the effects of uh room noise . {vocalsound} on {disfmarker} on uh some mikes uh but So . And then we had this other discussion about um {vocalsound} whether this affects the dynamic range , cuz I know , although we start off with thirty two bits , you end up with uh sixteen bits and {vocalsound} you know , are we getting hurt there ? But uh Dan is pretty confident that we 're not , that {disfmarker} that quantization error is not {disfmarker} is still not a significant {vocalsound} factor there . So . So there was a question of whether we should change things here , whether we should {vocalsound} change a capacitor on the input box for that or whether we should
Turn 5, B (PhD): Yeah , he suggested a smaller capacitor , right ?
Turn 6, A (Professor): Right . But then I had some other uh thing discussions with him
Turn 7, B (PhD): For the P D
Turn 8, A (Professor): and the feeling was {vocalsound} once we start monk monkeying with that , uh , many other problems could ha happen . And additionally we {disfmarker} we already have a lot of data that 's been collected with that , so .
Turn 9, B (PhD): Yeah .
Turn 10, A (Professor): A simple thing to do is he {disfmarker} he {disfmarker} he has a {disfmarker} I forget if it {disfmarker} this was in that mail or in the following mail , but he has a {disfmarker} a simple filter , a digital filter that he suggested . We just run over the data before we deal with it .
Turn 11, B (PhD): Mm - hmm .
Turn 12, A (Professor): um The other thing that I don't know the answer to , but when people are using Feacalc here , uh whether they 're using it with the high - pass filter option or not . And I don't know if anybody knows .
Turn 13, E (Grad): Um . {vocalsound} I could go check .
Turn 14, A (Professor): But . Yeah . So when we 're doing all these things using our software there is {disfmarker} um if it 's {disfmarker} if it 's based on the RASTA - PLP program , {vocalsound} which does both PLP and RASTA - PLP {vocalsound} um then {vocalsound} uh there is an option there which then comes up through to Feacalc which {vocalsound} um allows you to do high - pass filtering and in general we like to do that , because of things like this and {vocalsound} it 's {disfmarker} it 's pretty {disfmarker} it 's not a very severe filter . Doesn't affect speech frequencies , even pretty low speech frequencies , at all , but it 's
Turn 15, B (PhD): What 's the {pause} cut - off frequency it used ?
Turn 16, A (Professor): Oh . I don't know I wrote this a while ago
Turn 17, B (PhD): Is it like twenty ?
Turn 18, A (Professor): Something like that .
Turn 19, B (PhD): Yeah .
Turn 20, A (Professor): Yeah . I mean I think there 's some effect above twenty but it 's {disfmarker} it 's {disfmarker} it 's {disfmarker} it 's mild . So , I mean it probably {disfmarker} there 's probably some effect up to a hundred hertz or something but it 's {disfmarker} it 's pretty mild . I don't know in the {disfmarker} in the STRUT implementation of the stuff is there a high - pass filter or a pre pre - emphasis or something in the {disfmarker}
Turn 21, F (PhD): Uh . I think we use a pre - emphasis . Yeah . Yeah .
Turn 22, A (Professor): So . We {disfmarker} we {disfmarker} we want to go and check that in i for anything that we 're going to use the P D A mike for . {vocalsound} uh He says that there 's a pretty good roll off in the PZM mikes so {vocalsound} we don't need {disfmarker} need to worry about them one way or the other but if we do make use of the cheap mikes , {vocalsound} uh we want to be sure to do that {disfmarker} that filtering before we {vocalsound} process it . And then again if it 's uh depending on the option that the {disfmarker} our {disfmarker} our software is being run with , it 's {disfmarker} it 's quite possible that 's already being taken care of . uh But I also have to pick a different picture to show the effects of reverberation . uh
Turn 23, B (PhD): Did somebody notice it during your talk ?
Turn 24, A (Professor): uh No .
Turn 25, B (PhD): Huh .
Turn 26, A (Professor): Well . uh Well . If they made output they were {disfmarker} they were , you know {disfmarker} they were nice .
Turn 27, B (PhD): Didn't say anything ?
Turn 28, A (Professor): But . {vocalsound} I mean the thing is it was since I was talking about reverberation and showing this thing that was noise , it wasn't a good match , but it certainly was still uh an indication of the fact that you get noise with distant mikes . uh It 's just not a great example because not only isn't it reverberation but it 's a noise that we definitely know what to do .
Turn 29, B (PhD): Mm - hmm .
Turn 30, A (Professor): So , I mean , it doesn't take deep {disfmarker} {vocalsound} a new {disfmarker} bold new methods to get rid of uh five hertz noise , so .
Turn 31, B (PhD): Yeah .
Turn 32, A (Professor): um {vocalsound} uh But . So it was {disfmarker} it was a bad example in that way , but it 's {disfmarker} it still is {disfmarker} it 's the real thing that we did get out of the microphone at distance , so it wasn't {vocalsound} it w it w wasn't wrong it was inappropriate . So . {vocalsound} So uh , but uh , Yeah , someone noticed it later pointed it out to me , and I went " oh , man . Why didn't I notice that ? "
Turn 33, B (PhD): Hmm .
Turn 34, A (Professor): um . So . {vocalsound} um So I think we 'll change our {disfmarker} our picture on the web , when we 're @ @ . One of the things I was {disfmarker} I mean , I was trying to think about what {disfmarker} what 's the best {vocalsound} way to show the difference an and I had a couple of thoughts one was , {vocalsound} that spectrogram that we show {vocalsound} is O K , but the thing is {vocalsound} the eyes uh and the {vocalsound} the brain behind them are so good at picking out patterns {vocalsound} from {disfmarker} from noise {vocalsound} that in first glance you look at them it doesn't seem like it 's that bad uh because there 's many features that are still preserved . So one thing to do might be to just take a piece of the spec uh of the spectrogram where you can see {vocalsound} that something looks different , an and blow it up , and have that be the part that 's {disfmarker} just to show as well . You know .
Turn 35, B (PhD): Mm - hmm . Mm - hmm .
Turn 36, A (Professor): i i Some things are going to be hurt . um {vocalsound} Another , I was thinking of was um {vocalsound} taking some spectral slices , like uh {disfmarker} like we look at with the recognizer , and look at the spectrum or cepstrum that you get out of there , and the {disfmarker} the uh , um , {vocalsound} the reverberation uh does make it {disfmarker} does change that . And so maybe {disfmarker} maybe that would be more obvious .
Turn 37, B (PhD): Hmm .
Turn 38, C (Grad): Spectral slices ?
Turn 39, A (Professor): Yeah .
Turn 40, C (Grad): W w what d what do you mean ?
Turn 41, A (Professor): Well , I mean um all the recognizers look at frames . So they {disfmarker} they look at {disfmarker}
Turn 42, B (PhD): So like one instant in time .
Turn 43, A (Professor): Yeah , look at a {disfmarker}
Turn 44, C (Grad): OK .
Turn 45, A (Professor): So it 's , yeah , at one point in time or uh twenty {disfmarker} over twenty milliseconds or something , {vocalsound} you have a spectrum or a cepstrum .
Turn 46, C (Grad): OK .
Turn 47, A (Professor): That 's what I meant by a slice .
Turn 48, C (Grad): I see .
Turn 49, A (Professor): Yeah . And {vocalsound} if you look at {disfmarker}
Turn 50, B (PhD): You could just {disfmarker} you could just throw up , you know , uh {vocalsound} the uh {disfmarker} some MFCC feature vectors . You know , one from one , one from the other , and then , you know , you can look and see how different the numbers are .
Turn 51, A (Professor): Right . Well , that 's why I saying either {vocalsound} {vocalsound} Well , either spectrum or cepstrum
Turn 52, B (PhD): I 'm just kidding .
Turn 53, A (Professor): but {disfmarker} {vocalsound} but I think the thing is you wanna {disfmarker} 
Turn 54, B (PhD): I don't mean a graph . I mean the actual numbers .
Turn 55, A (Professor): Oh . I see . Oh . That would be lovely , yeah .
Turn 56, B (PhD): Yeah . " See how different these {vocalsound} sequences of numbers are ? "
Turn 57, A (Professor): Yeah . Or I could just add them up and get a different total .
Turn 58, B (PhD): Yeah . It 's not the square .
Turn 59, A (Professor): OK . Uh . What else {disfmarker} wh what 's {disfmarker} what else is going on ?
Turn 60, F (PhD): Uh , yeah . Yeah , at first I had a remark why {disfmarker} I am wondering why the PDA is always so far . I mean we are always meeting at the {vocalsound} beginning of the table and {vocalsound} the PDA 's there .
Turn 61, A (Professor): Uh . I guess cuz we haven't wanted to move it . We {disfmarker} we could {disfmarker} {vocalsound} we could move us ,
Turn 62, F (PhD): Yeah ?
Turn 63, A (Professor): and .
Turn 64, F (PhD): OK .
Turn 65, E (Grad): That 's right .
Turn 66, F (PhD): Well , anyway . Um . Yeah , so . Uh . Since the last meeting we 've {disfmarker} we 've tried to put together um {vocalsound} the clean low - pass um downsampling , upsampling , I mean , Uh the new filter that 's replacing the LDA filters , and also {vocalsound} the um delay issue so that {disfmarker} We considered th the {disfmarker} the delay issue on the {disfmarker} for the on - line normalization . Mmm . So we 've put together all this and then we have results that are not um {vocalsound} {vocalsound} very impressive . Well , there is no {vocalsound} real improvement .
Turn 67, A (Professor): But it 's not wer worse and it 's better {disfmarker} better latency ,
Turn 68, F (PhD): It 's not {disfmarker}
Turn 69, A (Professor): right ?
Turn 70, F (PhD): Yeah . Yeah . Well . Actually it 's better . It seems better when we look at the mismatched case but {vocalsound} I think we are like {disfmarker} like cheated here by the {disfmarker} th this problem that {vocalsound} uh in some cases when you modify slight {disfmarker} slightly modify the initial condition you end up {vocalsound} completely somewhere air somewhere else in the {disfmarker} in the space , {vocalsound} the parameters .
Turn 71, A (Professor): Yeah .
Turn 72, F (PhD): So . Well . The other system are for instance . For Italian is at seventy - eight {vocalsound} percent recognition rate on the mismatch , and this new system has eighty - nine . But I don't think it indicates something , really . I don't {disfmarker} I don't think it means that the new system is more robust
Turn 73, A (Professor): Uh - huh .
Turn 74, F (PhD): or {disfmarker} It 's simply the fact that {disfmarker} Well .
Turn 75, A (Professor): Well , the test would be if you then tried it on one of the other test sets , if {disfmarker} if it was {disfmarker}
Turn 76, F (PhD): Y
Turn 77, A (Professor): Right . So this was Italian , right ?
Turn 78, F (PhD): Yeah . Yeah .
Turn 79, A (Professor): So then if you take your changes
Turn 80, F (PhD): It 's similar for other test sets
Turn 81, A (Professor): and then {disfmarker}
Turn 82, F (PhD): but I mean {vocalsound} from this se seventy - eight um percent recognition rate system , {vocalsound} I could change the transition probabilities for the {disfmarker} the first HMM and {pause} it will end up to eighty - nine also .
Turn 83, A (Professor): Uh - huh .
Turn 84, F (PhD): By using point five instead of point six , point four {vocalsound} as in the {disfmarker} the HTK script .
Turn 85, A (Professor): Uh - huh . Yeah .
Turn 86, F (PhD): So . Well . That 's {disfmarker}
Turn 87, B (PhD): Yeah . Yeah I looked at um {disfmarker} {vocalsound} looked at the results when Stephane did that
Turn 88, F (PhD): Well . Eh uh {disfmarker}
Turn 89, B (PhD): and it 's {disfmarker} it 's really wo really happens .
Turn 90, F (PhD): This really happens .
Turn 91, B (PhD): I mean th the only difference is you change the self - loop transition probability by a tenth of a percent
Turn 92, F (PhD): Yeah .
Turn 93, A (Professor): Yeah .
Turn 94, B (PhD): and it causes ten percent difference in the word error rate .
Turn 95, A (Professor): A tenth of a per cent .
Turn 96, B (PhD): Yeah . From point {disfmarker}
Turn 97, F (PhD): Even tenth of a percent ?
Turn 98, B (PhD): I {disfmarker} I 'm sorry
Turn 99, F (PhD): Well , we tried {disfmarker} we tried point one ,
Turn 100, B (PhD): f for point {disfmarker} from {disfmarker} You change at point one
Turn 101, F (PhD): yeah .
Turn 102, A (Professor): Oh !
Turn 103, B (PhD): and n not tenth of a percent , one tenth ,
Turn 104, F (PhD): Hmm .
Turn 105, A (Professor): Yeah .
Turn 106, B (PhD): alright ? Um so from point five {disfmarker} so from point six to point five and you get ten percent better .
Turn 107, A (Professor): Mm - hmm .
Turn 108, B (PhD): And it 's {disfmarker} {vocalsound} I think it 's what you basically hypothesized in the last meeting {vocalsound} about uh it just being very {disfmarker}
Turn 109, F (PhD): Mm - hmm .
Turn 110, B (PhD): and I think you mentioned this in your email too {disfmarker} it 's just very um {disfmarker}
Turn 111, F (PhD): Mmm , yeah .
Turn 112, B (PhD): you know get stuck in some local minimum and this thing throws you out of it I guess .
Turn 113, F (PhD): Mm - hmm .
Turn 114, A (Professor): Well , what 's {disfmarker} what are {disfmarker} according to the rules what {disfmarker} what are we supposed to do about the transition probabilities ? Are they supposed to be point five or point six ?
Turn 115, B (PhD): I think you 're not allowed to {disfmarker} Yeah . That 's supposed to be point six , for the self - loop .
Turn 116, F (PhD): Yeah .
Turn 117, A (Professor): Point {disfmarker} It 's supposed to be point six .
Turn 118, B (PhD): Yeah . But changing it to point five I think is {disfmarker} which gives you much better results , but that 's {vocalsound} not allowed .
Turn 119, A (Professor): But not allowed ? Yeah . OK .
Turn 120, B (PhD): Yeah .
Turn 121, F (PhD): Yeah , but even if you use point five , I 'm not sure it will always give you the better results
Turn 122, B (PhD): Yeah .
Turn 123, F (PhD): on other test set or it
Turn 124, B (PhD): Right . We only tested it on the {disfmarker} the medium mismatch ,
Turn 125, F (PhD): on the other training set , I mean .
Turn 126, B (PhD): right ? You said on the other cases you didn't notice {disfmarker}
Turn 127, F (PhD): Yeah . But . I think , yeah . I think the reason is , yeah , I not I {disfmarker} it was in my mail I think also , {vocalsound} is the fact that the mismatch is trained only on the far microphone . Well , in {disfmarker} for the mismatched case everything is um using the far microphone training and testing , whereas for the highly mismatched , training is done on the close microphone so {vocalsound} it 's {disfmarker} it 's clean speech basically so you don't have this problem of local minima probably and for the well - match , it 's a mix of close microphone and distant microphone and {disfmarker} Well .
Turn 128, B (PhD): I did notice uh something {disfmarker}
Turn 129, F (PhD): So th I think the mismatch is the more difficult for the training part .
Turn 130, B (PhD): Somebody , I think it was Morgan , suggested at the last meeting that I actually count to see {vocalsound} how many parameters and how many frames .
Turn 131, A (Professor): Mm - hmm .
Turn 132, F (PhD): Mm - hmm .
Turn 133, B (PhD): And there are uh almost one point eight million frames of training data and less than forty thousand parameters in the baseline system .
Turn 134, A (Professor): Hmm .
Turn 135, F (PhD): Yeah .
Turn 136, B (PhD): So it 's very , very few parameters compared to how much training data .
Turn 137, A (Professor): Well . Yes .
Turn 138, D (PhD): Mm - hmm .
Turn 139, A (Professor): So . And that {disfmarker} that says that we could have lots more parameters actually .
Turn 140, B (PhD): Yeah . Yeah .
Turn 141, F (PhD): Mm - hmm .
Turn 142, B (PhD): I did one quick experiment just to make sure I had everything worked out and I just {disfmarker} {vocalsound} uh f for most of the um {disfmarker} For {disfmarker} for all of the digit models , they end up at three mixtures per state . And so I just did a quick experiment , where I changed it so it went to four and um {vocalsound} it it {disfmarker} it didn't have a r any significant effect at the uh medium mismatch and high mismatch cases and it had {disfmarker} {vocalsound} it was just barely significant for the well - matched better . Uh so I 'm r gonna run that again but {vocalsound} um with many more uh mixtures per state .
Turn 143, A (Professor): Yeah . Cuz at forty thou I mean you could you could have uh {disfmarker} Yeah , easily four times as many {vocalsound} parameters .
Turn 144, B (PhD): Mm - hmm . And I think also {vocalsound} just seeing what we saw {vocalsound} uh in terms of the expected duration of the silence model ? when we did this tweaking of the self - loop ? The silence model expected duration was really different .
Turn 145, F (PhD): Yeah .
Turn 146, B (PhD): And so in the case where {vocalsound} um {vocalsound} it had a better score , the silence model expected duration was much longer .
Turn 147, F (PhD): Yeah .
Turn 148, B (PhD): So it was like {disfmarker} {vocalsound} it was a better match . I think {vocalsound} you know if we make a better silence model I think that will help a lot too um for a lot of these cases so but one one thing I {disfmarker} I wanted to check out before I increased the um {vocalsound} number of mixtures per state was {vocalsound} uh {vocalsound} in their {vocalsound} default training script they do an initial set of three re - estimations and then they built the silence model and then they do seven iterations then the add mixtures and they do another seven then they add mixtures then they do a final set of seven and they quit . Seven seems like a lot to me and it also makes the experiments go take a really long time I mean to do one turn - around of the well matched case takes like a day .
Turn 149, A (Professor): Mm - hmm . Mm - hmm .
Turn 150, B (PhD): And so {vocalsound} you know in trying to run these experiments I notice , you know , it 's difficult to find machines , you know , compute the run on . And so one of the things I did was I compiled HTK for the Linux {vocalsound} machines
Turn 151, A (Professor): Mm - hmm .
Turn 152, B (PhD): cuz we have this one from IBM that 's got like five processors in it ?
Turn 153, A (Professor): Right .
Turn 154, B (PhD): and so now I 'm {disfmarker} you can run stuff on that and that really helps a lot because now we 've got {vocalsound} you know , extra machines that we can use for compute . And if {disfmarker} I 'm do running an experiment right now where I 'm changing the number of iterations ? {vocalsound} from seven to three ?
Turn 155, D (PhD): Mm - hmm .
Turn 156, A (Professor): Yeah .
Turn 157, B (PhD): just to see how it affects the baseline system . And so if we can get away with just doing three , we can do {vocalsound} many more experiments more quickly . And if it 's not a {disfmarker} a huge difference from running with seven iterations , {vocalsound} um , you know , we should be able to get a lot more experiments done .
Turn 158, F (PhD): Hmm .
Turn 159, B (PhD): And so . I 'll let you know what {disfmarker} what happens with that . But if we can {vocalsound} you know , run all of these back - ends f with many fewer iterations and {vocalsound} on Linux boxes we should be able to get a lot more experimenting done .
Turn 160, A (Professor): Mm - hmm .
Turn 161, B (PhD): So . So I wanted to experiment with cutting down the number of iterations before I {vocalsound} increased the number of Gaussians .
Turn 162, A (Professor): Right . Sorry . So um , how 's it going on the {disfmarker}
Turn 163, F (PhD): Um .
Turn 164, A (Professor): So . You {disfmarker} you did some things . They didn't improve things in a way that convinced you you 'd substantially improved anything .
Turn 165, F (PhD): Yeah .
Turn 166, A (Professor): But they 're not making things worse and we have reduced latency , right ?
Turn 167, F (PhD): Yeah . But actually {disfmarker} um actually it seems to do a little bit worse for the well - matched case and we just noticed that {disfmarker} Yeah , actually the way the final score is computed is quite funny . It 's not a mean of word error rate . It 's not a weighted mean of word error rate , it 's a weighted mean of improvements .
Turn 168, A (Professor): Uh - huh .
Turn 169, F (PhD): So . Which means that {vocalsound} actually the weight on the well - matched is {disfmarker} Well I well what what {disfmarker} What happened is that if you have a small improvement or a small if on the well - matched case {vocalsound} it will have uh huge influence on the improvement compared to the reference because the reference system is {disfmarker} is {disfmarker} is quite good for {disfmarker} for the well - ma well - matched case also .
Turn 170, B (PhD): So it {disfmarker} it weights the improvement on the well - matched case really heavily compared to the improvement on the other cases ?
Turn 171, F (PhD): No , but it 's the weighting of the {disfmarker} of the improvement not of the error rate .
Turn 172, B (PhD): Yeah . Yeah , and it 's hard to improve on the {disfmarker} on the best case , cuz it 's already so good , right ?
Turn 173, F (PhD): Yeah but {pause} what I mean is that you can have a huge improvement on the H {disfmarker} HMK 's , uh like five percent uh absolute , and this will not affect the final score almost {disfmarker} Uh this will almost not affect the final score because {vocalsound} this improvement {disfmarker} because the improvement {vocalsound} uh relative to the {disfmarker} the baseline is small {disfmarker}
Turn 174, A (Professor): So they do improvement in terms of uh accuracy ? rather than word error rate ?
Turn 175, F (PhD): Uh . Uh improvement ?
Turn 176, A (Professor): So {disfmarker}
Turn 177, F (PhD): No , it 's compared to the word er it 's improvement on the word error rate ,
Turn 178, A (Professor): OK .
Turn 179, F (PhD): yeah . Sorry .
Turn 180, A (Professor): So if you have uh ten percent error and you get five percent absolute uh {vocalsound} improvement then that 's fifty percent .
Turn 181, F (PhD): Mm - hmm .
Turn 182, A (Professor): OK . So what you 're saying then is that if it 's something that has a small word error rate , {vocalsound} then uh a {disfmarker} even a relatively small improvement on it , in absolute terms , {vocalsound} will show up as quite {disfmarker} quite large in this .
Turn 183, F (PhD): Mm - hmm .
Turn 184, A (Professor): Is that what you 're saying ?
Turn 185, F (PhD): Yeah .
Turn 186, A (Professor): Yes .
Turn 187, F (PhD): Yeah .
Turn 188, A (Professor): OK . But yeah that 's {disfmarker} that 's {disfmarker} it 's the notion of relative improvement . Word error rate .
Turn 189, F (PhD): Yeah . Sure , but when we think about the weighting , which is point five , point three , point two , {vocalsound} it 's on absolute on {disfmarker} on relative figures ,
Turn 190, A (Professor): Yeah .
Turn 191, F (PhD): not {disfmarker}
Turn 192, A (Professor): Yeah .
Turn 193, F (PhD): So when we look at this error rate
Turn 194, A (Professor): No . That 's why I 've been saying we should be looking at word error rate uh and {disfmarker} and not {disfmarker} not at {vocalsound} at accuracies .
Turn 195, F (PhD): uh {disfmarker} Mmm , yeah . Mmm , yeah .
Turn 196, A (Professor): It 's {disfmarker}
Turn 197, F (PhD): Mm - hmm .
Turn 198, A (Professor): I mean uh we probably should have standardized on that all the way through . It 's just {disfmarker}
Turn 199, B (PhD): Well .
Turn 200, F (PhD): Mm - hmm .
Turn 201, B (PhD): I mean , it 's not {disfmarker} it 's not that different , right ? I mean , just subtract the accuracy .
Turn 202, A (Professor): Yeah but you 're {disfmarker} but when you look at the numbers , your sense of the relative size of things is quite different .
Turn 203, B (PhD): I mean {disfmarker} Oh . Oh , I see . Yeah .
Turn 204, A (Professor): If you had ninety percent uh correct {vocalsound} and five percent , five over ninety doesn't look like it 's a big difference , but {vocalsound} five over ten is {disfmarker} is big .
Turn 205, B (PhD): Mm - hmm .
Turn 206, F (PhD): Mm - hmm .
Turn 207, A (Professor): So just when we were looking at a lot of numbers and {vocalsound} getting sense of what was important .
Turn 208, B (PhD): I see . I see . Yeah . That makes sense .
Turn 209, A (Professor): Um .
Turn 210, F (PhD): Mmm .
Turn 211, A (Professor): Um .
Turn 212, F (PhD): Well anyway uh . So . Yeah . So it hurts a little bit on the well - match and yeah .
Turn 213, A (Professor): What 's a little bit ? Like {disfmarker}
Turn 214, F (PhD): Like , it 's difficult to say because again um {vocalsound} {vocalsound} I 'm not sure I have the um {disfmarker}
Turn 215, B (PhD): Hey Morgan ? Do you remember that Signif program that we used to use for testing signi ? Is that still valid ? I {disfmarker} I 've been using that .
Turn 216, A (Professor): Yeah . Yeah , it was actually updated .
Turn 217, B (PhD): OK .
Turn 218, A (Professor): Uh . {vocalsound} Jeff updated it some years ago
Turn 219, B (PhD): Oh , it was . Oh , I shoul
Turn 220, A (Professor): and {disfmarker} and uh cleaned it up made some things better in it . So .
Turn 221, B (PhD): OK . I should find that new one . I just use my old one from {vocalsound} ninety - two or whatever
Turn 222, A (Professor): Yeah , I 'm sure it 's not that different but {disfmarker} but he {disfmarker} {vocalsound} he uh {disfmarker} he was a little more rigorous , as I recall .
Turn 223, B (PhD): OK .
Turn 224, F (PhD): Right . So it 's around , like , point five . No , point six {comment} uh percent absolute on Italian {disfmarker}
Turn 225, A (Professor): Worse .
Turn 226, F (PhD): Worse , yep .
Turn 227, A (Professor): Out of what ? I mean . s
Turn 228, F (PhD): Uh well we start from ninety - four point sixty - four , and we go to ninety - four point O four .
Turn 229, A (Professor): Uh - huh . So that 's six {disfmarker} six point th
Turn 230, F (PhD): Uh .
Turn 231, B (PhD): Ninety - three point six four , right ? is the baseline .
Turn 232, F (PhD): Oh , no , I 've ninety - four . Oh , the baseline , you mean .
Turn 233, B (PhD): Yeah .
Turn 234, F (PhD): Well I don't {disfmarker} I 'm not talking about the baseline here .
Turn 235, B (PhD): Oh . Oh . I 'm sorry .
Turn 236, F (PhD): I uh {disfmarker} My baseline is the submitted system .
Turn 237, B (PhD): Ah ! OK . Ah , ah .
Turn 238, F (PhD): Hmm .
Turn 239, A (Professor): Yeah .
Turn 240, B (PhD): Sorry .
Turn 241, F (PhD):  Oh yeah . For Finnish , we start to ninety - three point eight - four and we go to ninety - three point seventy - four . And for Spanish we are {disfmarker} we were at ninety - five point O five and we go to ninety - three - s point sixty one .
Turn 242, A (Professor): OK , so we are getting hurt somewhat .
Turn 243, F (PhD): So .
Turn 244, A (Professor): And is that wh what {disfmarker} do you know what piece {disfmarker} you 've done several changes here . Uh , do you know what pie
Turn 245, F (PhD): Yeah . I guess {disfmarker} I guess it 's {disfmarker} it 's the filter . Because nnn , well uh we don't have complete result , but the filter {disfmarker} So the filter with the shorter delay hurts on Italian well - matched , which {disfmarker} And , yeah . And the other things , like um {vocalsound} downsampling , upsampling , don't seem to hurt and {vocalsound} the new on - line normalization , neither .
Turn 246, B (PhD): I 'm {disfmarker}
Turn 247, F (PhD): So .
Turn 248, B (PhD): I 'm really confused about something . If we saw that making a small change like , you know , a tenth , to the self - loop had a huge effect , {vocalsound} can we really make any conclusions about differences in this stuff ?
Turn 249, F (PhD): Mm - hmm . Yeah that 's th Yeah .
Turn 250, B (PhD): I mean , especially when they 're this small . I mean .
Turn 251, F (PhD): I think we can be completely fooled by this thing , but {disfmarker} I don't know .
Turn 252, A (Professor): Well , yeah .
Turn 253, F (PhD): So . There is first this thing , and then the {disfmarker} yeah , I computed the um {disfmarker} {vocalsound} like , the confidence level on the different test sets . And for the well - matched they are around um {vocalsound} point six uh percent . For the mismatched they are around like let 's say one point five percent . And for the well - m uh HM they are also around one point five .
Turn 254, A (Professor): But {disfmarker} OK , so you {disfmarker} these {disfmarker} these degradations you were talking about were on the well - matched case
Turn 255, F (PhD): So .
Turn 256, A (Professor): Uh . Do the {disfmarker} does the new filter make things uh better or worse for the other cases ?
Turn 257, F (PhD): Yeah . But . Uh . About the same . It doesn't hurt . Yeah .
Turn 258, A (Professor): Doesn't hurt , but doesn't get a little better , or something .
Turn 259, F (PhD): No .
Turn 260, A (Professor): No . OK , so {vocalsound} um I guess the argument one might make is that , " Yeah , if you looked at one of these cases {vocalsound} and you jiggle something and it changes {vocalsound} then uh you 're not quite sure what to make of it . But when you look across a bunch of these and there 's some {disfmarker} some pattern , um {disfmarker} I mean , so eh h here 's all the {disfmarker} if {disfmarker} if in all these different cases {vocalsound} it never gets better , and there 's significant number of cases where it gets worse , {vocalsound} then you 're probably {pause} hurting things , {vocalsound} I would say . So um {vocalsound} I mean at the very least that would be a reasonably prediction of what would happen with {disfmarker} with a different test set , that you 're not jiggling things with . So I guess the question is if you can do better than this . If you can {disfmarker} if we can approximate {vocalsound} the old numbers while still keeping the latency down .
Turn 261, F (PhD): Mmm . Yeah .
Turn 262, A (Professor): Uh , so . Um . What I was asking , though , is uh {disfmarker} are {disfmarker} what 's {disfmarker} what 's the level of communication with uh {vocalsound} the O G I gang now , about this and {disfmarker}
Turn 263, F (PhD): Well , we are exchanging mail as soon as we {disfmarker} {vocalsound} we have significant results .
Turn 264, A (Professor): Yeah .
Turn 265, F (PhD): Um . Yeah . For the moment , they are working on integrating {vocalsound} the um {vocalsound} spectral subtraction apparently from Ericsson .
Turn 266, A (Professor): Mm - hmm .
Turn 267, F (PhD): Um . Yeah . And so . Yeah . We are working on our side on other things like {vocalsound} uh also trying a sup spectral subtraction but of {disfmarker} of our own , I mean , another {vocalsound} spectral substraction .
Turn 268, A (Professor): Mm - hmm .
Turn 269, F (PhD): Um . Yeah . So I think it 's {disfmarker} it 's OK . It 's going {disfmarker}
Turn 270, A (Professor): Is there any further discussion about this {disfmarker} this idea of {disfmarker} of having some sort of source code control ?
Turn 271, F (PhD): Yeah . Well . For the moment they 're {disfmarker} uh everybody 's quite um {disfmarker} There is this Eurospeech deadline , so .
Turn 272, A (Professor): I see .
Turn 273, F (PhD): Um . And . Yeah . But yeah . As soon as we have something that 's significant and that 's better than {disfmarker} than what was submitted , we will fix {disfmarker} fix the system and {disfmarker} But we 've not discussed it {disfmarker} it {disfmarker} it {disfmarker} this yet , yeah .
Turn 274, A (Professor): Yeah . Sounds like a great idea but {disfmarker} but I think that {disfmarker} that um {vocalsound} he 's saying people are sort of scrambling for a Eurospeech deadline .
Turn 275, F (PhD): Mmm .
Turn 276, A (Professor): But that 'll be uh , uh done in a week . So , maybe after {vocalsound} this next one .
Turn 277, F (PhD): Yeah .
Turn 278, B (PhD): Wow ! Already a week ! Man !
Turn 279, A (Professor): Yeah .
Turn 280, B (PhD): You 're right . That 's amazing .
Turn 281, A (Professor): Yeah . Anybo - anybody in the {disfmarker} in this group do doing anything for Eurospeech ?
Turn 282, F (PhD): S
Turn 283, A (Professor): Or , is that what {disfmarker} is that {disfmarker}
Turn 284, F (PhD): Yeah we are {disfmarker} {vocalsound} We are trying to {disfmarker} to do something with the Meeting Recorder digits ,
Turn 285, A (Professor): Right .
Turn 286, F (PhD): and {disfmarker} But yeah . Yeah . And the good thing is that {pause} there is this first deadline ,
Turn 287, A (Professor): Yeah .
Turn 288, F (PhD): and , well , some people from OGI are working on a paper for this , but there is also the um {vocalsound} special session about th Aurora which is {disfmarker} {vocalsound} uh which has an extended deadline . So . The deadline is in May .
Turn 289, A (Professor): For uh {disfmarker} {vocalsound} Oh , for Eurospeech ?
Turn 290, F (PhD): For th Yeah .
Turn 291, A (Professor): Oh !
Turn 292, F (PhD): So f only for the experiments on Aurora . So it {disfmarker} it 's good ,
Turn 293, A (Professor): Oh , a special dispensation .
Turn 294, F (PhD): yeah .
Turn 295, A (Professor): That 's great .
Turn 296, B (PhD): Mm - hmm . Where is Eurospeech this year ?
Turn 297, F (PhD): It 's in Denmark .
Turn 298, A (Professor): Aalborg {disfmarker} Aalborg uh
Turn 299, B (PhD): Oh .
Turn 300, A (Professor): So the deadline {disfmarker} When 's the deadline ? When 's the deadline ?
Turn 301, F (PhD): Hmm ? I think it 's the thirteenth of May .
Turn 302, A (Professor): That 's great ! It 's great . So we should definitely get something in for that .
Turn 303, F (PhD): Yeah .
Turn 304, A (Professor): But on meeting digits , maybe there 's {disfmarker} Maybe .
Turn 305, F (PhD): Yeah .
Turn 306, A (Professor): Maybe .
Turn 307, F (PhD): So it would be for the first deadline .
Turn 308, A (Professor): Yeah .
Turn 309, F (PhD): Nnn .
Turn 310, A (Professor): Yeah . So , I mean , I {disfmarker} I think that you could certainly start looking at {disfmarker} at the issue uh but {disfmarker} but uh {vocalsound} I think it 's probably , on s from what Stephane is saying , it 's {disfmarker} it 's unlikely to get sort of active participation from the two sides until after they 've {disfmarker}
Turn 311, B (PhD): Well I could at least {disfmarker} Well , I 'm going to be out next week but I could {pause} try to look into like this uh CVS over the web . That seems to be a very popular {vocalsound} way of {pause} people distributing changes and {disfmarker} over , you know , multiple sites and things
Turn 312, A (Professor): Mm - hmm .
Turn 313, B (PhD): so maybe {vocalsound} if I can figure out how do that easily and then pass the information on to everybody so that it 's {vocalsound} you know , as easy to do as possible and {disfmarker} and people don't {disfmarker} it won't interfere with {comment} their regular work , then maybe that would be good . And I think we could use it for other things around here too . So .
Turn 314, A (Professor): Good .
Turn 315, C (Grad): That 's cool . And if you 're interested in using CVS , I 've set it up here ,
Turn 316, B (PhD): Oh great .
Turn 317, C (Grad): so .
Turn 318, B (PhD): OK .
Turn 319, C (Grad): um j
Turn 320, B (PhD): I used it a long time ago but it 's been a while so maybe I can ask you some questions .
Turn 321, C (Grad): Oh . So . I 'll be away tomorrow and Monday but I 'll be back on Tuesday or Wednesday .
Turn 322, B (PhD): OK .
Turn 323, A (Professor): Yeah . Dave , the other thing , actually , is {disfmarker} is this business about this wave form . Maybe you and I can talk a little bit at some point about {vocalsound} coming up with a better {vocalsound} uh demonstration of the effects of reverberation for our web page , cuz uh {vocalsound} {disfmarker} the uh {vocalsound} um I mean , actually the {disfmarker} the uh It made a good {disfmarker} good audio demonstration because when we could play that clip the {disfmarker} the {disfmarker} the really {vocalsound} obvious difference is that you can hear two voices and {disfmarker} {vocalsound} {vocalsound} in the second one and only hear {disfmarker}
Turn 324, B (PhD): Maybe we could just {pause} like , talk into a cup .
Turn 325, A (Professor): Yeah .
Turn 326, B (PhD): Some good reverb .
Turn 327, A (Professor): No , I mean , it sound {disfmarker} it sounds pretty reverberant , but I mean you can't {disfmarker} when you play it back in a room with a {disfmarker} you know a big room , {vocalsound} nobody can hear that difference really .
Turn 328, C (Grad): Yeah .
Turn 329, A (Professor): They hear that it 's lower amplitude and they hear there 's a second voice ,
Turn 330, C (Grad): Uh - huh .
Turn 331, A (Professor): um {vocalsound} but uh that {disfmarker} actually that makes for a perfectly good demo because that 's a real obvious thing , that you hear two voices .
Turn 332, B (PhD): But not of reverberation .
Turn 333, A (Professor): Yeah .
Turn 334, C (Grad): A boom .
Turn 335, A (Professor): Well that {disfmarker} that {disfmarker} that 's OK . But for the {disfmarker} the visual , just , you know , I 'd like to have uh {vocalsound} uh , you know , the spectrogram again ,
Turn 336, C (Grad): Yeah .
Turn 337, A (Professor): because you 're {disfmarker} you 're {disfmarker} you 're visual {vocalsound} uh abilities as a human being are so good {vocalsound} you can pick out {disfmarker} you know , you {disfmarker} you look at the good one , you look at the cru the screwed up one , and {disfmarker} and you can see the features in it without trying to @ @ {disfmarker}
Turn 338, B (PhD): I noticed that in the pictures .
Turn 339, A (Professor): yeah .
Turn 340, B (PhD): I thought " hey , you know th " I {disfmarker} My initial thought was " this is not too bad ! "
Turn 341, A (Professor): Right . But you have to {disfmarker} you know , if you look at it closely , you see " well , here 's a place where this one has a big formant {disfmarker} uh uh formant {disfmarker} maj major formants here are {disfmarker} {vocalsound} are moving quite a bit . " And then you look in the other one and they look practically flat .
Turn 342, B (PhD): Mm - hmm .
Turn 343, A (Professor): So I mean you could {disfmarker} that 's why I was thinking , in a section like that , you could take a look {disfmarker} look at just that part of the spectrogram and you could say " Oh yeah . This {disfmarker} this really distorted it quite a bit . "
Turn 344, B (PhD): Yeah . The main thing that struck me in looking at those two spectrograms was the difference in the high frequencies . It looked like {vocalsound} for the one that was farther away , you know , it really {disfmarker} everything was attenuated
Turn 345, A (Professor): Right .
Turn 346, B (PhD): and {disfmarker} I mean that was the main visual thing that I noticed .
Turn 347, A (Professor): Right . But it 's {disfmarker} it 's uh {disfmarker} So . Yeah . So there are {disfmarker} clearly are spectral effects . Since you 're getting all this indirect energy , then a lot of it does have {disfmarker} have uh {vocalsound} reduced high frequencies . But um the other thing is the temporal courses of things really are changed , and {disfmarker} {vocalsound} and uh we want to show that , in some obvious way . The reason I put the wave forms in there was because {vocalsound} uh they {disfmarker} they do look quite different . Uh . And so I thought " Oh , this is good . " but I {disfmarker} {vocalsound} I just uh {disfmarker} After {disfmarker} after uh they were put in there I didn't really look at them anymore , cuz I just {disfmarker} they were different . So {vocalsound} I want something that has a {disfmarker} is a more interesting explanation for why they 're different . Um .
Turn 348, C (Grad): Oh . So maybe we can just substitute one of these wave forms and um {vocalsound} then do some kind of zoom in on the spectrogram on an interesting area .
Turn 349, A (Professor): Something like that . Yeah .
Turn 350, C (Grad): Uh - huh .
Turn 351, A (Professor): The other thing that we had in there that I didn't like was that um {vocalsound} the most obvious characteristic of the difference uh when you listen to it is that there 's a second voice , and the {disfmarker} the {disfmarker} the {disfmarker} the {disfmarker} the uh {vocalsound} cuts that we have there actually don't correspond to the full wave form . It 's just the first {disfmarker} I think there was something where he was having some trouble getting so much in , or . I {disfmarker} I forget the reason behind it . But {vocalsound} it {disfmarker} it 's um {disfmarker} {vocalsound} it 's the first six seconds or something {vocalsound} of it and it 's in {vocalsound} the seventh or eighth second or something where @ @ the second voice comes in . So we {disfmarker} we would like to actually see {vocalsound} the voice coming in , too , I think , since that 's the most obvious thing {pause} when you listen to it .
Turn 352, C (Grad): Mm - hmm .
Turn 353, A (Professor): So . Um .
Turn 354, F (PhD): Uh , yeah . Yeah . I brought some {disfmarker} I don't know if {disfmarker} {vocalsound} some {vocalsound} figures here . Well . I start {disfmarker} we started to work on spectral subtraction . And {vocalsound} um {vocalsound} the preliminary results were very bad .
Turn 355, A (Professor): Uh - huh .
Turn 356, F (PhD): So the thing that we did is just to add spectral subtraction before this , the Wall uh process , which contains LDA on - line normalization . And it hurts uh a lot .
Turn 357, A (Professor): Uh - huh .
Turn 358, F (PhD): And so we started to look at {disfmarker} at um things like this , which is , well , it 's {disfmarker} Yeah . So you have the C - zero parameters for one uh Italian utterance .
Turn 359, D (PhD): You can @ @ .
Turn 360, F (PhD): And I plotted this for two channels . Channel zero is the close mic microphone , and channel one is the distant microphone . And it 's perfectly synchronized , so . And the sentence contain only one word , which is " Due " And it can't clearly be seen . Where {disfmarker} where is it ?
Turn 361, A (Professor): Uh - huh .
Turn 362, F (PhD): Where is the word ?
Turn 363, B (PhD): This is {disfmarker} this is ,
Turn 364, E (Grad): Hmm .
Turn 365, B (PhD): oh , a plot of C - zero ,
Turn 366, F (PhD): So .
Turn 367, B (PhD): the energy .
Turn 368, F (PhD): This is a plot of C - zero , uh when we don't use spectral substraction , and when there is no on - line normalization .
Turn 369, A (Professor): Mm - hmm .
Turn 370, F (PhD): So . There is just some filtering with the LDA and {vocalsound} and some downsampling , upsampling .
Turn 371, B (PhD): C - zero is the close talking ? {disfmarker}
Turn 372, F (PhD): So .
Turn 373, B (PhD): uh the close channel ?
Turn 374, F (PhD): Yeah . Yeah .
Turn 375, B (PhD): and s channel one is the {disfmarker}
Turn 376, F (PhD): Yeah . So C - zero is very clean , actually .
Turn 377, B (PhD): Yeah .
Turn 378, F (PhD): Uh then when we apply mean normalization it looks like the second figure , though it is not . Which is good . Well , the noise part is around zero
Turn 379, A (Professor): Mm - hmm .
Turn 380, F (PhD): and {disfmarker} {vocalsound} {vocalsound} And then the third figure is what happens when we apply mean normalization and variance normalization . So . What we can clearly see is that on the speech portion {vocalsound} the two channel come {disfmarker} becomes very close , but also what happens on the noisy portion is that the variance of the noise is {disfmarker}
Turn 381, A (Professor): Mm - hmm .
Turn 382, B (PhD): This is still being a plot of C - zero ? OK .
Turn 383, F (PhD): Yeah . This is still C - zero .
Turn 384, B (PhD): Can I ask um what does variance normalization do ? w What is the effect of that ?
Turn 385, A (Professor): Normalizes the variance .
Turn 386, F (PhD): So it {disfmarker} it {disfmarker} Yeah .
Turn 387, B (PhD): I mean
Turn 388, F (PhD): It normalized th the standard deviation .
Turn 389, B (PhD): y Yeah .
Turn 390, F (PhD): So it {disfmarker}
Turn 391, B (PhD): No , I understand that ,
Turn 392, F (PhD): You {disfmarker} you get an estimate of the standard deviation .
Turn 393, B (PhD): but I mean {disfmarker}
Turn 394, F (PhD): That 's
Turn 395, B (PhD): No .
Turn 396, F (PhD): um {disfmarker}
Turn 397, B (PhD): No , I understand what it is , but I mean , what does it {disfmarker} what 's {disfmarker} what is
Turn 398, F (PhD): Yeah but .
Turn 399, B (PhD): uh {disfmarker}
Turn 400, A (Professor): What 's the rationale ?
Turn 401, B (PhD): We Yeah . Yeah . Why {disfmarker} why do it ?
Turn 402, F (PhD): Uh .
Turn 403, A (Professor): Well , I mean , because {vocalsound} everything uh {disfmarker} If you have a system based on Gaussians , everything is based on means and variances .
Turn 404, B (PhD): Yeah .
Turn 405, A (Professor): So if there 's an overall {vocalsound} reason {disfmarker} You know , it 's like uh if you were doing uh image processing and in some of the pictures you were looking at , uh there was a lot of light uh and {disfmarker} and in some , there was low light ,
Turn 406, B (PhD): Mm - hmm .
Turn 407, A (Professor): you know , you would want to adjust for that in order to compare things .
Turn 408, B (PhD): Mm - hmm .
Turn 409, A (Professor): And the variance is just sort of like the next moment , you know ? So uh {vocalsound} what if um one set of pictures was taken uh so that throughout the course it was {disfmarker} went through daylight and night uh {vocalsound} um um ten times , another time it went thr I mean i is , you know , how {disfmarker} how much {disfmarker} {vocalsound} how much vari
Turn 410, B (PhD): Oh , OK .
Turn 411, A (Professor): Or no . I guess a better example would be {vocalsound} how much of the light was coming in from outside rather than artificial light . So if it was a lot {disfmarker} {vocalsound} if more was coming from outside , then there 'd be the bigger effect of the {disfmarker} of the {disfmarker} of the change in the {disfmarker} So every mean {disfmarker} every {disfmarker} all {disfmarker} all of the {disfmarker} the parameters that you have , especially the variances , are going to be affected by the overall variance .
Turn 412, B (PhD): Oh , OK . Uh - huh .
Turn 413, A (Professor): And so , in principle , you {disfmarker} if you remove that source , then , you know , you can {disfmarker}
Turn 414, B (PhD): I see . OK . So would {disfmarker} the major effect is {disfmarker} that you 're gonna get is by normalizing the means ,
Turn 415, A (Professor): That 's the first order but {disfmarker} thing ,
Turn 416, B (PhD): but it may help {disfmarker} First - order effects .
Turn 417, A (Professor): but then the second order is {disfmarker} is the variances
Turn 418, B (PhD): And it may help to do the variance . OK .
Turn 419, A (Professor): because , again , if you {disfmarker} if you 're trying to distinguish between E and B
Turn 420, B (PhD): OK .
Turn 421, A (Professor): if it just so happens that the E 's {vocalsound} were a more {disfmarker} you know , were recorded when {disfmarker} when the energy was {disfmarker} was {disfmarker} was larger or something ,
Turn 422, B (PhD): Mm - hmm . Mm - hmm . Mm - hmm . 
Turn 423, A (Professor): or the variation in it was larger , {vocalsound} uh than with the B 's , then this will be {disfmarker} give you some {disfmarker} some bias .
Turn 424, B (PhD): 
Turn 425, A (Professor): So the {disfmarker} {vocalsound} it 's removing these sources of variability in the data {vocalsound} that have nothing to do with the linguistic component .
Turn 426, B (PhD): OK .
Turn 427, F (PhD): Mmm .
Turn 428, B (PhD): Gotcha . OK . Sorry to interrupt .
Turn 429, A (Professor): But the {disfmarker} the uh {disfmarker} but let me as ask {disfmarker} ask you something .
Turn 430, F (PhD): Yep . And it {disfmarker} and this {disfmarker}
Turn 431, A (Professor): i is {disfmarker} if {disfmarker} If you have a good voice activity detector , isn't {disfmarker} isn't it gonna pull that out ?
Turn 432, F (PhD): Yeah . Sure . If they are good . Yeah . Well what it {disfmarker} it shows is that , yeah , perhaps a good voice activity detector is {disfmarker} is good before on - line normalization and that 's what uh {vocalsound} we 've already observed . But uh , yeah , voice activity detection is not {vocalsound} {vocalsound} an easy thing neither .
Turn 433, B (PhD): But after you do this , after you do the variance normalization {disfmarker} I mean .
Turn 434, F (PhD): Mm - hmm .
Turn 435, B (PhD): I don't know , it seems like this would be a lot easier than this signal to work with .
Turn 436, F (PhD): Yeah . So . What I notice is that , while I prefer to look at the second figure than at the third one , well , because you clearly see where speech is .
Turn 437, A (Professor): Yeah .
Turn 438, B (PhD): Yeah .
Turn 439, F (PhD): But the problem is that on the speech portion , channel zero and channel one are more different than when you use variance normalization where channel zero and channel one become closer .
Turn 440, A (Professor): Right .
Turn 441, B (PhD): But for the purposes of finding the speech {disfmarker}
Turn 442, F (PhD): And {disfmarker} Yeah , but here {disfmarker}
Turn 443, B (PhD): You 're more interested in the difference between the speech and the nonspeech ,
Turn 444, F (PhD): Yeah .
Turn 445, B (PhD): right ?
Turn 446, F (PhD): Yeah . So I think , yeah . For I th I think that it {disfmarker} perhaps it shows that {vocalsound} uh the parameters that the voice activity detector should use {disfmarker} uh have to use should be different than the parameter that have to be used for speech recognition .
Turn 447, A (Professor): Yeah . So basically you want to reduce this effect .
Turn 448, F (PhD): Well , y
Turn 449, A (Professor): So you can do that by doing the voi voice activity detection . You also could do it by spect uh spectral subtraction before the {vocalsound} variance normalization , right ?
Turn 450, F (PhD): Yeah , but it 's not clear , yeah .
Turn 451, A (Professor): So uh {disfmarker}
Turn 452, F (PhD): We So . Well . It 's just to
Turn 453, A (Professor): Yeah .
Turn 454, F (PhD): the {disfmarker} the number that at that are here are recognition experiments on Italian HM and MM {vocalsound} with these two kinds of parameters . And , {pause} well , it 's better with variance normalization .
Turn 455, A (Professor): Yeah . Yeah . So it does get better even though it looks ugly .
Turn 456, F (PhD): Uh {disfmarker}
Turn 457, A (Professor): OK . but does this have the voice activity detection in it ?
Turn 458, F (PhD): Yeah .
Turn 459, A (Professor): OK .
Turn 460, F (PhD): Um .
Turn 461, A (Professor): So .
Turn 462, E (Grad): OK .
Turn 463, B (PhD): Where 's th
Turn 464, F (PhD): But the fact is that the voice activity detector doesn't work on channel one . So . Yeah .
Turn 465, A (Professor): Uh - huh .
Turn 466, B (PhD): Where {disfmarker} at what stage is the voice activity detector applied ? Is it applied here or a after the variance normalization ?
Turn 467, F (PhD): Hmm ?
Turn 468, A (Professor): Spectral subtraction , I guess .
Turn 469, B (PhD): or {disfmarker}
Turn 470, F (PhD): It 's applied before variance normalization . So it 's a good thing ,
Turn 471, B (PhD): Oh .
Turn 472, F (PhD): because I guess voice activity detection on this should {disfmarker} could be worse .
Turn 473, B (PhD): Yeah . Is it applied all the way back here ?
Turn 474, F (PhD): It 's applied the um on , yeah , something like this ,
Turn 475, B (PhD): Maybe that 's why it doesn't work for channel one .
Turn 476, F (PhD): yeah . Perhaps , yeah .
Turn 477, A (Professor): Can I {disfmarker}
Turn 478, F (PhD): So we could perhaps do just mean normalization before VAD .
Turn 479, B (PhD): Mm - hmm .
Turn 480, A (Professor): Mm - hmm . Can I ask a , I mean {disfmarker} a sort of top - level question , which is {vocalsound} um " if {disfmarker} if most of what the OGI folk are working with is trying to {vocalsound} integrate this other {disfmarker} other uh spectral subtraction , {vocalsound} why are we worrying about it ? "
Turn 481, F (PhD): Mm - hmm . About ? Spectral subtraction ?
Turn 482, A (Professor): Yeah .
Turn 483, F (PhD): It 's just uh {disfmarker} Well it 's another {disfmarker} They are trying to u to use the um {disfmarker} {vocalsound} the Ericsson and we 're trying to use something {disfmarker} something else . And . Yeah , and also to understand what happens because
Turn 484, A (Professor): OK .
Turn 485, F (PhD): uh fff Well . When we do spectral subtraction , actually , I think {vocalsound} that this is the {disfmarker} the two last figures .
Turn 486, A (Professor): Yeah .
Turn 487, F (PhD): Um . It seems that after spectral subtraction , speech is more emerging now uh {vocalsound} than {disfmarker} than before .
Turn 488, A (Professor): Mm - hmm .
Turn 489, B (PhD): Speech is more what ?
Turn 490, F (PhD): Well , the difference between the energy of the speech and the energy of the n spectral subtrac subtracted noise portion is {disfmarker} is larger .
Turn 491, A (Professor): Mm - hmm .
Turn 492, F (PhD): Well , if you compare the first figure to this one {disfmarker} Actually the scale is not the same , but if you look at the {disfmarker} the numbers um {vocalsound} you clearly see that the difference between the C - zero of the speech and C - zero of the noise portion is larger . Uh but what happens is that after spectral subtraction , {vocalsound} you also increase the variance of this {disfmarker} of C - zero .
Turn 493, A (Professor): Mm - hmm .
Turn 494, F (PhD): And so if you apply variance normalization on this , it completely sc screw everything . Well .
Turn 495, A (Professor): Mm - hmm .
Turn 496, F (PhD): Um . Uh . Yeah . So yeah . And what they did at OGI is just {vocalsound} uh they don't use on - line normalization , for the moment , on spectral subtraction and I think {disfmarker} Yeah . I think as soon as they will try on - line normalization {vocalsound} there will be a problem . So yeah , we 're working on the same thing but {vocalsound} I think uh with different {disfmarker} different system and {disfmarker}
Turn 497, A (Professor): Right . I mean , i the Intellectually it 's interesting to work on things th uh one way or the other
Turn 498, F (PhD): Mm - hmm .
Turn 499, A (Professor): but I 'm {disfmarker} I 'm just wondering if um {disfmarker} {vocalsound} on the list of things that there are to do , if there are things that we won't do because {vocalsound} we 've got two groups doing the same thing .
Turn 500, F (PhD): Mm - hmm .
Turn 501, A (Professor): Um . That 's {disfmarker}
Turn 502, F (PhD): Mm - hmm .
Turn 503, A (Professor): Um . Just {disfmarker} just asking . Uh . I mean , it 's {disfmarker}
Turn 504, F (PhD): Yeah , well ,
Turn 505, B (PhD): There also could be {disfmarker} I mean . I can maybe see a reason f for both working on it too
Turn 506, F (PhD): uh .
Turn 507, B (PhD): if {vocalsound} um you know , if {disfmarker} if {disfmarker} if you work on something else and {disfmarker} and you 're waiting for them to give you {vocalsound} spectral subtraction {disfmarker} I mean it 's hard to know whether {vocalsound} the effects that you get from the other experiments you do will {vocalsound} carry over once you then bring in their spectral subtraction module . So it 's {disfmarker} it 's almost like everything 's held up waiting for this {vocalsound} one thing . I don't know if that 's true or not , but I could see how {disfmarker}
Turn 508, F (PhD): Mmm .
Turn 509, A (Professor): I don't know .
Turn 510, B (PhD): Maybe that 's what you were thinking .
Turn 511, A (Professor): I don't know . {vocalsound} I mean , we still evidently have a latency reduction plan which {disfmarker} which isn't quite what you 'd like it to be . That {disfmarker} that seems like one prominent thing . And then uh weren't issues of {disfmarker} of having a {disfmarker} a second stream or something ? That was {disfmarker} Was it {disfmarker} There was this business that , you know , we {disfmarker} we could use up the full forty - eight hundred bits , and {disfmarker}
Turn 512, F (PhD): Yeah . But I think they ' I think we want to work on this . They also want to work on this , so . Uh . {vocalsound} yeah . We {disfmarker} we will try MSG , but um , yeah . And they are t I think they want to work on the second stream also , but more with {vocalsound} some kind of multi - band or , well , what they call TRAP or generalized TRAP .
Turn 513, A (Professor): Mm - hmm .
Turn 514, F (PhD): Um . So .
Turn 515, A (Professor): OK . Do you remember when the next meeting is supposed to be ? the next uh {disfmarker}
Turn 516, F (PhD): It 's uh in June .
Turn 517, A (Professor): In June . OK .
Turn 518, F (PhD): Yeah .
Turn 519, A (Professor): Yeah . Um . Yeah , the other thing is that you saw that {disfmarker} that mail about uh the VAD {disfmarker} V A Ds performing quite differently ? That that uh So um . This {disfmarker} there was this experiment of uh " what if we just take the baseline ? "
Turn 520, F (PhD): Mmm .
Turn 521, A (Professor): set uh of features , just mel cepstra , and you inc incorporate the different V A And it looks like the {disfmarker} the French VAD is actually uh better {disfmarker} significantly better .
Turn 522, B (PhD): Improves the baseline ?
Turn 523, A (Professor): Yeah . Yeah .
Turn 524, F (PhD): Yeah but I don't know which VAD they use . Uh . If the use the small VAD I th I think it 's on {disfmarker} I think it 's easy to do better because it doesn't work at all . So . I {disfmarker} I don't know which {disfmarker} which one . It 's Pratibha that {disfmarker} that did this experiment .
Turn 525, D (PhD): Yeah .
Turn 526, F (PhD): Um . We should ask which VAD she used .
Turn 527, D (PhD): I don't @ @ . He {disfmarker} Actually , I think that he say with the good VAD of {disfmarker} from OGI and with the Alcatel VAD . And the experiment was sometime better , sometime worse .
Turn 528, F (PhD): Yeah but I {disfmarker} it 's uh {disfmarker} I think you were talking about the other mail that used VAD on the reference features .
Turn 529, A (Professor): Yes .
Turn 530, F (PhD): Yeah .
Turn 531, A (Professor): And on that one , uh the French one is {disfmarker} was better .
Turn 532, D (PhD): I don't remember .
Turn 533, A (Professor): It was just better .
Turn 534, D (PhD): Mm - hmm .
Turn 535, A (Professor): I mean it was enough better that {disfmarker} that it would {vocalsound} uh account for a fair amount of the difference between our performance , actually .
Turn 536, F (PhD): Mm - hmm .
Turn 537, D (PhD): Mm - hmm .
Turn 538, A (Professor): So . {vocalsound} Uh . So if they have a better one , we should use it . I mean . You know ? it 's {disfmarker} you can't work on everything .
Turn 539, F (PhD): Yeah .
Turn 540, A (Professor): Uh . {vocalsound} Uh . Yeah .
Turn 541, F (PhD): Yeah , so we should find out if it 's really better . I mean if it {disfmarker} the {disfmarker} compared to the small or the big network .
Turn 542, D (PhD): Mm - hmm .
Turn 543, A (Professor): Yeah .
Turn 544, F (PhD): And perhaps we can easily improve if {disfmarker} if we put like mean normalization before the {disfmarker} before the VAD . Because {disfmarker} {vocalsound} as {disfmarker} as you 've {pause} mentioned .
Turn 545, A (Professor): Yeah .
Turn 546, F (PhD): Mmm .
Turn 547, A (Professor): H Hynek will be back in town uh the week after next , back {disfmarker} back in the country . So . And start {disfmarker} start organizing uh {vocalsound} more visits and connections and so forth ,
Turn 548, F (PhD): Mm - hmm .
Turn 549, A (Professor): and {disfmarker} uh working towards June .
Turn 550, F (PhD): Yeah .
Turn 551, D (PhD): Also is Stephane was thinking that {vocalsound} maybe it was useful to f to think about uh {vocalsound} voiced - unvoiced {disfmarker}
Turn 552, F (PhD): Mm - hmm .
Turn 553, D (PhD): to work uh here in voiced - unvoiced detection .
Turn 554, F (PhD): Yeah . Yeah .
Turn 555, D (PhD): And we are looking {vocalsound} {vocalsound} in the uh signal .
Turn 556, F (PhD): Yeah , my feeling is that um actually {vocalsound} when we look at all the proposals , ev everybody is still using some kind of spectral envelope
Turn 557, A (Professor): Right .
Turn 558, F (PhD): and um it 's {disfmarker}
Turn 559, A (Professor): No use of pitch uh basically . Yeah .
Turn 560, F (PhD): Yeah , well , not pitch , but to look at the um fine {disfmarker} at the {disfmarker} at the high re high resolution spectrum .
Turn 561, A (Professor): Yeah . Well , it {disfmarker}
Turn 562, F (PhD): So . We don't necessarily want to find the {disfmarker} the pitch of the {disfmarker} of the sound but uh {disfmarker} Cuz I have a feeling that {vocalsound} when we look {disfmarker} when we look at the {disfmarker} just at the envelope there is no way you can tell if it 's voiced and unvoiced , if there is some {disfmarker} It 's {disfmarker} it 's easy in clean speech because voiced sound are more low frequency and . So there would be more ,
Turn 563, A (Professor): Yeah .
Turn 564, F (PhD): uh {disfmarker} there is the first formant , which is the larger and then voiced sound are more high frequencies cuz it 's frication and {disfmarker}
Turn 565, A (Professor): Right .
Turn 566, F (PhD): But , yeah . When you have noise there is no um {disfmarker} {vocalsound} if {disfmarker} if you have a low frequency noise it could be taken for {disfmarker} for voiced speech and .
Turn 567, A (Professor): Yeah , you can make these mistakes ,
Turn 568, F (PhD): So .
Turn 569, A (Professor): but {disfmarker} but {disfmarker}
Turn 570, B (PhD): Isn't there some other
Turn 571, F (PhD): S
Turn 572, B (PhD): uh d
Turn 573, F (PhD): So I think that it {disfmarker} it would be good {disfmarker} Yeah , yeah , well , go {disfmarker} go on .
Turn 574, B (PhD): Uh , I was just gonna say isn't there {disfmarker} {vocalsound} aren't {disfmarker} aren't there lots of ideas for doing voice activity , or speech - nonspeech rather , {comment} um by looking at {vocalsound} um , you know , uh {vocalsound} I guess harmonics or looking across time {disfmarker}
Turn 575, A (Professor): Well , I think he was talking about the voiced - unvoiced , though ,
Turn 576, F (PhD): Mmm .
Turn 577, A (Professor): right ? So , not the speech - nonspeech .
Turn 578, B (PhD): Yeah . Well even with e
Turn 579, A (Professor): Yeah .
Turn 580, B (PhD): uh w ah you know , uh even with the voiced - non {pause} voiced - unvoiced
Turn 581, F (PhD): Mmm .
Turn 582, B (PhD): um {disfmarker} I thought that you or {pause} somebody was talking about {disfmarker}
Turn 583, A (Professor): Well . Uh yeah . B We should let him finish what he w he was gonna say ,
Turn 584, F (PhD): So .
Turn 585, B (PhD): OK .
Turn 586, A (Professor): and {disfmarker}
Turn 587, B (PhD): So go ahead .
Turn 588, F (PhD): Um yeah , so yeah , I think if we try to develop a second stream well , there would be one stream that is the envelope and the second , it could be interesting to have that 's {disfmarker} something that 's more related to the fine structure of the spectrum . And . Yeah , so I don't know . We were thinking about like using ideas from {disfmarker} from Larry Saul , have a good voice detector , have a good , well , voiced - speech detector , that 's working on {disfmarker} on the FFT and {vocalsound} uh
Turn 589, A (Professor): U
Turn 590, F (PhD): Larry Saul could be an idea . We were are thinking about just {vocalsound} kind of uh taking the spectrum and computing the variance of {disfmarker} of the high resolution spectrum {vocalsound} and things like this .
Turn 591, A (Professor): So u s u OK . So {disfmarker} So many {vocalsound} tell you something about that . Uh we had a guy here some years ago who did some work on {vocalsound} um {vocalsound} making use of voicing information uh to {vocalsound} help in reducing the noise .
Turn 592, F (PhD): Yeah ?
Turn 593, A (Professor): So what he was doing is basically y you {disfmarker} {vocalsound} you do estimate the pitch .
Turn 594, F (PhD): Mm - hmm .
Turn 595, A (Professor): And um you {disfmarker} from that you {disfmarker} you estimate {disfmarker} or you estimate fine harmonic structure , whichev ei either way , it 's more or less the same . But {vocalsound} uh the thing is that um you then {vocalsound} can get rid of things that are not {disfmarker} i if there is strong harmonic structure , {vocalsound} you can throw away stuff that 's {disfmarker} that 's non - harmonic .
Turn 596, F (PhD): Mm - hmm . Mm - hmm .
Turn 597, A (Professor): And that {disfmarker} that is another way of getting rid of part of the noise
Turn 598, F (PhD): Yeah .
Turn 599, A (Professor): So um that 's something {vocalsound} that is sort of finer ,
Turn 600, F (PhD): Yeah .
Turn 601, A (Professor): brings in a little more information than just spectral subtraction . Um .
Turn 602, F (PhD): Mm - hmm .
Turn 603, A (Professor): And he had some {disfmarker} I mean , he did that sort of in combination with RASTA . It was kind of like RASTA was taking care of convolutional stuff
Turn 604, F (PhD): Mmm .
Turn 605, A (Professor): and he was {disfmarker}
Turn 606, F (PhD): Mm - hmm .
Turn 607, A (Professor): and {disfmarker} and got some {disfmarker} some decent results doing that . So that {disfmarker} that 's another {disfmarker} another way . But yeah , there 's {disfmarker} there 's {disfmarker}
Turn 608, F (PhD): Yeah . Mmm .
Turn 609, A (Professor): Right . There 's all these cues . We 've actually back when Chuck was here we did some voiced - unvoiced uh {vocalsound} classification using a bunch of these ,
Turn 610, F (PhD): But {disfmarker}
Turn 611, A (Professor): and {disfmarker} and uh works OK . Obviously it 's not perfect but um {disfmarker}
Turn 612, F (PhD): Mm - hmm .
Turn 613, A (Professor): But the thing is that you can't {disfmarker} given the constraints of this task , we can't , {vocalsound} in a very nice way , feed {pause} forward to the recognizer the information {disfmarker} the probabilistic information that you might get about whether it 's voiced or unvoiced , where w we can't you know affect the {disfmarker} {vocalsound} the uh distributions or anything .
Turn 614, F (PhD): Mm - hmm .
Turn 615, A (Professor): But we {disfmarker} what we uh {disfmarker} I guess we could Yeah .
Turn 616, B (PhD): Didn't the head dude send around that message ? Yeah , I think you sent us all a copy of the message , where he was saying that {disfmarker} I I 'm not sure , exactly , what the gist of what he was saying , but something having to do with the voice {vocalsound} activity detector and that it will {disfmarker} {vocalsound} that people shouldn't put their own in or something . It was gonna be a {disfmarker}
Turn 617, A (Professor): That {disfmarker} But {disfmarker} OK . So that 's voice activity detector as opposed to voicing detector .
Turn 618, F (PhD): They didn't .
Turn 619, A (Professor): So we 're talking about something a little different .
Turn 620, F (PhD): Mmm .
Turn 621, B (PhD): Oh , I 'm sorry .
Turn 622, A (Professor): Right ?
Turn 623, B (PhD): I {disfmarker} I missed that .
Turn 624, F (PhD): Mmm .
Turn 625, A (Professor): I guess what you could do , maybe this would be w useful , if {disfmarker} if you have {disfmarker} if you view the second stream , yeah , before you {disfmarker} before you do KLT 's and so forth , if you do view it as probabilities , and if it 's an independent {disfmarker} So , if it 's {disfmarker} if it 's uh not so much {vocalsound} envelope - based by fine - structure - based , uh looking at harmonicity or something like that , um if you get a probability from that information and then multiply it by {disfmarker} you know , multiply by all the voiced {vocalsound} outputs and all the unvoiced outputs , you know , then {vocalsound} use that as the
Turn 626, F (PhD): Mm - hmm .
Turn 627, A (Professor): uh {disfmarker} take the log of that or {vocalsound} uh pre pre uh {disfmarker} pre - nonlinearity ,
Turn 628, F (PhD): Yeah . i if {disfmarker}
Turn 629, A (Professor): uh and do the KLT on the {disfmarker} on {disfmarker} on that ,
Turn 630, F (PhD): Yeah .
Turn 631, A (Professor): then that would {disfmarker} that would I guess be uh a reasonable use of independent information . So maybe that 's what you meant . And then that would be {disfmarker}
Turn 632, F (PhD): Yeah , well , I was not thinking this {disfmarker} yeah , this could be an yeah So you mean have some kind of probability for the v the voicing
Turn 633, A (Professor): R Right . So you have a second neural net .
Turn 634, F (PhD): and then use a tandem system
Turn 635, A (Professor): It could be pretty small . Yeah . If you have a tandem system and then you have some kind of {disfmarker} it can be pretty small {disfmarker} net {disfmarker}
Turn 636, F (PhD): Mm - hmm .
Turn 637, A (Professor): we used {disfmarker} we d did some of this stuff . Uh I {disfmarker} I did , some years ago ,
Turn 638, F (PhD): Yeah .
Turn 639, A (Professor): and the {disfmarker} and {disfmarker} and you use {disfmarker} {vocalsound} the thing is to use information primarily that 's different as you say , it 's more fine - structure - based than {disfmarker} than envelope - based
Turn 640, F (PhD): Mm - hmm .
Turn 641, A (Professor): uh so then it you {disfmarker} you {disfmarker} you can pretty much guarantee it 's stuff that you 're not looking at very well with the other one , and uh then you only use for this one distinction .
Turn 642, F (PhD): Alright .
Turn 643, A (Professor): And {disfmarker} and so now you 've got a probability of the cases , and you 've got uh the probability of the finer uh categories on the other side . You multiply them where appropriate and uh {vocalsound} um
Turn 644, F (PhD): I see , yeah . Mm - hmm .
Turn 645, A (Professor): if they really are from independent {pause} information sources then {vocalsound} they should have different kinds of errors
Turn 646, F (PhD): Mm - hmm .
Turn 647, A (Professor): and roughly independent errors , and {vocalsound} it 's a good choice for {disfmarker}
Turn 648, F (PhD): Mm - hmm . Mm - hmm . Yeah .
Turn 649, A (Professor): Uh . Yeah , that 's a good idea .
Turn 650, F (PhD): Yeah . Because , yeah , well , spectral subtraction is good and we could u we could use the fine structure to {disfmarker} to have a better estimate of the noise but {vocalsound} still there is this issue with spectral subtraction that it seems to increase the variance of {disfmarker} of {disfmarker} of
Turn 651, A (Professor): Yeah .
Turn 652, F (PhD): um Well it 's this musical noise which is annoying if you d you do some kind of on - line normalization after .
Turn 653, A (Professor): Right .
Turn 654, F (PhD): So . Um . Yeah . Well . Spectral subtraction and on - line normalization don't seem to {disfmarker} to go together very well . I
Turn 655, A (Professor): Or if you do a spectral subtraction {disfmarker} do some spectral subtraction first and then do some on - line normalization then do some more spectral subtraction {disfmarker} I mean , maybe {disfmarker} maybe you can do it layers or something so it doesn't {disfmarker} doesn't hurt too much or something .
Turn 656, F (PhD): Ah , yeah .
Turn 657, A (Professor): But it {disfmarker} but uh , anyway I think I was sort of arguing against myself there by giving that example
Turn 658, F (PhD): Yeah .
Turn 659, A (Professor): uh I mean cuz I was already sort of {vocalsound} suggesting that we should be careful about not spending too much time on exactly what they 're doing In fact if you get {disfmarker} if you go into uh {disfmarker} a uh harmonics - related thing {vocalsound} it 's definitely going to be different than what they 're doing and uh uh
Turn 660, F (PhD): Mm - hmm .
Turn 661, A (Professor): should have some interesting properties in noise . Um . {vocalsound} I know that when have people have done {pause} um sort of the obvious thing of taking {vocalsound} uh your feature vector and adding {pause} in some variables which are {vocalsound} pitch related or uh that {disfmarker} it hasn't {disfmarker} my impression it hasn't particularly helped . Uh . Has not .
Turn 662, F (PhD): It {disfmarker} it i has not ,
Turn 663, A (Professor): Yeah .
Turn 664, F (PhD): yeah .
Turn 665, A (Professor): But I think uh {pause} that 's {disfmarker} that 's a question for this uh you know extending the feature vector versus having different streams .
Turn 666, F (PhD): Oh . Was it nois noisy condition ? the example that you {disfmarker} you just
Turn 667, A (Professor): And {disfmarker} and it may not have been noisy conditions .
Turn 668, F (PhD): Yeah .
Turn 669, A (Professor): Yeah . I {disfmarker} I don't remember the example but it was {disfmarker} {vocalsound} it was on some DARPA data and some years ago and so it probably wasn't , actually
Turn 670, F (PhD): Mm - hmm . Mm - hmm . Yeah . But we were thinking , we discussed with Barry about this , and {vocalsound} perhaps {vocalsound} thinking {disfmarker} we were thinking about some kind of sheet cheating experiment where we would use TIMIT
Turn 671, A (Professor): Uh - huh .
Turn 672, F (PhD): and see if giving the d uh , this voicing bit would help in {disfmarker} in terms of uh frame classification .
Turn 673, A (Professor): Why don't you {disfmarker} why don't you just do it with Aurora ?
Turn 674, F (PhD): Mmm .
Turn 675, A (Professor): Just any i in {disfmarker} in each {disfmarker} in each frame
Turn 676, F (PhD): Yeah , but {disfmarker} but {disfmarker} B but we cannot do the cheating , this cheating thing .
Turn 677, E (Grad): We 're {disfmarker}
Turn 678, A (Professor): uh {disfmarker}
Turn 679, E (Grad): We need labels .
Turn 680, A (Professor): Why not ?
Turn 681, F (PhD): Well . Cuz we don't have {disfmarker} Well , for Italian perhaps we have , but we don't have this labeling for Aurora . We just have a labeling with word models
Turn 682, A (Professor): I see .
Turn 683, F (PhD): but not for phonemes .
Turn 684, D (PhD): Not for foreigners .
Turn 685, E (Grad): we don't have frame {disfmarker} frame level transcriptions .
Turn 686, A (Professor): Um .
Turn 687, D (PhD): Right .
Turn 688, F (PhD): Um . {vocalsound} Yeah .
Turn 689, A (Professor): But you could {disfmarker} I mean you can {disfmarker} you can align so that {disfmarker} It 's not perfect , but if you {disfmarker} if you know what was said and {disfmarker}
Turn 690, B (PhD): But the problem is that their models are all word level models . So there 's no phone models {pause} that you get alignments for .
Turn 691, F (PhD): Mm - hmm .
Turn 692, A (Professor): Oh .
Turn 693, B (PhD): You {disfmarker} So you could find out where the word boundaries are but that 's about it .
Turn 694, A (Professor): Yeah . I see .
Turn 695, E (Grad): S But we could use uh the {disfmarker} the noisy version that TIMIT , which {vocalsound} you know , is similar to the {disfmarker} the noises found in the TI - digits {vocalsound} um portion of Aurora .
Turn 696, F (PhD): Yeah . noise , yeah . Yeah , that 's right , yep . Mmm .
Turn 697, A (Professor): Yeah .
Turn 698, F (PhD): Well , I guess {disfmarker} I guess we can {disfmarker} we can say that it will help , but I don't know . If this voicing bit doesn't help , uh , I think we don't have to {disfmarker} to work more about this because {disfmarker}
Turn 699, A (Professor): Uh .
Turn 700, F (PhD): Uh . It 's just to know if it {disfmarker} how much i it will help
Turn 701, A (Professor): Yeah .
Turn 702, F (PhD): and to have an idea of how much we can gain .
Turn 703, A (Professor): Right . I mean in experiments that we did a long time ago
Turn 704, F (PhD): Mmm .
Turn 705, A (Professor): and different ta it was probably Resource Management or something , um , I think you were getting {pause} something like still eight or nine percent error on the voicing , as I recall . And um , so um
Turn 706, E (Grad): Another person 's voice .
Turn 707, A (Professor): what that said is that , sort of , left to its own devices , like without the {disfmarker} a strong language model and so forth , that you would {disfmarker} {vocalsound} you would make significant number of errors {vocalsound} just with your uh probabilistic machinery in deciding
Turn 708, B (PhD): It also {disfmarker}
Turn 709, A (Professor): one oh
Turn 710, B (PhD): Yeah , the {disfmarker} though I think uh there was one problem with that in that , you know , we used canonical mapping so {vocalsound} our truth may not have really been {pause} true to the acoustics .
Turn 711, A (Professor): Uh - huh .
Turn 712, E (Grad): Hmm .
Turn 713, B (PhD): So .
Turn 714, F (PhD): Mmm .
Turn 715, A (Professor): Yeah . Well back twenty years ago when I did this voiced - unvoiced stuff , we were getting more like {vocalsound} ninety - seven or ninety - eight percent correct in voicing . But that was {vocalsound} speaker - dependent {vocalsound} actually . We were doing training {vocalsound} on a particular announcer
Turn 716, F (PhD): Mm - hmm .
Turn 717, A (Professor): and {disfmarker} and getting a {vocalsound} very good handle on the features .
Turn 718, F (PhD): Mm - hmm .
Turn 719, A (Professor): And we did this complex feature selection thing where we looked at all the different possible features one could have for voicing and {disfmarker} {vocalsound} and {disfmarker} and uh {disfmarker} and exhaustively searched {vocalsound} all size subsets and {disfmarker} and uh {disfmarker} for {disfmarker} for that particular speaker and you 'd find you know the five or six features which really did well on them .
Turn 720, B (PhD): Wow !
Turn 721, F (PhD): Mm - hmm .
Turn 722, A (Professor): And then doing {disfmarker} doing all of that we could get down to two or three percent error . But that , again , was speaker - dependent with {vocalsound} lots of feature selection
Turn 723, F (PhD): Mm - hmm .
Turn 724, A (Professor): and a very complex sort of thing .
Turn 725, F (PhD): Mmm .
Turn 726, A (Professor): So I would {disfmarker} I would believe {vocalsound} that uh it was quite likely that um looking at envelope only , that we 'd be {vocalsound} significantly worse than that .
Turn 727, F (PhD): Mm - hmm .
Turn 728, A (Professor): Uh .
Turn 729, F (PhD): And the {disfmarker} all the {disfmarker} the SpeechCorders ? what 's the idea behind ? Cuz they {disfmarker} they have to {disfmarker} Oh , they don't even have to detect voiced spe speech ?
Turn 730, A (Professor): The modern ones don't do a {disfmarker} {vocalsound} a simple switch .
Turn 731, F (PhD): They just work on the code book
Turn 732, A (Professor): They work on the code book excitation .
Turn 733, F (PhD): and find out the best excitation .
Turn 734, A (Professor): Yeah they do {vocalsound} analysis - by - synthesis . They try {disfmarker} they {disfmarker} they try every {disfmarker} every possible excitation they have in their code book and find the one that matches best .
Turn 735, F (PhD): Yeah . Mmm . Alright . Yeah . So it would not help .
Turn 736, A (Professor): Yeah .
Turn 737, E (Grad): Hmm .
Turn 738, A (Professor): Uh . O K .
Turn 739, B (PhD): Can I just mention one other interesting thing ?
Turn 740, A (Professor): Yeah .
Turn 741, B (PhD): Um . One of the ideas that we {pause} had come up with last week for things to try to {vocalsound} improve the system {disfmarker} Um . Actually I {disfmarker} I s we didn't {disfmarker} I guess I wrote this in after the meeting b but {vocalsound} the thought I had was um looking at the language model that 's used in the HTK recognizer , which is basically just a big {vocalsound} loop ,
Turn 742, E (Grad): Mm - hmm .
Turn 743, B (PhD): right ? So you {disfmarker} it goes " digit "
Turn 744, D (PhD): Mm - hmm .
Turn 745, B (PhD): and then that can be {disfmarker} either go to silence or go to another digit , which {disfmarker} That model would allow for the production of {vocalsound} infinitely long sequences of digits , right ?
Turn 746, A (Professor): Right .
Turn 747, B (PhD): So . I thought " well I 'm gonna just look at the {disfmarker} what actual digit strings do occur in the training data . "
Turn 748, A (Professor): Right .
Turn 749, B (PhD): And the interesting thing was it turns out that there are no sequences of two - long or three - long digit strings {pause} in any of the Aurora training data . So it 's either one , four , five , six , uh up to eleven , and then it skips and then there 's some at sixteen .
Turn 750, A (Professor): But what about the testing data ?
Turn 751, B (PhD): Um . I don't know . I didn't look at the test data yet .
Turn 752, A (Professor): Yeah . I mean if there 's some testing data that has {disfmarker} has {disfmarker} {vocalsound} has two or three {disfmarker}
Turn 753, B (PhD): So . Yeah . But I just thought that was a little odd , that there were no two or three long {disfmarker} Sorry . So I {disfmarker} I {disfmarker} just for the heck of it , I made a little grammar which um , you know , had it 's separate path {pause} for each length digit string you could get . So there was a one - long path and there was a four - long and a five - long
Turn 754, A (Professor): Mm - hmm .
Turn 755, B (PhD): and I tried that and it got way worse . There were lots of deletions .
Turn 756, A (Professor): Mm - hmm .
Turn 757, B (PhD): So it was {disfmarker} {vocalsound} you know , I {disfmarker} I didn't have any weights of these paths or {disfmarker} I didn't have anything like that .
Turn 758, A (Professor): Mm - hmm .
Turn 759, B (PhD): And I played with tweaking the {vocalsound} word transition penalties a bunch , but I couldn't go anywhere .
Turn 760, A (Professor): Hmm .
Turn 761, B (PhD): But um . I thought " well if I only allow {disfmarker} " Yeah , I guess I should have looked at {disfmarker} to see how often there was a mistake where a two - long or a three - long path was actually put out as a hypothesis . Um . But .
Turn 762, A (Professor): Hmm .
Turn 763, B (PhD): So to do that right you 'd probably want to have {disfmarker} {vocalsound} allow for them all but then have weightings and things . So . I just thought that was a interesting {vocalsound} thing about the data .
Turn 764, A (Professor): OK . So we 're gonna read some more digit strings I guess ?
Turn 765, B (PhD): Yeah . You want to go ahead , Morgan ?
Turn 766, A (Professor): Sure .
