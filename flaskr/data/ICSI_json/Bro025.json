{"metadata": {"meeting_name": "Bro025"}, "turns": [{"turn": 1, "name": "PhD", "id": "A", "contribution": " Alright . We 're on ."}, {"turn": 2, "name": "Professor", "id": "B", "contribution": " Test , um . Test , test , test . Guess that 's me . Yeah . OK ."}, {"turn": 3, "name": "Grad", "id": "D", "contribution": " Ooh , Thursday ."}, {"turn": 4, "name": "Professor", "id": "B", "contribution": " So . There 's two sheets of paper in front of us ."}, {"turn": 5, "name": "PhD", "id": "A", "contribution": " What are these ?"}, {"turn": 6, "name": "PhD", "id": "E", "contribution": " Yeah . So ."}, {"turn": 7, "name": "Professor", "id": "B", "contribution": " This is the arm wrestling ?"}, {"turn": 8, "name": "PhD", "id": "C", "contribution": " Uh . Yeah , we formed a coalition actually ."}, {"turn": 9, "name": "PhD", "id": "E", "contribution": " Yeah . Almost ."}, {"turn": 10, "name": "PhD", "id": "C", "contribution": " We already made it into one ."}, {"turn": 11, "name": "Professor", "id": "B", "contribution": " Oh , good ."}, {"turn": 12, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 13, "name": "Professor", "id": "B", "contribution": " Excellent ."}, {"turn": 14, "name": "PhD", "id": "E", "contribution": " Yeah ."}, {"turn": 15, "name": "Professor", "id": "B", "contribution": " That 's the best thing ."}, {"turn": 16, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 17, "name": "Professor", "id": "B", "contribution": " So , tell me about it ."}, {"turn": 18, "name": "PhD", "id": "E", "contribution": " So it 's {disfmarker} well , it 's {pause} spectral subtraction or Wiener filtering , um , depending on if we put {disfmarker} if we square the transfer function or not ."}, {"turn": 19, "name": "Professor", "id": "B", "contribution": " Right ."}, {"turn": 20, "name": "PhD", "id": "E", "contribution": " And then with over - estimation of the noise , depending on the , uh {disfmarker} the SNR , with smoothing along time , um , smoothing along frequency ."}, {"turn": 21, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 22, "name": "PhD", "id": "E", "contribution": " It 's very simple , smoothing things ."}, {"turn": 23, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 24, "name": "PhD", "id": "E", "contribution": " And , um , {vocalsound} the best result is {vocalsound} when we apply this procedure on FFT bins , uh , with a Wiener filter ."}, {"turn": 25, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 26, "name": "PhD", "id": "E", "contribution": " And there is no noise addition after {disfmarker} after that ."}, {"turn": 27, "name": "Professor", "id": "B", "contribution": " OK ."}, {"turn": 28, "name": "PhD", "id": "E", "contribution": " So it 's good because {vocalsound} {vocalsound} it 's difficult when we have to add noise to {disfmarker} to {disfmarker} to find the right level ."}, {"turn": 29, "name": "Professor", "id": "B", "contribution": " OK ."}, {"turn": 30, "name": "PhD", "id": "A", "contribution": " Are you looking at one in {disfmarker} in particular of these two ?"}, {"turn": 31, "name": "PhD", "id": "E", "contribution": " Yeah . So the sh it 's the sheet that gives fifty - f three point sixty - six ."}, {"turn": 32, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 33, "name": "PhD", "id": "E", "contribution": " Um , {vocalsound} the second sheet is abo uh , about the same . It 's the same , um , idea but it 's working on mel bands , {vocalsound} and it 's a spectral subtraction instead of Wiener filter , and there is also a noise addition after , uh , cleaning up the mel bins . Mmm . Well , the results are similar ."}, {"turn": 34, "name": "Professor", "id": "B", "contribution": " Yeah . I mean , {vocalsound} it 's {disfmarker} {comment} it 's actually , uh , very similar ."}, {"turn": 35, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 36, "name": "Professor", "id": "B", "contribution": " I mean , {vocalsound} if you look at databases , uh , the , uh , one that has the smallest {disfmarker} smaller overall number is actually better on the Finnish and Spanish , uh , but it is , uh , worse on the , uh , Aurora {disfmarker}"}, {"turn": 37, "name": "PhD", "id": "E", "contribution": " It 's worse on {disfmarker}"}, {"turn": 38, "name": "Professor", "id": "B", "contribution": " I mean on the , uh , TI - TI - digits ,"}, {"turn": 39, "name": "PhD", "id": "E", "contribution": " on the multi - condition in TI - digits . Yeah ."}, {"turn": 40, "name": "Professor", "id": "B", "contribution": " uh , uh . Um ."}, {"turn": 41, "name": "PhD", "id": "E", "contribution": " Mmm ."}, {"turn": 42, "name": "Professor", "id": "B", "contribution": " So , it probably doesn't matter that much either way . But , um , when you say u uh , unified do you mean , uh , it 's one piece of software now , or {disfmarker} ?"}, {"turn": 43, "name": "PhD", "id": "E", "contribution": " So now we are , yeah , setting up the software ."}, {"turn": 44, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 45, "name": "PhD", "id": "E", "contribution": " Um , it should be ready , uh , very soon . Um , and we"}, {"turn": 46, "name": "PhD", "id": "A", "contribution": " So what 's {disfmarker} what 's happened ? I think I 've missed something ."}, {"turn": 47, "name": "Professor", "id": "B", "contribution": " OK . So a week ago {disfmarker} maybe you weren't around when {disfmarker} when {disfmarker} when Hynek and Guenther and I {disfmarker} ?"}, {"turn": 48, "name": "PhD", "id": "C", "contribution": " Hynek was here ."}, {"turn": 49, "name": "PhD", "id": "A", "contribution": " Yeah . I didn't ."}, {"turn": 50, "name": "Professor", "id": "B", "contribution": " Oh , OK . So {disfmarker} Yeah , let 's summarize . Um {disfmarker} And then if I summarize somebody can tell me if I 'm wrong , which will also be possibly helpful . What did I just press here ? I hope this is still working ."}, {"turn": 51, "name": "PhD", "id": "E", "contribution": " p - p - p"}, {"turn": 52, "name": "Professor", "id": "B", "contribution": " We , uh {disfmarker} we looked at , {nonvocalsound} uh {disfmarker} anyway we {disfmarker} {vocalsound} after coming back from QualComm we had , you know , very strong feedback and , uh , I think it was {vocalsound} Hynek and Guenter 's and my opinion also that , um , you know , we sort of spread out to look at a number of different ways of doing noise suppression . But given the limited time , uh , it was sort of time to {pause} choose one ."}, {"turn": 53, "name": "PhD", "id": "A", "contribution": " Mm - hmm . Mmm ."}, {"turn": 54, "name": "Professor", "id": "B", "contribution": " Uh , and so , uh , th the vector Taylor series hadn't really worked out that much . Uh , the subspace stuff , uh , had not been worked with so much . Um , so it sort of came down to spectral subtraction versus Wiener filtering ."}, {"turn": 55, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 56, "name": "Professor", "id": "B", "contribution": " Uh , we had a long discussion about how they were the same and how they were d uh , completely different ."}, {"turn": 57, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 58, "name": "Professor", "id": "B", "contribution": " And , uh , I mean , fundamentally they 're the same sort of thing but the math is a little different so that there 's a {disfmarker} a {disfmarker} {vocalsound} there 's an exponent difference in the index {disfmarker} you know , what 's the ideal filtering , and depending on how you construct the problem ."}, {"turn": 59, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 60, "name": "Professor", "id": "B", "contribution": " And , uh , I guess it 's sort {disfmarker} you know , after {disfmarker} after that meeting it sort of made more sense to me because {vocalsound} um , if you 're dealing with power spectra then how are you gonna choose your error ? And typically you 'll do {disfmarker} choose something like a variance . And so that means it 'll be something like the square of the power spectra . Whereas when you 're {disfmarker} when you 're doing the {disfmarker} the , uh , um , {vocalsound} looking at it the other way , you 're gonna be dealing with signals"}, {"turn": 61, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 62, "name": "Professor", "id": "B", "contribution": " and you 're gonna end up looking at power {disfmarker} uh , noise power that you 're trying to reduce . And so , eh {disfmarker} so there should be a difference {vocalsound} of {disfmarker} you know , conceptually of {disfmarker} of , uh , a factor of two in the exponent ."}, {"turn": 63, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 64, "name": "Professor", "id": "B", "contribution": " But there 're so many different little factors that you adjust in terms of {disfmarker} of , uh , {vocalsound} uh , over - subtraction and {disfmarker} and {disfmarker} and {disfmarker} and {disfmarker} and so forth , um , that {vocalsound} arguably , you 're c and {disfmarker} and {disfmarker} and the choice of do you {disfmarker} do you operate on the mel bands or do you operate on the FFT beforehand . There 're so many other choices to make that are {disfmarker} are almost {disfmarker} well , if not independent , certainly in addition to {pause} the choice of whether you , uh , do spectral subtraction or Wiener filtering , that , um , {vocalsound} @ @ again we sort of felt the gang should just sort of figure out which it is they wanna do and then let 's pick it , go forward with it . So that 's {disfmarker} that was {disfmarker} that was last week . And {disfmarker} {vocalsound} and , uh , we said , uh , take a week , go arm wrestle , you know ,"}, {"turn": 65, "name": "Grad", "id": "D", "contribution": " Oh ."}, {"turn": 66, "name": "Professor", "id": "B", "contribution": " figure it out . I mean , and th the joke there was that each of them had specialized in one of them ."}, {"turn": 67, "name": "PhD", "id": "A", "contribution": " Oh , OK ."}, {"turn": 68, "name": "Professor", "id": "B", "contribution": " And {disfmarker} and so they {disfmarker} so instead they went to Yosemite and bonded , and {disfmarker} and they came out with a single {disfmarker} single piece of software . So it 's {vocalsound} another {disfmarker} another victory for international collaboration . So ."}, {"turn": 69, "name": "PhD", "id": "A", "contribution": " So {disfmarker} so you guys have combined {disfmarker} or you 're going to be combining the software ?"}, {"turn": 70, "name": "Professor", "id": "B", "contribution": " Uh ."}, {"turn": 71, "name": "PhD", "id": "C", "contribution": " Well , the piece of software has , like , plenty of options ,"}, {"turn": 72, "name": "PhD", "id": "E", "contribution": " Oh boy ."}, {"turn": 73, "name": "PhD", "id": "C", "contribution": " like you can parse command - line arguments . So depending on that , it {disfmarker} it becomes either spectral subtraction or Wiener filtering ."}, {"turn": 74, "name": "PhD", "id": "A", "contribution": " Oh , OK ."}, {"turn": 75, "name": "PhD", "id": "C", "contribution": " So , ye"}, {"turn": 76, "name": "PhD", "id": "A", "contribution": " They 're close enough ."}, {"turn": 77, "name": "Professor", "id": "B", "contribution": " Well , that 's fine , but the thing is {disfmarker} the important thing is that there is a piece of software that you {disfmarker} that we all will be using now ."}, {"turn": 78, "name": "PhD", "id": "C", "contribution": " Yeah . Yeah ."}, {"turn": 79, "name": "Professor", "id": "B", "contribution": " Yes ."}, {"turn": 80, "name": "PhD", "id": "C", "contribution": " There 's just one piece of software ."}, {"turn": 81, "name": "PhD", "id": "E", "contribution": " Yeah ."}, {"turn": 82, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 83, "name": "PhD", "id": "E", "contribution": " I need to allow it to do everything and even more {disfmarker} more than this ."}, {"turn": 84, "name": "PhD", "id": "C", "contribution": " Right ."}, {"turn": 85, "name": "PhD", "id": "E", "contribution": " Well , if we want to , like , optimize different parameters of {disfmarker}"}, {"turn": 86, "name": "PhD", "id": "C", "contribution": " Parameters . Yeah ."}, {"turn": 87, "name": "Professor", "id": "B", "contribution": " Sure ."}, {"turn": 88, "name": "PhD", "id": "E", "contribution": " Yeah , we can do it later . But , still {disfmarker} so , there will be a piece of software with , {vocalsound} {vocalsound} uh , will give this system , the fifty - three point sixty - six , by default and {disfmarker}"}, {"turn": 89, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 90, "name": "PhD", "id": "A", "contribution": " How {disfmarker} how is {disfmarker} how good is that ?"}, {"turn": 91, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 92, "name": "PhD", "id": "A", "contribution": " I {disfmarker} I {disfmarker} I don't have a sense of {disfmarker}"}, {"turn": 93, "name": "PhD", "id": "E", "contribution": " It 's just one percent off of the {pause} best proposal ."}, {"turn": 94, "name": "PhD", "id": "C", "contribution": " Best system ."}, {"turn": 95, "name": "PhD", "id": "E", "contribution": " It 's between {disfmarker} i we are second actually if we take this system ."}, {"turn": 96, "name": "PhD", "id": "A", "contribution": " OK ."}, {"turn": 97, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 98, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 99, "name": "PhD", "id": "E", "contribution": " Right ?"}, {"turn": 100, "name": "PhD", "id": "A", "contribution": " Compared to the last evaluation numbers ? Yeah ."}, {"turn": 101, "name": "Professor", "id": "B", "contribution": " But , uh {disfmarker} w which we sort of were before"}, {"turn": 102, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 103, "name": "PhD", "id": "E", "contribution": " Mm - hmm . Yeah ."}, {"turn": 104, "name": "Professor", "id": "B", "contribution": " but we were considerably far behind . And the thing is , this doesn't have neural net in yet for instance . You know ?"}, {"turn": 105, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 106, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 107, "name": "Professor", "id": "B", "contribution": " So it {disfmarker} so , um , it 's {disfmarker} it it 's not using our full bal bag of tricks , if you will ."}, {"turn": 108, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 109, "name": "Professor", "id": "B", "contribution": " And , uh , and it {disfmarker} it is , uh , very close in performance to the best thing that was there before . Uh , but , you know , looking at it another way , maybe more importantly , uh , {vocalsound} we didn't have any explicit noise , uh , handling {disfmarker} stationary {disfmarker} dealing with {disfmarker} e e we didn't explicitly have anything to deal with stationary noise ."}, {"turn": 110, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 111, "name": "Professor", "id": "B", "contribution": " And now we do ."}, {"turn": 112, "name": "PhD", "id": "A", "contribution": " So will the {pause} neural net operate on the output from either the Wiener filtering or the spectral subtraction ? Or will it operate on the original ?"}, {"turn": 113, "name": "Professor", "id": "B", "contribution": " Well , so {disfmarker} so {disfmarker} so argu arguably , I mean , what we should do {disfmarker} I mean , I gather you have {disfmarker} it sounds like you have a few more days of {disfmarker} of nailing things down with the software and so on . But {disfmarker} and then {disfmarker} but , um , {vocalsound} arguably what we should do is , even though the software can do many things , we should for now pick a set of things , th these things I would guess , and not change that ."}, {"turn": 114, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 115, "name": "Professor", "id": "B", "contribution": " And then focus on {pause} everything that 's left . And I think , you know , that our goal should be by next week , when Hynek comes back , {vocalsound} uh , to {disfmarker} uh , really just to have a firm path , uh , for the {disfmarker} you know , for the time he 's gone , of {disfmarker} of , uh , what things will be attacked . But I would {disfmarker} I would {disfmarker} I would thought think that what we would wanna do is not futz with this stuff for a while because what 'll happen is we 'll change many other things in the system ,"}, {"turn": 116, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 117, "name": "Professor", "id": "B", "contribution": " and then we 'll probably wanna come back to this and possibly make some other choices . But , um ."}, {"turn": 118, "name": "PhD", "id": "A", "contribution": " But just conceptually , where does the neural net go ? Do {disfmarker} do you wanna h run it on the output of the spectrally subtracted {disfmarker} ?"}, {"turn": 119, "name": "PhD", "id": "E", "contribution": " Mmm ."}, {"turn": 120, "name": "Professor", "id": "B", "contribution": " Well , depending on its size {disfmarker} Well , one question is , is it on the , um , server side or is it on the terminal side ? Uh , if it 's on the server side , it {disfmarker} you probably don't have to worry too much about size ."}, {"turn": 121, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 122, "name": "Professor", "id": "B", "contribution": " So that 's kind of an argument for that . We do still , however , have to consider its latency . So the issue is {disfmarker} is , um , {vocalsound} for instance , could we have a neural net that only looked at the past ?"}, {"turn": 123, "name": "PhD", "id": "A", "contribution": " Right ."}, {"turn": 124, "name": "Professor", "id": "B", "contribution": " Um , what we 've done in uh {disfmarker} in the past is to use the neural net , uh , to transform , {vocalsound} um , all of the features that we use . So this is done early on . This is essentially , {vocalsound} um , um {disfmarker} I guess it 's {disfmarker} it 's more or less like a spee a speech enhancement technique here {disfmarker}"}, {"turn": 125, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 126, "name": "Professor", "id": "B", "contribution": " right ? {disfmarker} where we 're just kind of creating {vocalsound} new {disfmarker} if not new speech at least new {disfmarker} new FFT 's that {disfmarker} that have {disfmarker} you know , which could be turned into speech {disfmarker} uh , that {disfmarker} that have some of the noise removed ."}, {"turn": 127, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 128, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 129, "name": "Professor", "id": "B", "contribution": " Um , after that we still do a mess of other things to {disfmarker} to produce a bunch of features ."}, {"turn": 130, "name": "PhD", "id": "A", "contribution": " Right ."}, {"turn": 131, "name": "Professor", "id": "B", "contribution": " And then those features are not now currently transformed {vocalsound} by the neural net . And then the {disfmarker} the way that we had it in our proposal - two before , we had the neural net transformed features and we had {vocalsound} the untransformed features , which I guess you {disfmarker} you actually did linearly transform with the KLT ,"}, {"turn": 132, "name": "PhD", "id": "E", "contribution": " Yeah . Yeah . Right ."}, {"turn": 133, "name": "Professor", "id": "B", "contribution": " but {disfmarker} but {disfmarker} but {disfmarker} uh , to orthogonalize them {disfmarker} but {disfmarker} {vocalsound} but they were not , uh , processed through a neural net . And Stephane 's idea with that , as I recall , was that {vocalsound} you 'd have one part of the feature vector that was very discriminant and another part that wasn't ,"}, {"turn": 134, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 135, "name": "Professor", "id": "B", "contribution": " uh , which would smooth things a bit for those occasions when , uh , the testing set was quite different than what you 'd trained your discriminant features for . So , um , all of that is {disfmarker} is , uh {disfmarker} still seems like a good idea . The thing is now we know some other constraints . We can't have unlimited amounts of latency . Uh , y you know , that 's still being debated by the {disfmarker} by people in Europe but , {vocalsound} uh , no matter how they end up there , it 's not going to be unlimited amounts ,"}, {"turn": 136, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 137, "name": "Professor", "id": "B", "contribution": " so we have to be a little conscious of that . Um . So there 's the neural net issue . There 's the VAD issue . And , uh , there 's the second stream {pause} thing . And I think those that we {disfmarker} last time we agreed that those are the three things that have to get , uh , focused on ."}, {"turn": 138, "name": "PhD", "id": "A", "contribution": " What was the issue with the VAD ?"}, {"turn": 139, "name": "Professor", "id": "B", "contribution": " Well , better {comment} ones are good ."}, {"turn": 140, "name": "PhD", "id": "A", "contribution": " And so the w the default , uh , boundaries that they provide are {disfmarker} they 're OK , but they 're not all that great ?"}, {"turn": 141, "name": "Professor", "id": "B", "contribution": " I guess they still allow two hundred milliseconds on either side or some ? Is that what the deal is ?"}, {"turn": 142, "name": "PhD", "id": "E", "contribution": " Mm - hmm . Uh , so th um , they keep two hundred milliseconds at the beginning and end of speech . And they keep all the {disfmarker}"}, {"turn": 143, "name": "PhD", "id": "A", "contribution": " Outside the beginnings and end ."}, {"turn": 144, "name": "PhD", "id": "E", "contribution": " Yeah ."}, {"turn": 145, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 146, "name": "PhD", "id": "E", "contribution": " And all the speech pauses , which is {disfmarker} Sometimes on the SpeechDat - Car you have pauses that are more than one or two seconds ."}, {"turn": 147, "name": "PhD", "id": "A", "contribution": " Wow ."}, {"turn": 148, "name": "PhD", "id": "E", "contribution": " More than one second for sure . Um ."}, {"turn": 149, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 150, "name": "PhD", "id": "E", "contribution": " Yeah . And , yeah , it seems to us that this way of just dropping the beginning and end is not {disfmarker} We cou we can do better , I think ,"}, {"turn": 151, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 152, "name": "PhD", "id": "E", "contribution": " because , um , {vocalsound} with this way of dropping the frames they improve {pause} over the baseline by fourteen percent and {vocalsound} Sunil already showed that with our current VAD we can improve by more than twenty percent ."}, {"turn": 153, "name": "PhD", "id": "A", "contribution": " On top of the VAD that they provide ?"}, {"turn": 154, "name": "PhD", "id": "C", "contribution": " No ."}, {"turn": 155, "name": "PhD", "id": "E", "contribution": " Just using either their VAD or our current VAD ."}, {"turn": 156, "name": "PhD", "id": "C", "contribution": " Our way ."}, {"turn": 157, "name": "PhD", "id": "A", "contribution": " Oh , OK ."}, {"turn": 158, "name": "PhD", "id": "E", "contribution": " So , our current VAD is {disfmarker} is more than twenty percent , while their is fourteen ."}, {"turn": 159, "name": "PhD", "id": "A", "contribution": " Theirs is fourteen ? I see ."}, {"turn": 160, "name": "PhD", "id": "E", "contribution": " Yeah ."}, {"turn": 161, "name": "PhD", "id": "A", "contribution": " Huh ."}, {"turn": 162, "name": "PhD", "id": "E", "contribution": " So . Yeah . And {pause} another thing that we did also is that we have all this training data for {disfmarker} let 's say , for SpeechDat - Car . We have channel zero which is clean , channel one which is far - field microphone . And if we just take only the , um , VAD probabilities computed on the clean signal and apply them on the far - field , uh , test utterances , {vocalsound} then results are much better ."}, {"turn": 163, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 164, "name": "PhD", "id": "E", "contribution": " In some cases it divides the error rate by two ."}, {"turn": 165, "name": "PhD", "id": "A", "contribution": " Wow ."}, {"turn": 166, "name": "PhD", "id": "E", "contribution": " So it means that there are stim {comment} still {disfmarker}"}, {"turn": 167, "name": "PhD", "id": "A", "contribution": " How {disfmarker} how much latency does the , uh {disfmarker} does our VAD add ?"}, {"turn": 168, "name": "PhD", "id": "E", "contribution": " If {disfmarker} if we can have a good VAD , well , it would be great ."}, {"turn": 169, "name": "PhD", "id": "A", "contribution": " Is it significant ,"}, {"turn": 170, "name": "PhD", "id": "E", "contribution": " Uh , right now it 's , um , a neural net with nine frames ."}, {"turn": 171, "name": "PhD", "id": "A", "contribution": " or {disfmarker} ?"}, {"turn": 172, "name": "PhD", "id": "E", "contribution": " So it 's forty milliseconds plus , um , the rank ordering , which , uh , should be"}, {"turn": 173, "name": "PhD", "id": "C", "contribution": " Like another ten frames ."}, {"turn": 174, "name": "PhD", "id": "E", "contribution": " ten {disfmarker} Yeah ."}, {"turn": 175, "name": "Grad", "id": "D", "contribution": " Rank . Oh ."}, {"turn": 176, "name": "PhD", "id": "E", "contribution": " So , right now it 's one hundred and forty {pause} milliseconds ."}, {"turn": 177, "name": "Professor", "id": "B", "contribution": " With the rank ordering {disfmarker} ? I 'm sorry ."}, {"turn": 178, "name": "PhD", "id": "C", "contribution": " The {disfmarker} the {disfmarker} the smoothing {disfmarker} the m the {disfmarker} the filtering of the probabilities ."}, {"turn": 179, "name": "PhD", "id": "E", "contribution": " The {disfmarker} The , um {disfmarker}"}, {"turn": 180, "name": "PhD", "id": "C", "contribution": " on the R ."}, {"turn": 181, "name": "PhD", "id": "E", "contribution": " Yeah . It 's not a median filtering . It 's just {disfmarker} We don't take the median value . We take something {disfmarker} Um , so we have eleven , um , frames ."}, {"turn": 182, "name": "Professor", "id": "B", "contribution": " Oh , this is for the VAD ."}, {"turn": 183, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 184, "name": "PhD", "id": "E", "contribution": " And {disfmarker} for the VAD , yeah {disfmarker}"}, {"turn": 185, "name": "Professor", "id": "B", "contribution": " Oh , OK ."}, {"turn": 186, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 187, "name": "PhD", "id": "E", "contribution": " and we take th the third ."}, {"turn": 188, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 189, "name": "Grad", "id": "D", "contribution": " Dar"}, {"turn": 190, "name": "PhD", "id": "E", "contribution": " Um ."}, {"turn": 191, "name": "Professor", "id": "B", "contribution": " Yeah . Um . So {disfmarker} {comment} Yeah , I was just noticing on this that it makes reference to delay ."}, {"turn": 192, "name": "PhD", "id": "E", "contribution": " Mmm ."}, {"turn": 193, "name": "Professor", "id": "B", "contribution": " So what 's the {disfmarker} ? If you ignore {disfmarker} Um , the VAD is sort of in {disfmarker} in parallel , isn't i isn't it , with {disfmarker} with the {disfmarker} ? I mean , it isn't additive with the {disfmarker} the , uh , LDA and the Wiener filtering , and so forth ."}, {"turn": 194, "name": "PhD", "id": "C", "contribution": " The LDA ?"}, {"turn": 195, "name": "Professor", "id": "B", "contribution": " Right ?"}, {"turn": 196, "name": "PhD", "id": "C", "contribution": " Yeah . So {disfmarker} so what happened right now , we removed the delay of the LDA ."}, {"turn": 197, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 198, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 199, "name": "PhD", "id": "C", "contribution": " So we {disfmarker} I mean , if {disfmarker} so if we {disfmarker} if {disfmarker} so which is like if we reduce the delay of VA So , the f the final delay 's now ba is f determined by the delay of the VAD , because the LDA doesn't have any delay . So if we re if we reduce the delay of the VAD , I mean , it 's like effectively reducing the delay ."}, {"turn": 200, "name": "PhD", "id": "A", "contribution": " How {disfmarker} how much , uh , delay was there on the LDA ?"}, {"turn": 201, "name": "PhD", "id": "C", "contribution": " So the LDA and the VAD both had a hundred millisecond delay . So and they were in parallel , so which means you pick either one of them {disfmarker}"}, {"turn": 202, "name": "PhD", "id": "A", "contribution": " Mmm ."}, {"turn": 203, "name": "PhD", "id": "C", "contribution": " the {disfmarker} the biggest , whatever ."}, {"turn": 204, "name": "PhD", "id": "A", "contribution": " I see ."}, {"turn": 205, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 206, "name": "PhD", "id": "C", "contribution": " So , right now the LDA delays are more ."}, {"turn": 207, "name": "Professor", "id": "B", "contribution": " And there {disfmarker}"}, {"turn": 208, "name": "PhD", "id": "A", "contribution": " Oh , OK ."}, {"turn": 209, "name": "Professor", "id": "B", "contribution": " And there didn't seem to be any , uh , penalty for that ? There didn't seem to be any penalty for making it causal ?"}, {"turn": 210, "name": "PhD", "id": "C", "contribution": " Pardon ? Oh , no . It actually made it , like , point one percent better or something , actually ."}, {"turn": 211, "name": "Professor", "id": "B", "contribution": " OK . Well , may as well , then ."}, {"turn": 212, "name": "PhD", "id": "C", "contribution": " Or something like that"}, {"turn": 213, "name": "Professor", "id": "B", "contribution": " And he says Wiener filter is {disfmarker} is forty milliseconds delay ."}, {"turn": 214, "name": "PhD", "id": "C", "contribution": " and {disfmarker}"}, {"turn": 215, "name": "Professor", "id": "B", "contribution": " So is it {disfmarker} ?"}, {"turn": 216, "name": "PhD", "id": "C", "contribution": " Yeah . So that 's the one which Stephane was discussing , like {disfmarker}"}, {"turn": 217, "name": "PhD", "id": "E", "contribution": " Mmm ."}, {"turn": 218, "name": "Professor", "id": "B", "contribution": " The smoothing ?"}, {"turn": 219, "name": "PhD", "id": "C", "contribution": " Yeah . The {disfmarker} you smooth it and then delay the decision by {disfmarker} So ."}, {"turn": 220, "name": "Professor", "id": "B", "contribution": " Right . OK . So that 's {disfmarker} that 's really not {disfmarker} not bad . So we may in fact {disfmarker} we 'll see what they decide . We may in fact have , {vocalsound} um , the {disfmarker} the , uh , latency time available for {disfmarker} to have a neural net . I mean , sounds like we probably will . So ."}, {"turn": 221, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 222, "name": "Professor", "id": "B", "contribution": " That 'd be good . Cuz I {disfmarker} cuz it certainly always helped us before . So ."}, {"turn": 223, "name": "PhD", "id": "A", "contribution": " What amount of latency are you thinking about when you say that ?"}, {"turn": 224, "name": "Professor", "id": "B", "contribution": " Uh . Well , they 're {disfmarker} you know , they 're disputing it ."}, {"turn": 225, "name": "PhD", "id": "A", "contribution": " Mmm ."}, {"turn": 226, "name": "Professor", "id": "B", "contribution": " You know , they 're saying , uh {disfmarker} one group is saying a hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds . Two hundred and fifty is what it was before actually . So ,"}, {"turn": 227, "name": "PhD", "id": "A", "contribution": " Oh ."}, {"turn": 228, "name": "Professor", "id": "B", "contribution": " uh , some people are lobbying {disfmarker} lobbying {comment} to make it shorter ."}, {"turn": 229, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 230, "name": "Professor", "id": "B", "contribution": " Um . And , um ."}, {"turn": 231, "name": "PhD", "id": "A", "contribution": " Were you thinking of the two - fifty or the one - thirty when you said we should {pause} have enough for the neural net ?"}, {"turn": 232, "name": "Professor", "id": "B", "contribution": " Well , it just {disfmarker} it {disfmarker} when we find that out it might change exactly how we do it , is all ."}, {"turn": 233, "name": "PhD", "id": "A", "contribution": " Oh , OK ."}, {"turn": 234, "name": "Professor", "id": "B", "contribution": " I mean , how much effort do we put into making it causal ? I mean , {vocalsound} I think the neural net will probably do better if it looks at a little bit of the future ."}, {"turn": 235, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 236, "name": "Professor", "id": "B", "contribution": " But , um , it will probably work to some extent to look only at the past . And we ha you know , limited machine and human time , and {vocalsound} effort . And , you know , how {disfmarker} how much time should we put into {disfmarker} into that ? So it 'd be helpful if we find out from the {disfmarker} the standards folks whether , you know , they 're gonna restrict that or not ."}, {"turn": 237, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 238, "name": "Professor", "id": "B", "contribution": " Um . But I think , you know , at this point our major concern is making the performance better and {disfmarker} and , um , {vocalsound} if , uh , something has to take a little longer in latency in order to do it that 's {pause} you know , a secondary issue ."}, {"turn": 239, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 240, "name": "Professor", "id": "B", "contribution": " But if we get told otherwise then , you know , we may have to c clamp down a bit more ."}, {"turn": 241, "name": "Grad", "id": "D", "contribution": " Mmm ."}, {"turn": 242, "name": "PhD", "id": "C", "contribution": " So , the one {disfmarker} one {disfmarker} one difference is that {disfmarker} was there is like we tried computing the delta and then doing the frame - dropping ."}, {"turn": 243, "name": "Grad", "id": "D", "contribution": " S"}, {"turn": 244, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 245, "name": "PhD", "id": "C", "contribution": " The earlier system was do the frame - dropping and then compute the delta on the {disfmarker}"}, {"turn": 246, "name": "Professor", "id": "B", "contribution": " Uh - huh ."}, {"turn": 247, "name": "PhD", "id": "C", "contribution": " So this {disfmarker}"}, {"turn": 248, "name": "PhD", "id": "A", "contribution": " Which could be a kind of a funny delta . Right ?"}, {"turn": 249, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 250, "name": "Professor", "id": "B", "contribution": " Oh , oh . So that 's fixed in this . Yeah , we talked about that ."}, {"turn": 251, "name": "PhD", "id": "C", "contribution": " Yeah . So we have no delta . And then {disfmarker}"}, {"turn": 252, "name": "PhD", "id": "E", "contribution": " Yeah . Uh - huh ."}, {"turn": 253, "name": "Professor", "id": "B", "contribution": " Good ."}, {"turn": 254, "name": "PhD", "id": "C", "contribution": " So the frame - dropping is the last thing that we do . So , yeah , what we do is we compute the silence probability , convert it to that binary flag ,"}, {"turn": 255, "name": "Professor", "id": "B", "contribution": " Uh - huh ."}, {"turn": 256, "name": "PhD", "id": "C", "contribution": " and then in the end you c up upsample it to {vocalsound} match the final features number of {disfmarker}"}, {"turn": 257, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 258, "name": "PhD", "id": "A", "contribution": " Did that help then ?"}, {"turn": 259, "name": "PhD", "id": "C", "contribution": " It seems to be helping on the well - matched condition . So that 's why this improvement I got from the last result . So . And it actually r reduced a little bit on the high mismatch , so in the final weightage it 's b b better because the well - matched is still weighted more than {disfmarker}"}, {"turn": 260, "name": "Professor", "id": "B", "contribution": " So , @ @ I mean , you were doing a lot of changes . Did you happen to notice how much , {vocalsound} uh , the change was due to just this frame - dropping problem ? What about this ?"}, {"turn": 261, "name": "PhD", "id": "C", "contribution": " Uh , y you had something on it . Right ?"}, {"turn": 262, "name": "PhD", "id": "E", "contribution": " Just the frame - dropping problem . Yeah . But it 's {disfmarker} it 's difficult . Sometime we {disfmarker} we change two {disfmarker} two things together and {disfmarker} But it 's around {pause} maybe {disfmarker} it 's less than one percent ."}, {"turn": 263, "name": "Professor", "id": "B", "contribution": " Uh - huh ."}, {"turn": 264, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 265, "name": "PhD", "id": "E", "contribution": " It {disfmarker}"}, {"turn": 266, "name": "Professor", "id": "B", "contribution": " Well . {vocalsound} But like we 're saying , if there 's four or five things like that then {vocalsound} pretty sho soon you 're talking real improvement ."}, {"turn": 267, "name": "PhD", "id": "E", "contribution": " Yeah . Yeah . And it {disfmarker} Yeah . And then we have to be careful with that also {disfmarker} with the neural net"}, {"turn": 268, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 269, "name": "PhD", "id": "E", "contribution": " because in {comment} the proposal the neural net was also , uh , working on {disfmarker} after frame - dropping ."}, {"turn": 270, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 271, "name": "PhD", "id": "E", "contribution": " Um ."}, {"turn": 272, "name": "Professor", "id": "B", "contribution": " Oh , that 's a real good point ."}, {"turn": 273, "name": "PhD", "id": "E", "contribution": " So . Well , we 'll have to be {disfmarker} to do the same kind of correction ."}, {"turn": 274, "name": "Professor", "id": "B", "contribution": " It might be hard if it 's at the server side . Right ?"}, {"turn": 275, "name": "PhD", "id": "E", "contribution": " Mmm . Well , we can do the frame - dropping on the server side or we can just be careful at the terminal side to send a couple of more frames before and after , and {disfmarker} So . I think it 's OK ."}, {"turn": 276, "name": "Professor", "id": "B", "contribution": " OK ."}, {"turn": 277, "name": "PhD", "id": "A", "contribution": " You have , um {disfmarker} So when you {disfmarker} Uh , maybe I don't quite understand how this works , but , um , couldn't you just send all of the frames , but mark the ones that are supposed to be dropped ? Cuz you have a bunch more bandwidth . Right ?"}, {"turn": 278, "name": "Professor", "id": "B", "contribution": " Well , you could . Yeah . I mean , it {disfmarker} it always seemed to us that it would be kind of nice to {disfmarker} in addition to , uh , reducing insertions , actually use up less bandwidth ."}, {"turn": 279, "name": "PhD", "id": "A", "contribution": " Yeah . Yeah ."}, {"turn": 280, "name": "Professor", "id": "B", "contribution": " But nobody seems to have {vocalsound} cared about that in this {pause} evaluation ."}, {"turn": 281, "name": "PhD", "id": "A", "contribution": " And that way the net could use {disfmarker}"}, {"turn": 282, "name": "Professor", "id": "B", "contribution": " So ."}, {"turn": 283, "name": "PhD", "id": "A", "contribution": " If the net 's on the server side then it could use all of the {pause} frames ."}, {"turn": 284, "name": "PhD", "id": "C", "contribution": " Yes , it could be . It 's , like , you mean you just transferred everything and then finally drop the frames after the neural net ."}, {"turn": 285, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 286, "name": "PhD", "id": "C", "contribution": " Right ? Yeah . That 's {disfmarker} that 's one thing which {disfmarker}"}, {"turn": 287, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 288, "name": "PhD", "id": "A", "contribution": " But you could even mark them , before they get to the server ."}, {"turn": 289, "name": "PhD", "id": "C", "contribution": " Yeah . Right now we are {disfmarker} Uh , ri Right now what {disfmarker} wha what we did is , like , we just mark {disfmarker} we just have this additional bit which goes around the features , {vocalsound} saying it 's currently a {disfmarker} it 's a speech or a nonspeech ."}, {"turn": 290, "name": "PhD", "id": "A", "contribution": " Oh , OK ."}, {"turn": 291, "name": "PhD", "id": "C", "contribution": " So there is no frame - dropping till the final features , like , including the deltas are computed ."}, {"turn": 292, "name": "PhD", "id": "A", "contribution": " I see ."}, {"turn": 293, "name": "PhD", "id": "C", "contribution": " And after the deltas are computed , you just pick up the ones that are marked silence and then drop them ."}, {"turn": 294, "name": "PhD", "id": "A", "contribution": " Mm - hmm . I see . I see ."}, {"turn": 295, "name": "Professor", "id": "B", "contribution": " So it would be more or less the same thing with the neural net , I guess , actually ."}, {"turn": 296, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 297, "name": "PhD", "id": "C", "contribution": " So . Yeah , that 's what {disfmarker} that 's what {disfmarker} that 's what , uh , this is doing right now ."}, {"turn": 298, "name": "PhD", "id": "A", "contribution": " I see . OK ."}, {"turn": 299, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 300, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 301, "name": "Professor", "id": "B", "contribution": " Um . OK . So , uh , what 's , uh {disfmarker} ? That 's {disfmarker} that 's a good set of work that {disfmarker} that , uh {disfmarker}"}, {"turn": 302, "name": "PhD", "id": "C", "contribution": " Just one more thing . Like , should we do something f more for the noise estimation , because we still {disfmarker} ?"}, {"turn": 303, "name": "Professor", "id": "B", "contribution": " Yeah . I was wondering about that . That was {disfmarker} I {disfmarker} I had written that down there ."}, {"turn": 304, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 305, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 306, "name": "Professor", "id": "B", "contribution": " Um {disfmarker}"}, {"turn": 307, "name": "PhD", "id": "E", "contribution": " So , we , uh {disfmarker} actually I did the first experiment . This is {pause} with just fifteen frames . Um . We take the first fifteen frame of each utterance to it ,"}, {"turn": 308, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 309, "name": "PhD", "id": "E", "contribution": " and average their power spectra . Um . I tried just plugging the , um , {vocalsound} uh , Guenter noise estimation on this system , and it {disfmarker} uh , it got worse . Um , but of course I didn't play {pause} with it ."}, {"turn": 310, "name": "Professor", "id": "B", "contribution": " Uh - huh ."}, {"turn": 311, "name": "PhD", "id": "E", "contribution": " But {disfmarker} Mm - hmm . Uh , I didn't {pause} do much more {pause} for noise estimation . I just tried this ,"}, {"turn": 312, "name": "Professor", "id": "B", "contribution": " Hmm . Yeah . Well , it 's not surprising it 'd be worse the first time ."}, {"turn": 313, "name": "PhD", "id": "E", "contribution": " and {disfmarker}"}, {"turn": 314, "name": "Professor", "id": "B", "contribution": " But , um ,"}, {"turn": 315, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 316, "name": "Professor", "id": "B", "contribution": " it does seem like , you know , i i i i some compromise between always depending on the first fifteen frames and a a always depending on a {disfmarker} a pause is {disfmarker} is {disfmarker} is a good idea . Uh , maybe you have to weight the estimate from the first - teen {disfmarker} fifteen frames more heavily than {disfmarker} than was done in your first attempt . But {disfmarker}"}, {"turn": 317, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 318, "name": "Professor", "id": "B", "contribution": " but {disfmarker}"}, {"turn": 319, "name": "PhD", "id": "E", "contribution": " Yeah , I guess ."}, {"turn": 320, "name": "Professor", "id": "B", "contribution": " Yeah . Um . No , I mean {disfmarker} Um , do you have any way of assessing how well or how poorly the noise estimation is currently doing ?"}, {"turn": 321, "name": "PhD", "id": "E", "contribution": " Mmm . No , we don't ."}, {"turn": 322, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 323, "name": "PhD", "id": "E", "contribution": " We don't have nothing {pause} that {disfmarker}"}, {"turn": 324, "name": "PhD", "id": "C", "contribution": " Is there {disfmarker} was there any experiment with {disfmarker} ? Well , I {disfmarker} I did {disfmarker} The only experiment where I tried was I used the channel zero VAD for the noise estimation and frame - dropping . So I don't have a {disfmarker} {vocalsound} I don't have a split , like which one helped more ."}, {"turn": 325, "name": "PhD", "id": "E", "contribution": " Yeah ."}, {"turn": 326, "name": "PhD", "id": "C", "contribution": " So . It {disfmarker} it was the best result I could get ."}, {"turn": 327, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 328, "name": "PhD", "id": "C", "contribution": " So , that 's the {disfmarker}"}, {"turn": 329, "name": "Professor", "id": "B", "contribution": " So that 's something you could do with , um , this final system . Right ? Just do this {disfmarker} everything that is in this final system except , {vocalsound} uh , use the channel zero ."}, {"turn": 330, "name": "PhD", "id": "C", "contribution": " Mm - hmm . For the noise estimation ."}, {"turn": 331, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 332, "name": "PhD", "id": "C", "contribution": " Yeah . We can try something ."}, {"turn": 333, "name": "Professor", "id": "B", "contribution": " And then see how much better it gets ."}, {"turn": 334, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Sure ."}, {"turn": 335, "name": "Professor", "id": "B", "contribution": " If it 's , you know , essentially not better , then {pause} it 's probably not worth"}, {"turn": 336, "name": "PhD", "id": "E", "contribution": " Yeah ."}, {"turn": 337, "name": "Professor", "id": "B", "contribution": " any more ."}, {"turn": 338, "name": "PhD", "id": "C", "contribution": " Yeah . But the Guenter 's argument is slightly different . It 's , like , ev even {disfmarker} even if I use a channel zero VAD , I 'm just averaging the {disfmarker} {vocalsound} the s power spectrum . But the Guenter 's argument is , like , if it is a non - stationary {pause} segment , then he doesn't update the noise spectrum . So he 's , like {disfmarker} he tries to capture only the stationary part in it . So the averaging is , like , {vocalsound} different from {pause} updating the noise spectrum only during stationary segments . So , th the Guenter was arguing that , I mean , even if you have a very good VAD , averaging it , like , over the whole thing is not a good idea ."}, {"turn": 339, "name": "Professor", "id": "B", "contribution": " I see ."}, {"turn": 340, "name": "PhD", "id": "C", "contribution": " Because you 're averaging the stationary and the non - stationary , and finally you end up getting something which is not really the s because , you {disfmarker} anyway , you can't remove the stationary part fr I mean , non - stationary part from {vocalsound} the signal ."}, {"turn": 341, "name": "Professor", "id": "B", "contribution": " Not using these methods anyway . Yeah ."}, {"turn": 342, "name": "PhD", "id": "C", "contribution": " So {disfmarker} Yeah . So you just {pause} update only doing {disfmarker} or update only the stationary components . Yeah . So , that 's {disfmarker} so that 's still a slight difference from what Guenter is trying"}, {"turn": 343, "name": "Professor", "id": "B", "contribution": " Well , yeah . And {disfmarker} and also there 's just the fact that , um , eh , uh , although we 're trying to do very well on this evaluation , um , we actually would like to have something that worked well in general . And , um , relying on having fifteen frames at the front or something is {disfmarker} is pretty {disfmarker}"}, {"turn": 344, "name": "PhD", "id": "C", "contribution": " Yeah , yeah ."}, {"turn": 345, "name": "Professor", "id": "B", "contribution": " I mean , you might , you might not ."}, {"turn": 346, "name": "PhD", "id": "C", "contribution": " Mmm ."}, {"turn": 347, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 348, "name": "Professor", "id": "B", "contribution": " So , um . Um , it 'd certainly be more robust to different kinds of input if you had at least some updates . Um ."}, {"turn": 349, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 350, "name": "Professor", "id": "B", "contribution": " But , um . Well , I don't know . What {disfmarker} what do you , uh {disfmarker} what do you guys see as {disfmarker} as being what you would be doing in the next week , given wha what 's {pause} happened ?"}, {"turn": 351, "name": "PhD", "id": "C", "contribution": " Cure the VAD ?"}, {"turn": 352, "name": "PhD", "id": "E", "contribution": " Yeah ."}, {"turn": 353, "name": "PhD", "id": "A", "contribution": " What was that ?"}, {"turn": 354, "name": "PhD", "id": "C", "contribution": " VAD ."}, {"turn": 355, "name": "PhD", "id": "A", "contribution": " Oh ."}, {"turn": 356, "name": "PhD", "id": "C", "contribution": " And {disfmarker}"}, {"turn": 357, "name": "Professor", "id": "B", "contribution": " OK ."}, {"turn": 358, "name": "PhD", "id": "E", "contribution": " So , should we keep the same {disfmarker} ? I think we might try to keep the same idea of having a neural network , but {vocalsound} training it on more data and adding better features , I think , but {disfmarker} because the current network is just PLP features . Well , it 's trained on noisy {pause} PLP {disfmarker}"}, {"turn": 359, "name": "PhD", "id": "C", "contribution": " Just the cepstra . Yeah ."}, {"turn": 360, "name": "PhD", "id": "E", "contribution": " PLP features computed on noisy speech . But {vocalsound} {vocalsound} there is no nothing particularly robust in these features ."}, {"turn": 361, "name": "PhD", "id": "A", "contribution": " So , I I uh {disfmarker}"}, {"turn": 362, "name": "PhD", "id": "C", "contribution": " No ."}, {"turn": 363, "name": "PhD", "id": "E", "contribution": " There 's no RASTA , no {disfmarker}"}, {"turn": 364, "name": "PhD", "id": "A", "contribution": " So , uh , I {disfmarker} I don't remember what you said {vocalsound} the answer to my , uh , question earlier . Will you {disfmarker} will you train the net on {disfmarker} after you 've done the spectral subtraction or the Wiener filtering ?"}, {"turn": 365, "name": "Professor", "id": "B", "contribution": " This is a different net ."}, {"turn": 366, "name": "PhD", "id": "A", "contribution": " Oh ."}, {"turn": 367, "name": "PhD", "id": "C", "contribution": " So we have a VAD which is like neur that 's a neural net ."}, {"turn": 368, "name": "PhD", "id": "E", "contribution": " Oh , yeah . Hmm ."}, {"turn": 369, "name": "PhD", "id": "A", "contribution": " Oh , you 're talking about the VAD net . OK ."}, {"turn": 370, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 371, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 372, "name": "PhD", "id": "A", "contribution": " I see ."}, {"turn": 373, "name": "PhD", "id": "C", "contribution": " So that {disfmarker} that VAD was trained on the noisy features ."}, {"turn": 374, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 375, "name": "PhD", "id": "C", "contribution": " So , right now we have , like , uh {disfmarker} we have the cleaned - up features , so we can have a better VAD by training the net on {pause} the cleaned - up speech ."}, {"turn": 376, "name": "PhD", "id": "A", "contribution": " Mm - hmm . I see . I see ."}, {"turn": 377, "name": "PhD", "id": "C", "contribution": " Yeah , but we need a VAD for uh noise estimation also . So it 's , like , where do we want to put the VAD ? Uh , it 's like {disfmarker}"}, {"turn": 378, "name": "PhD", "id": "A", "contribution": " Can you use the same net to do both , or {disfmarker} ?"}, {"turn": 379, "name": "PhD", "id": "C", "contribution": " For {disfmarker}"}, {"turn": 380, "name": "PhD", "id": "A", "contribution": " Can you use the same net that you {disfmarker} that I was talking about to do the VAD ?"}, {"turn": 381, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Uh , it actually comes at v at the very end ."}, {"turn": 382, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 383, "name": "PhD", "id": "C", "contribution": " So the net {disfmarker} the final net {disfmarker} I mean , which is the feature net {disfmarker} so that actually comes after a chain of , like , LDA plus everything . So it 's , like , it takes a long time to get a decision out of it . And {disfmarker} {vocalsound} and you can actually do it for final frame - dropping , but not for the VA - f noise estimation ."}, {"turn": 384, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 385, "name": "Professor", "id": "B", "contribution": " You see , the idea is that the , um , initial decision to {disfmarker} that {disfmarker} that you 're in silence or speech happens pretty quickly ."}, {"turn": 386, "name": "PhD", "id": "A", "contribution": " Oh , OK ."}, {"turn": 387, "name": "PhD", "id": "C", "contribution": " Hmm ."}, {"turn": 388, "name": "PhD", "id": "A", "contribution": " Cuz that 's used by some of these other {disfmarker} ?"}, {"turn": 389, "name": "Professor", "id": "B", "contribution": " And that {disfmarker} Yeah . And that 's sort of fed forward , and {disfmarker} and you say \" well , flush everything , it 's not speech anymore \" ."}, {"turn": 390, "name": "PhD", "id": "A", "contribution": " Oh , OK . I see ."}, {"turn": 391, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 392, "name": "PhD", "id": "A", "contribution": " I thought that was only used for doing frame - dropping later on ."}, {"turn": 393, "name": "Professor", "id": "B", "contribution": " Um , it is used , uh {disfmarker} Yeah , it 's only used f Well , it 's used for frame - dropping . Um , it 's used for end of utterance"}, {"turn": 394, "name": "PhD", "id": "E", "contribution": " Mmm ."}, {"turn": 395, "name": "Professor", "id": "B", "contribution": " because , you know , there 's {disfmarker} {vocalsound} if you have {pause} more than five hundred milliseconds of {disfmarker} of {disfmarker} of nonspeech then you figure it 's end of utterance or something like that ."}, {"turn": 396, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 397, "name": "Professor", "id": "B", "contribution": " So , um ."}, {"turn": 398, "name": "PhD", "id": "E", "contribution": " And it seems important for , like , the on - line normalization . Um . We don't want to update the mean and variance during silen long silence portions . Um . So it {disfmarker} it has to be done before"}, {"turn": 399, "name": "PhD", "id": "A", "contribution": " Oh . I see ."}, {"turn": 400, "name": "PhD", "id": "E", "contribution": " this mean and variance normalization . Um ."}, {"turn": 401, "name": "Professor", "id": "B", "contribution": " Um . Yeah . So probably the VAD and {disfmarker} and maybe testing out the noise {pause} estimation a little bit . I mean , keeping the same method but {disfmarker} but , uh , {vocalsound} seeing if you cou but , um noise estimation could be improved . Those are sort of related issues ."}, {"turn": 402, "name": "PhD", "id": "E", "contribution": " Mm - hmm ."}, {"turn": 403, "name": "Professor", "id": "B", "contribution": " It probably makes sense to move from there . And then , uh , {vocalsound} later on in the month I think we wanna start including the {pause} neural net at the end . Um . OK . Anything else ?"}, {"turn": 404, "name": "PhD", "id": "E", "contribution": " The Half Dome was great ."}, {"turn": 405, "name": "Professor", "id": "B", "contribution": " Good . Yeah . You didn't {disfmarker} didn't fall . That 's good ."}, {"turn": 406, "name": "PhD", "id": "C", "contribution": " Well , yeah ."}, {"turn": 407, "name": "Professor", "id": "B", "contribution": " Our e our effort would have been devastated if you guys had {comment} {vocalsound} run into problems ."}, {"turn": 408, "name": "PhD", "id": "A", "contribution": " So , Hynek is coming back next week , you said ?"}, {"turn": 409, "name": "Professor", "id": "B", "contribution": " Yeah , that 's the plan ."}, {"turn": 410, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 411, "name": "Professor", "id": "B", "contribution": " I guess the week after he 'll be , uh , going back to Europe , and so we wanna {disfmarker}"}, {"turn": 412, "name": "PhD", "id": "A", "contribution": " Is he in Europe right now or is he up at {disfmarker} ?"}, {"turn": 413, "name": "Professor", "id": "B", "contribution": " No , no . He 's {disfmarker} he 's {disfmarker} he 's dropped into the US . Yeah . Yeah ."}, {"turn": 414, "name": "PhD", "id": "A", "contribution": " Oh . Hmm ."}, {"turn": 415, "name": "Professor", "id": "B", "contribution": " So . Uh . {vocalsound} So , uh . Uh , the idea was that , uh , we 'd {disfmarker} we 'd sort out where we were going next with this {disfmarker} with this work before he , uh , left on this next trip . Good . {vocalsound} {vocalsound} Uh , Barry , you just got through your {vocalsound} quals , so I don't know if you {vocalsound} have much to say . But , uh ."}, {"turn": 416, "name": "Grad", "id": "D", "contribution": " Mmm . No , just , uh , looking into some {disfmarker} some of the things that , um , {vocalsound} uh , John Ohala and Hynek , um , gave as feedback , um , as {disfmarker} as a starting point for the project . Um . In {disfmarker} in my proposal , I {disfmarker} I was thinking about starting from a set of , uh , phonological features , {vocalsound} or a subset of them . Um , but that might not be necessarily a good idea according to , um , John ."}, {"turn": 417, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 418, "name": "Grad", "id": "D", "contribution": " He said , uh , um , these {disfmarker} these phonological features are {disfmarker} are sort of figments of imagination also ."}, {"turn": 419, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 420, "name": "Grad", "id": "D", "contribution": " Um . S"}, {"turn": 421, "name": "Professor", "id": "B", "contribution": " In conversational speech in particular . I think you can {disfmarker} you can put them in pretty reliably in synthetic speech ."}, {"turn": 422, "name": "Grad", "id": "D", "contribution": " Ye"}, {"turn": 423, "name": "Professor", "id": "B", "contribution": " But {vocalsound} we don't have too much trouble recognizing synthetic speech since we create it in the first place . So , it 's {disfmarker}"}, {"turn": 424, "name": "Grad", "id": "D", "contribution": " Right . Yeah . So , um , a better way would be something more {disfmarker} more data - driven ,"}, {"turn": 425, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 426, "name": "Grad", "id": "D", "contribution": " just looking at the data and seeing what 's similar and what 's not similar ."}, {"turn": 427, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 428, "name": "Grad", "id": "D", "contribution": " So , I 'm {disfmarker} I 'm , um , taking a look at some of , um , {vocalsound} Sangita 's work on {disfmarker} on TRAPS . She did something where , um {disfmarker} {vocalsound} w where the TRAPS learn She clustered the {disfmarker} the temporal patterns of , um , certain {disfmarker} certain phonemes in {disfmarker} in m averaged over many , many contexts . And , uh , some things tended to cluster ."}, {"turn": 429, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 430, "name": "Grad", "id": "D", "contribution": " Right ? You know , like stop {disfmarker} stop consonants clustered really well ."}, {"turn": 431, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 432, "name": "Grad", "id": "D", "contribution": " Um , silence was by its own self ."}, {"turn": 433, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 434, "name": "Grad", "id": "D", "contribution": " And , uh , um , {vocalsound} v vocalic was clustered ."}, {"turn": 435, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 436, "name": "Grad", "id": "D", "contribution": " And , {vocalsound} um , so , {vocalsound} those are {pause} interesting things to {disfmarker}"}, {"turn": 437, "name": "PhD", "id": "A", "contribution": " So you 're {disfmarker} now you 're sort of looking to try to gather a set of these types of features ?"}, {"turn": 438, "name": "Grad", "id": "D", "contribution": " Right ."}, {"turn": 439, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 440, "name": "Grad", "id": "D", "contribution": " Yeah . Just to see where {disfmarker} where I could start off from ,"}, {"turn": 441, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 442, "name": "Grad", "id": "D", "contribution": " uh , you know ? A {disfmarker} a {disfmarker} a set of small features and continue to iterate and find , uh , a better set ."}, {"turn": 443, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 444, "name": "Grad", "id": "D", "contribution": " Yeah ."}, {"turn": 445, "name": "Professor", "id": "B", "contribution": " OK . Well , short meeting . That 's OK ."}, {"turn": 446, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 447, "name": "Professor", "id": "B", "contribution": " OK . So next week hopefully we 'll {disfmarker} can get Hynek here to {disfmarker} to join us and , uh , uh ."}, {"turn": 448, "name": "PhD", "id": "A", "contribution": " Should we do digits ?"}, {"turn": 449, "name": "Professor", "id": "B", "contribution": " Digits , digits . OK , now ."}, {"turn": 450, "name": "PhD", "id": "A", "contribution": " Go ahead , Morgan . You can start ."}, {"turn": 451, "name": "Professor", "id": "B", "contribution": " Alright . Let me get my glasses on so I can {pause} see them . OK ."}, {"turn": 452, "name": "PhD", "id": "A", "contribution": " OK . And we 're off ."}, {"turn": 453, "name": "Professor", "id": "B", "contribution": " Mm"}]}