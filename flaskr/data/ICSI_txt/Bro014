Turn 0, A (PhD): It 's not very significant .
Turn 1, B (Professor): Uh , channel one . Yes .
Turn 2, D (Grad): Channel three .
Turn 3, B (Professor): OK .
Turn 4, F (PhD): Mm - hmm .
Turn 5, D (Grad): Channel three .
Turn 6, A (PhD): Ta
Turn 7, D (Grad): Channel three . Alright .
Turn 8, B (Professor): OK , did you solve speech recognition last week ?
Turn 9, E (Grad): Almost .
Turn 10, B (Professor): Alright ! Let 's do image processing .
Turn 11, C (PhD): Yes , again .
Turn 12, A (PhD): Great .
Turn 13, C (PhD): We did it again , Morgan .
Turn 14, B (Professor): Alright !
Turn 15, E (Grad): Doo - doop , doo - doo .
Turn 16, A (PhD): What 's wrong with {disfmarker} ?
Turn 17, B (Professor): OK . It 's April fifth . Actually , Hynek should be getting back in town shortly if he isn't already .
Turn 18, C (PhD): Is he gonna come here ?
Turn 19, B (Professor): Uh . Well , we 'll drag him here . I know where he is .
Turn 20, C (PhD): So when you said " in town " , you mean {pause} Oregon .
Turn 21, B (Professor): U u u u uh , I meant , you know , this end of the world , yeah , {vocalsound} is really what I meant ,
Turn 22, C (PhD): Oh .
Turn 23, E (Grad): Doo , doo - doo .
Turn 24, B (Professor): uh , cuz he 's been in Europe .
Turn 25, E (Grad): Doo - doo .
Turn 26, B (Professor): So .
Turn 27, C (PhD): I have something just fairly brief to report on .
Turn 28, B (Professor): Mmm .
Turn 29, C (PhD): Um , I did some {pause} experim uh , uh , just a few more experiments before I had to , {vocalsound} uh , go away for the w well , that week .
Turn 30, B (Professor): Great !
Turn 31, C (PhD): Was it last week or whenever ? Um , so what I was started playing with was the {disfmarker} th again , this is the HTK back - end . And , um , I was curious because the way that they train up the models , {vocalsound} they go through about four sort of rounds of {disfmarker} of training . And in the first round they do {disfmarker} uh , I think it 's three iterations , and for the last three rounds e e they do seven iterations of re - estimation in each of those three . And so , you know , that 's part of what takes so long to train the {disfmarker} the {disfmarker} the back - end for this .
Turn 32, B (Professor): I 'm sorry , I didn't quite get that . There 's {disfmarker} there 's four and there 's seven and {disfmarker} I {disfmarker} I 'm sorry .
Turn 33, C (PhD): Yeah . Uh , maybe I should write it on the board . So , {vocalsound} there 's four rounds of training . Um , I g I g I guess you could say iterations . The first one is three , then seven , seven , and seven . And what these numbers refer to is the number of times that the , uh , HMM re - estimation is run . It 's this program called H E
Turn 34, B (Professor): But in HTK , what 's the difference between , uh , a {disfmarker} an inner loop and an outer loop in these iterations ?
Turn 35, C (PhD): OK . So what happens is , um , at each one of these points , you increase the number of Gaussians in the model .
Turn 36, B (Professor): Yeah . Oh , right ! This was the mix up stuff .
Turn 37, C (PhD): Yeah . The mix up .
Turn 38, B (Professor): That 's right .
Turn 39, C (PhD): Right .
Turn 40, B (Professor): I remember now .
Turn 41, C (PhD): And so , in the final one here , you end up with , uh {disfmarker} for all of the {disfmarker} the digit words , you end up with , uh , three {pause} mixtures per state ,
Turn 42, B (Professor): Yeah .
Turn 43, C (PhD): eh , in the final {pause} thing . So I had done some experiments where I was {disfmarker} I {disfmarker} I want to play with the number of mixtures .
Turn 44, B (Professor): Mm - hmm .
Turn 45, C (PhD): But , um , uh , I wanted to first test to see if we actually need to do {pause} this many iterations early on .
Turn 46, E (Grad): Uh , one , two ,
Turn 47, B (Professor): Mm - hmm .
Turn 48, C (PhD): And so , um , I {disfmarker} I ran a couple of experiments where I {vocalsound} reduced that to l to be three , two , two , {vocalsound} uh , five , I think , and I got almost the exact same results .
Turn 49, B (Professor): Mm - hmm .
Turn 50, C (PhD): And {disfmarker} but it runs much much faster . So , um , I {disfmarker} I think m {pause} it only took something like , uh , three or four hours to do the full training ,
Turn 51, B (Professor): As opposed to {disfmarker} ?
Turn 52, F (PhD): Good .
Turn 53, C (PhD): as opposed to wh what , sixteen hours or something like that ? I mean , it takes {disfmarker} you have to do an overnight basically , the way it is set up now .
Turn 54, F (PhD): Yeah . It depends .
Turn 55, A (PhD): Mm - hmm .
Turn 56, B (Professor): Mm - hmm .
Turn 57, C (PhD): So , uh , even we don't do anything else , doing something like this could allow us to turn experiments around a lot faster .
Turn 58, B (Professor): And then when you have your final thing , do a full one , so it 's {disfmarker}
Turn 59, C (PhD): And when you have your final thing , we go back to this .
Turn 60, F (PhD): Yeah .
Turn 61, C (PhD): So , um , and it 's a real simple change to make . I mean , it 's like one little text file you edit and change those numbers , and you don't do anything else .
Turn 62, F (PhD): Oh , this is a {disfmarker}
Turn 63, A (PhD): Mm - hmm .
Turn 64, C (PhD): And then you just run .
Turn 65, F (PhD): OK .
Turn 66, C (PhD): So it 's a very simple change to make and it doesn't seem to hurt all that much .
Turn 67, A (PhD): So you {disfmarker} you run with three , two , two , five ? That 's a
Turn 68, C (PhD): So I {disfmarker} Uh , I {disfmarker} I have to look to see what the exact numbers were .
Turn 69, A (PhD): Yeah .
Turn 70, C (PhD): I {disfmarker} I thought was , like , three , two , two , five ,
Turn 71, A (PhD): Mm - hmm .
Turn 72, C (PhD): but I I 'll {disfmarker} I 'll double check . It was {vocalsound} over a week ago that I did it ,
Turn 73, A (PhD): OK . Mm - hmm .
Turn 74, C (PhD): so I can't remember exactly .
Turn 75, E (Grad): Oh .
Turn 76, C (PhD): But , uh {disfmarker}
Turn 77, B (Professor): Mm - hmm .
Turn 78, C (PhD): um , but it 's so much faster . I it makes a big difference .
Turn 79, E (Grad): Hmm .
Turn 80, C (PhD): So we could do a lot more experiments and throw a lot more stuff in there .
Turn 81, F (PhD): Yeah .
Turn 82, B (Professor): That 's great .
Turn 83, C (PhD): Um . Oh , the other thing that I did was , um , {vocalsound} I compiled {pause} the HTK stuff for the Linux boxes . So we have this big thing that we got from IBM , which is a five - processor machine . Really fast , but it 's running Linux . So , you can now run your experiments on that machine and you can run five at a time and it runs , {vocalsound} uh , as fast as , you know , uh , five different machines .
Turn 84, A (PhD): Mm - hmm .
Turn 85, F (PhD): Mm - hmm .
Turn 86, C (PhD): So , um , I 've forgotten now what the name of that machine is but I can {disfmarker} I can send email around about it .
Turn 87, A (PhD): Yeah .
Turn 88, C (PhD): And so we 've got it {disfmarker} now HTK 's compiled for both the Linux and for , um , the Sparcs . Um , you have to make {disfmarker} you have to make sure that in your dot CSHRC , {vocalsound} um , it detects whether you 're running on the Linux or a {disfmarker} a Sparc and points to the right executables . Uh , and you may not have had that in your dot CSHRC before , if you were always just running the Sparc . So , um ,
Turn 89, A (PhD): Mm - hmm .
Turn 90, C (PhD): uh , I can {disfmarker} I can tell you exactly what you need to do to get all of that to work . But it 'll {disfmarker} it really increases what we can run on .
Turn 91, E (Grad): Hmm . Cool .
Turn 92, C (PhD): So , {vocalsound} together with the fact that we 've got these {pause} faster Linux boxes and that it takes less time to do {pause} these , um , we should be able to crank through a lot more experiments .
Turn 93, A (PhD): Mm - hmm .
Turn 94, C (PhD): So .
Turn 95, E (Grad): Hmm .
Turn 96, C (PhD): So after I did that , then what I wanted to do {comment} was try {pause} increasing the number of mixtures , just to see , um {disfmarker} see how {disfmarker} how that affects performance .
Turn 97, A (PhD): Yeah .
Turn 98, C (PhD): So .
Turn 99, B (Professor): Yeah . In fact , you could do something like {pause} keep exactly the same procedure and then add a fifth thing onto it
Turn 100, C (PhD): Mm - hmm .
Turn 101, B (Professor): that had more .
Turn 102, C (PhD): Exactly .
Turn 103, B (Professor): Yeah .
Turn 104, C (PhD): Right . Right .
Turn 105, E (Grad): So at {disfmarker} at the middle o where the arrows are showing , that 's {disfmarker} you 're adding one more mixture per state ,
Turn 106, C (PhD): Uh - huh . Uh ,
Turn 107, E (Grad): or {disfmarker} ?
Turn 108, C (PhD): let 's see , uh . It goes from this {disfmarker} uh , try to go it backwards {disfmarker} this {disfmarker} at this point it 's two mixtures {pause} per state . So this just adds one . Except that , uh , actually for the silence model , it 's six mixtures per state .
Turn 109, B (Professor): Mm - hmm .
Turn 110, C (PhD): Uh , so it goes to two .
Turn 111, E (Grad): OK .
Turn 112, C (PhD): Um . And I think what happens here is {disfmarker}
Turn 113, B (Professor): Might be between , uh , shared , uh {disfmarker} shared variances or something ,
Turn 114, C (PhD): Yeah . I think that 's what it is .
Turn 115, B (Professor): or {disfmarker}
Turn 116, C (PhD): Uh , yeah . It 's , uh {disfmarker} Shoot . I {disfmarker} I {disfmarker} I can't remember now what happens at that first one . Uh , I have to look it up and see .
Turn 117, E (Grad): Oh , OK .
Turn 118, C (PhD): Um , there {disfmarker} because they start off with , uh , an initial model which is just this global model , and then they split it to the individuals . And so , {vocalsound} it may be that that 's what 's happening here . I {disfmarker} I {disfmarker} {vocalsound} I have to look it up and see . I {disfmarker} I don't exactly remember .
Turn 119, E (Grad): OK .
Turn 120, B (Professor): OK .
Turn 121, C (PhD): So . That 's it .
Turn 122, B (Professor): Alright . So what else ?
Turn 123, A (PhD): Um . Yeah . There was a conference call this Tuesday . Um . I don't know yet the {disfmarker} {vocalsound} what happened {vocalsound} Tuesday , but {vocalsound} the points that they were supposed to discuss is still , {vocalsound} uh , things like {vocalsound} the weights , uh {disfmarker}
Turn 124, B (Professor): Oh , this is a conference call for , uh , uh , Aurora participant sort of thing .
Turn 125, E (Grad): For {disfmarker}
Turn 126, A (PhD): Yeah . Yeah .
Turn 127, B (Professor): I see .
Turn 128, A (PhD): Mmm .
Turn 129, B (Professor): Do you know who was {disfmarker} who was {disfmarker} since we weren't in on it , uh , do you know who was in from OGI ? Was {disfmarker} {vocalsound} was {disfmarker} was Hynek involved or was it Sunil
Turn 130, A (PhD): I have no idea .
Turn 131, B (Professor): or {disfmarker} ?
Turn 132, A (PhD): Mmm , I just {disfmarker}
Turn 133, B (Professor): Oh , you don't know . OK .
Turn 134, A (PhD): Yeah .
Turn 135, B (Professor): Alright .
Turn 136, A (PhD): Um , yeah . So the points were the {disfmarker} the weights {disfmarker} how to weight the different error rates {vocalsound} that are obtained from different language and {disfmarker} and conditions . Um , it 's not clear that they will keep the same kind of weighting . Right now it 's a weighting on {disfmarker} on improvement .
Turn 137, B (Professor): Mm - hmm .
Turn 138, A (PhD): Some people are arguing that it would be better to have weights on uh {disfmarker} well , to {disfmarker} to combine error rates {pause} before computing improvement . Uh , and the fact is that for {disfmarker} right now for {pause} the English , they have weights {disfmarker} they {disfmarker} they combine error rates , but for the other languages they combine improvement . So it 's not very consistent . Um {disfmarker}
Turn 139, B (Professor): Mm - hmm .
Turn 140, A (PhD): Yeah . The , um {disfmarker} Yeah . And so {disfmarker} Well , {vocalsound} this is a point . And right now actually there is a thing also , {vocalsound} uh , that happens with the current weight is that a very non - significant improvement {pause} on the well - matched case result in {pause} huge differences in {disfmarker} {vocalsound} in the final number .
Turn 141, B (Professor): Mm - hmm .
Turn 142, A (PhD): And so , perhaps they will change the weights to {disfmarker}
Turn 143, C (PhD): Hmm .
Turn 144, A (PhD): Yeah .
Turn 145, C (PhD): How should that be done ? I mean , it {disfmarker} it seems like there 's a simple way {disfmarker}
Turn 146, A (PhD): Mm - hmm .
Turn 147, C (PhD): Uh , this seems like an obvious mistake or something .
Turn 148, B (Professor): Well , I mean , the fact that it 's inconsistent is an obvious mistake .
Turn 149, C (PhD): Th - they 're {disfmarker}
Turn 150, B (Professor): But the {disfmarker} but , um , the other thing {disfmarker}
Turn 151, A (PhD): In
Turn 152, B (Professor): I don't know I haven't thought it through , but one {disfmarker} one would think that {vocalsound} each {disfmarker} It {disfmarker} it 's like if you say what 's the {disfmarker} what 's the best way to do an average , an arithmetic average or a geometric average ?
Turn 153, C (PhD): Mm - hmm .
Turn 154, B (Professor): It depends what you wanna show .
Turn 155, A (PhD): Mm - hmm .
Turn 156, B (Professor): Each {disfmarker} each one is gonna have a different characteristic .
Turn 157, A (PhD): Yeah .
Turn 158, B (Professor): So {disfmarker}
Turn 159, C (PhD): Well , it seems like they should do , like , the percentage improvement or something , rather than the {pause} absolute improvement .
Turn 160, A (PhD): Tha - that 's what they do .
Turn 161, B (Professor): Well , they are doing that .
Turn 162, A (PhD): Yeah .
Turn 163, B (Professor): No , that is relative . But the question is , do you average the relative improvements {pause} or do you average the error rates and take the relative improvement maybe of that ?
Turn 164, A (PhD): Yeah . Yeah .
Turn 165, B (Professor): And the thing is it 's not just a pure average because there are these weightings .
Turn 166, C (PhD): Oh .
Turn 167, B (Professor): It 's a weighted average . Um .
Turn 168, A (PhD): Yeah . And so when you average the {disfmarker} the relative improvement it tends to {disfmarker} {vocalsound} to give a lot of {disfmarker} of , um , {vocalsound} importance to the well - matched case because {pause} the baseline is already very good and , um , i it 's {disfmarker}
Turn 169, C (PhD): Why don't they not look at improvements but just look at your av your scores ? You know , figure out how to combine the scores
Turn 170, A (PhD): Mm - hmm .
Turn 171, C (PhD): with a weight or whatever , and then give you a score {disfmarker} here 's your score . And then they can do the same thing for the baseline system {disfmarker} and here 's its score . And then you can look at {disfmarker}
Turn 172, A (PhD): Mm - hmm .
Turn 173, B (Professor): Well , that 's what he 's seeing as one of the things they could do .
Turn 174, A (PhD): Yeah .
Turn 175, B (Professor): It 's just when you {disfmarker} when you get all done , I think that they pro I m I {disfmarker} I wasn't there but I think they started off this process with the notion that {vocalsound} you should be {pause} significantly better than the previous standard .
Turn 176, C (PhD): Mm - hmm .
Turn 177, B (Professor): And , um , so they said " how much is significantly better ? what do you {disfmarker} ? " And {disfmarker} and so they said " well , {vocalsound} you know , you should have half the errors , " or something , " that you had before " .
Turn 178, A (PhD): Mm - hmm . Hmm .
Turn 179, C (PhD): Mm - hmm .
Turn 180, A (PhD): Yeah .
Turn 181, B (Professor): So it 's , uh , But it does seem like
Turn 182, C (PhD): Hmm .
Turn 183, B (Professor): i i it does seem like it 's more logical to combine them first and then do the {disfmarker}
Turn 184, A (PhD): Combine error rates and then {disfmarker}
Turn 185, B (Professor): Yeah .
Turn 186, A (PhD): Yeah . Well {disfmarker}
Turn 187, B (Professor): Yeah .
Turn 188, A (PhD): But there is this {disfmarker} this {disfmarker} is this still this problem of weights . When {disfmarker} when you combine error rate it tends to {pause} give more importance to the difficult cases , and some people think that {disfmarker}
Turn 189, B (Professor): Oh , yeah ?
Turn 190, A (PhD): well , they have different , {vocalsound} um , opinions about this . Some people think that {vocalsound} it 's more important to look at {disfmarker} {vocalsound} to have ten percent imp relative improvement on {pause} well - matched case than to have fifty percent on the m mismatched , and other people think that it 's more important to improve a lot on the mismatch and {disfmarker} So , bu
Turn 191, C (PhD): It sounds like they don't really have a good idea about what the final application is gonna be .
Turn 192, A (PhD): l de fff ! Mmm .
Turn 193, B (Professor): Well , you know , the {disfmarker} the thing is {vocalsound} that if you look at the numbers on the {disfmarker} on the more difficult cases , {vocalsound} um , if you really believe that was gonna be the predominant use , {vocalsound} none of this would be good enough .
Turn 194, A (PhD): Yeah . Mmm . Yeah .
Turn 195, B (Professor): Nothing anybody 's {disfmarker}
Turn 196, C (PhD): Mm - hmm .
Turn 197, B (Professor): whereas {vocalsound} you sort of with some reasonable error recovery could imagine in the better cases that these {disfmarker} these systems working . So , um , I think the hope would be that it would {disfmarker} {vocalsound} uh , it would work well {pause} for the good cases and , uh , it would have reasonable {disfmarker} reas {vocalsound} soft degradation as you got to worse and worse conditions . Um .
Turn 198, C (PhD): Yeah . I {disfmarker} I guess what I 'm {disfmarker} I mean , I {disfmarker} I was thinking about it in terms of , if I were building the final product and I was gonna test to see which front - end I 'd {disfmarker} {vocalsound} I wanted to use , I would {vocalsound} try to {pause} weight things depending on the exact environment that I was gonna be using the system in .
Turn 199, B (Professor): But {disfmarker} but {disfmarker} No .
Turn 200, C (PhD): If I {disfmarker}
Turn 201, B (Professor): Well , no {disfmarker} well , no . I mean , {vocalsound} it isn't the operating theater . I mean , they don they {disfmarker} they don't {disfmarker} they don't really {pause} know , I think .
Turn 202, C (PhD): Yeah .
Turn 203, B (Professor): I mean , I th
Turn 204, C (PhD): So if {disfmarker} if they don't know , doesn't that suggest the way for them to go ? Uh , you assume everything 's equal . I mean , y y I mean , you {disfmarker}
Turn 205, B (Professor): Well , I mean , I {disfmarker} I think one thing to do is to just not rely on a single number {disfmarker} to maybe have two or three numbers ,
Turn 206, C (PhD): Yeah .
Turn 207, B (Professor): you know ,
Turn 208, C (PhD): Right .
Turn 209, B (Professor): and {disfmarker} and {disfmarker} and say {vocalsound} here 's how much you , uh {disfmarker} you improve {vocalsound} the , uh {disfmarker} the {disfmarker} the relatively clean case and here 's {disfmarker} or {disfmarker} or well - matched case , and here 's how {disfmarker} here 's how much you ,
Turn 210, C (PhD): Mm - hmm .
Turn 211, B (Professor): uh {disfmarker}
Turn 212, C (PhD): So not {disfmarker}
Turn 213, B (Professor): So .
Turn 214, C (PhD): So not try to combine them .
Turn 215, B (Professor): Yeah . Uh , actually it 's true .
Turn 216, C (PhD): Yeah .
Turn 217, B (Professor): Uh , I had forgotten this , uh , but , uh , well - matched is not actually clean . What it is is just that , u uh , the training and testing are similar .
Turn 218, C (PhD): The training and testing .
Turn 219, A (PhD): Mmm .
Turn 220, B (Professor): So , I guess what you would do in practice is you 'd try to get as many , {vocalsound} uh , examples of similar sort of stuff as you could , and then ,
Turn 221, C (PhD): Yeah .
Turn 222, B (Professor): uh {disfmarker} So the argument for that being the {disfmarker} the {disfmarker} the more important thing , {vocalsound} is that you 're gonna try and do that , {vocalsound} but you wanna see how badly it deviates from that when {disfmarker} when {disfmarker} when the , uh {disfmarker} it 's a little different .
Turn 223, C (PhD): So {disfmarker}
Turn 224, B (Professor): Um ,
Turn 225, C (PhD): so you should weight those other conditions v very {disfmarker} you know , really small .
Turn 226, B (Professor): But {disfmarker} No . That 's a {disfmarker} that 's a {disfmarker} that 's an arg
Turn 227, C (PhD): I mean , that 's more of an information kind of thing .
Turn 228, B (Professor): that 's an ar Well , that 's an argument for it , but let me give you the opposite argument . The opposite argument is you 're never really gonna have a good sample of all these different things .
Turn 229, C (PhD): Uh - huh .
Turn 230, B (Professor): I mean , are you gonna have w uh , uh , examples with the windows open , half open , full open ? Going seventy , sixty , fifty , forty miles an hour ? On what kind of roads ?
Turn 231, C (PhD): Mm - hmm .
Turn 232, B (Professor): With what passing you ? With {disfmarker} uh , I mean ,
Turn 233, C (PhD): Mm - hmm .
Turn 234, B (Professor): I {disfmarker} I {disfmarker} I think that you could make the opposite argument that the well - matched case is a fantasy .
Turn 235, C (PhD): Mm - hmm .
Turn 236, B (Professor): You know , so ,
Turn 237, E (Grad): Uh - huh .
Turn 238, B (Professor): I think the thing is is that if you look at the well - matched case versus the po you know , the {disfmarker} the medium and the {disfmarker} and the fo and then the mismatched case , {vocalsound} um , we 're seeing really , really big differences in performance . Right ? And {disfmarker} and y you wouldn't like that to be the case . You wouldn't like that as soon as you step outside {disfmarker} You know , a lot of the {disfmarker} the cases it 's {disfmarker} is {disfmarker}
Turn 239, C (PhD): Well , that 'll teach them to roll their window up .
Turn 240, B (Professor): I mean , in these cases , if you go from the {disfmarker} the , uh {disfmarker} I mean , I don't remember the numbers right off , but if you {disfmarker} if you go from the well - matched case to the medium , {vocalsound} it 's not an enormous difference in the {disfmarker} in the {disfmarker} the training - testing situation , and {disfmarker} and {disfmarker} and it 's a really big {vocalsound} performance drop .
Turn 241, C (PhD): Mm - hmm .
Turn 242, B (Professor): You know , so , um {disfmarker} Yeah , I mean the reference one , for instance {disfmarker} this is back old on , uh {disfmarker} on Italian {disfmarker} uh , was like {pause} six percent error for the well - matched and eighteen for the medium - matched and sixty for the {disfmarker} {vocalsound} for highly - mismatched . Uh , and , you know , with these other systems we {disfmarker} we {vocalsound} helped it out quite a bit , but still there 's {disfmarker} there 's something like a factor of two or something between well - matched and medium - matched . And {vocalsound} so I think that {vocalsound} if what you 're {disfmarker} {vocalsound} if the goal of this is to come up with robust features , it does mean {disfmarker} So you could argue , in fact , that the well - matched is something you shouldn't be looking at at all , that {disfmarker} that the goal is to come up with features {vocalsound} that will still give you reasonable performance , you know , with again gentle degregra degradation , um , even though the {disfmarker} the testing condition is not the same as the training .
Turn 243, C (PhD): Hmm .
Turn 244, B (Professor): So , you know , I {disfmarker} I could argue strongly that something like the medium mismatch , which is you know not compl pathological but {disfmarker} I mean , what was the {disfmarker} the medium - mismatch condition again ?
Turn 245, A (PhD): Um , {vocalsound} it 's {disfmarker} Yeah . Medium mismatch is everything with the far {pause} microphone , but trained on , like , low noisy condition , like low speed and {disfmarker} or {pause} stopped car and tested on {pause} high - speed conditions , I think , like on a highway and {disfmarker}
Turn 246, B (Professor): Right .
Turn 247, A (PhD): So {disfmarker}
Turn 248, B (Professor): So it 's still the same {disfmarker} same microphone in both cases ,
Turn 249, A (PhD): Same microphone but {disfmarker} Yeah .
Turn 250, B (Professor): but , uh , it 's {disfmarker} there 's a mismatch between the car conditions . And that 's {disfmarker} uh , you could argue that 's a pretty realistic situation
Turn 251, C (PhD): Yeah .
Turn 252, A (PhD): Mm - hmm .
Turn 253, B (Professor): and , uh , I 'd almost argue for weighting that highest . But the way they have it now , {vocalsound} it 's {disfmarker} I guess it 's {disfmarker} it 's {disfmarker} They {disfmarker} they compute the relative improvement first and then average that with a weighting ?
Turn 254, A (PhD): Yeah .
Turn 255, B (Professor): And so then the {disfmarker} that {disfmarker} that makes the highly - matched the really big thing .
Turn 256, A (PhD): Mm - hmm .
Turn 257, B (Professor): Um , so , u i since they have these three categories , it seems like the reasonable thing to do {vocalsound} is to go across the languages {pause} and to come up with an improvement for each of those .
Turn 258, A (PhD): Mm - hmm .
Turn 259, B (Professor): Just say " OK , in the {disfmarker} in the highly - matched case this is what happens , in the {disfmarker} {vocalsound} m the , uh {disfmarker} this other m medium if this happens , in the highly - mismatched {pause} that happens " .
Turn 260, A (PhD): Mm - hmm .
Turn 261, B (Professor): And , uh , you should see , uh , a gentle degradation {pause} through that .
Turn 262, A (PhD): Mmm .
Turn 263, B (Professor): Um . But {disfmarker} I don't know .
Turn 264, A (PhD): Yeah .
Turn 265, B (Professor): I think that {disfmarker} that {disfmarker} I {disfmarker} I {disfmarker} I gather that in these meetings it 's {disfmarker} it 's really tricky to make anything {vocalsound} ac {vocalsound} make any {comment} policy change because {vocalsound} {vocalsound} everybody has {disfmarker} has , uh , their own opinion
Turn 266, A (PhD): Mm - hmm .
Turn 267, B (Professor): and {disfmarker} I don't know .
Turn 268, A (PhD): Yeah .
Turn 269, B (Professor): Yeah .
Turn 270, A (PhD): Uh , so {disfmarker} Yeah . Yeah , but there is probably a {disfmarker} a big change that will {vocalsound} be made is that the {disfmarker} the baseline {disfmarker} th they want to have a new baseline , perhaps , which is , um , MFCC but with {vocalsound} a voice activity detector . And apparently , {vocalsound} uh , some people are pushing to still keep this fifty percent number . So they want {vocalsound} to have at least fifty percent improvement on the baseline , but w which would be a much better baseline .
Turn 271, B (Professor): Mm - hmm . Mm - hmm .
Turn 272, A (PhD): And if we look at the result that Sunil sent , {vocalsound} just putting the VAD in the baseline improved , like , more than twenty percent ,
Turn 273, B (Professor): Mm - hmm .
Turn 274, A (PhD): which would mean then {disfmarker} then {disfmarker} mean that fifty percent on this new baseline is like , well , more than sixty percent improvement on {disfmarker} on {disfmarker} o e e uh {disfmarker}
Turn 275, B (Professor): So nobody would {pause} be there , probably . Right ?
Turn 276, A (PhD): Right now , nobody would be there , but {disfmarker} Yeah .
Turn 277, B (Professor): Good . Work to do .
Turn 278, A (PhD): Uh - huh .
Turn 279, B (Professor): So whose VAD is {disfmarker} Is {disfmarker} is this a {disfmarker} ?
Turn 280, A (PhD): Uh , they didn't decide yet . I guess i this was one point of the conference call also , but {disfmarker} mmm , so I don't know . Um , but {disfmarker} Yeah .
Turn 281, E (Grad): Oh .
Turn 282, B (Professor): Oh , I {disfmarker} I think th that would be {vocalsound} good . I mean , it 's not that the design of the VAD isn't important , but it 's just that it {disfmarker} it {disfmarker} it does seem to be i uh , a lot of {pause} work to do a good job on {disfmarker} on that and as well as being a lot of work to do a good job on the feature {vocalsound} design ,
Turn 283, A (PhD): Yeah .
Turn 284, B (Professor): so
Turn 285, A (PhD): Yeah .
Turn 286, B (Professor): if we can {pause} cut down on that maybe we can make some progress .
Turn 287, A (PhD): M Yeah .
Turn 288, E (Grad): Hmm .
Turn 289, A (PhD): But I guess perhaps {disfmarker} I don't know w {vocalsound} Yeah . Uh , yeah . Per - e s s someone told that perhaps it 's not fair to do that because the , um {disfmarker} to make a good VAD {pause} you don't have enough to {disfmarker} with the {disfmarker} the features that are {disfmarker} the baseline features . So {disfmarker} mmm , you need more features . So you really need to put more {disfmarker} more in the {disfmarker} in {disfmarker} in the front - end .
Turn 290, B (Professor): Yeah .
Turn 291, A (PhD): So i
Turn 292, B (Professor): Um ,
Turn 293, A (PhD): S
Turn 294, B (Professor): sure . But i bu
Turn 295, C (PhD): Wait a minute . I {disfmarker} I 'm confused .
Turn 296, A (PhD): Yeah .
Turn 297, C (PhD): Wha - what do you mean ?
Turn 298, A (PhD): Yeah , if i
Turn 299, B (Professor): So y so you m s Yeah , but {disfmarker} Well , let 's say for ins see , MFCC for instance doesn't have anything in it , uh , related to the pitch . So just {disfmarker} just for example . So suppose you 've {disfmarker} that {vocalsound} what you really wanna do is put a good pitch detector on there and if it gets an unambiguous {disfmarker}
Turn 300, C (PhD): Oh , oh . I see .
Turn 301, A (PhD): Mm - hmm .
Turn 302, B (Professor): if it gets an unambiguous result then you 're definitely in a {disfmarker} in a {disfmarker} in a voice in a , uh , s region with speech . Uh .
Turn 303, C (PhD): So there 's this assumption that the v the voice activity detector can only use the MFCC ?
Turn 304, A (PhD): That 's not clear , but this {disfmarker} {vocalsound} e
Turn 305, B (Professor): Well , for the baseline .
Turn 306, C (PhD): Yeah .
Turn 307, B (Professor): So {disfmarker} so if you use other features then y But it 's just a question of what is your baseline . Right ? What is it that you 're supposed to do better than ?
Turn 308, C (PhD): I g Yeah .
Turn 309, B (Professor): And so having the baseline be the MFCC 's {pause} means that people could {pause} choose to pour their ener their effort into trying to do a really good VAD
Turn 310, C (PhD): I don't s But they seem like two {pause} separate issues .
Turn 311, B (Professor): or tryi They 're sort of separate .
Turn 312, C (PhD): Right ? I mean {disfmarker}
Turn 313, B (Professor): Unfortunately there 's coupling between them , which is part of what I think Stephane is getting to , is that {vocalsound} you can choose your features in such a way as to improve the VAD .
Turn 314, A (PhD): Yeah .
Turn 315, B (Professor): And you also can choose your features in such a way as to prove {disfmarker} improve recognition . They may not be the same thing .
Turn 316, C (PhD): But it seems like you should do both .
Turn 317, B (Professor): You should do both
Turn 318, C (PhD): Right ?
Turn 319, B (Professor): and {disfmarker} and I {disfmarker} I think that this still makes {disfmarker} I still think this makes sense as a baseline . It 's just saying , as a baseline , we know {disfmarker}
Turn 320, A (PhD): Mmm .
Turn 321, B (Professor): you know , we had the MFCC 's before , lots of people have done voice activity detectors ,
Turn 322, A (PhD): Mm - hmm .
Turn 323, B (Professor): you might as well pick some voice activity detector and make that the baseline , just like you picked some version of HTK and made that the baseline .
Turn 324, A (PhD): Yeah . Right .
Turn 325, B (Professor): And then {pause} let 's try and make everything better . Um , and if one of the ways you make it better is by having your features {pause} be better features for the VAD then that 's {disfmarker} so be it .
Turn 326, A (PhD): Mm - hmm .
Turn 327, B (Professor): But , uh , uh , uh , at least you have a starting point that 's {disfmarker} um , cuz i i some of {disfmarker} the some of the people didn't have a VAD at all , I guess . Right ? And {disfmarker} and
Turn 328, A (PhD): Yeah .
Turn 329, B (Professor): then they {disfmarker} they looked pretty bad and {disfmarker} and in fact what they were doing wasn't so bad at all .
Turn 330, A (PhD): Mm - hmm . Mm - hmm .
Turn 331, B (Professor): But , um .
Turn 332, C (PhD): Yeah . It seems like you should try to make your baseline as good as possible . And if it turns out that {pause} you can't improve on that , well , I mean , then , you know , nobody wins and you just use MFCC . Right ?
Turn 333, B (Professor): Yeah . I mean , it seems like , uh , it should include sort of the current state of the art {vocalsound} that you want {disfmarker} are trying to improve , and MFCC 's , you know , or PLP or something {disfmarker} it seems like {vocalsound} reasonable baseline for the features , and anybody doing this task , {vocalsound} uh , is gonna have some sort of voice activity detection at some level , in some way . They might use the whole recognizer to do it {vocalsound} but {disfmarker} rather than {vocalsound} a separate thing , but {disfmarker} {vocalsound} but they 'll have it on some level . So , um .
Turn 334, C (PhD): It seems like whatever they choose they shouldn't , {vocalsound} you know , purposefully brain - damage a part of the system to {pause} make a worse baseline , or {disfmarker}
Turn 335, B (Professor): Well , I think people just had
Turn 336, C (PhD): You know ?
Turn 337, B (Professor): it wasn't that they purposely brain - damaged it . I think people hadn't really thought through {vocalsound} about the , uh {disfmarker} the VAD issue .
Turn 338, C (PhD): Mmm .
Turn 339, A (PhD): Mm - hmm .
Turn 340, B (Professor): And {disfmarker} and then when the {disfmarker} the {disfmarker} the proposals actually came in and half of them had V A Ds and half of them didn't , and the half that did did well and the {vocalsound} half that didn't did poorly .
Turn 341, C (PhD): Mm - hmm .
Turn 342, B (Professor): So it 's {disfmarker}
Turn 343, A (PhD): Mm - hmm . Um .
Turn 344, B (Professor): Uh .
Turn 345, A (PhD): Yeah . So we 'll see what happen with this . And {disfmarker} Yeah . So what happened since , um , {vocalsound} last week is {disfmarker} well , from OGI , these experiments on {pause} putting VAD on the baseline . And these experiments also are using , uh , some kind of noise compensation , so spectral subtraction , and putting on - line normalization , um , just after this . So I think spectral subtraction , LDA filtering , and on - line normalization , so which is similar to {vocalsound} the pro proposal - one , but with {pause} spectral subtraction in addition , and it seems that on - line normalization doesn't help further when you have spectral subtraction .
Turn 346, C (PhD): Is this related to the issue that you brought up a couple of meetings ago with the {disfmarker} the {vocalsound} musical tones
Turn 347, A (PhD): I {disfmarker}
Turn 348, C (PhD): and {disfmarker} ?
Turn 349, A (PhD): I have no idea , because the issue I brought up was with a very simple spectral subtraction approach ,
Turn 350, C (PhD): Mmm .
Turn 351, A (PhD): and the one that {vocalsound} they use at OGI is one from {disfmarker} from {vocalsound} the proposed {disfmarker} the {disfmarker} the {disfmarker} the Aurora prop uh , proposals , which might be much better . So , yeah . I asked {vocalsound} Sunil for more information about that , but , uh , I don't know yet . Um . And what 's happened here is that we {disfmarker} so we have this kind of new , um , reference system which {vocalsound} use a nice {disfmarker} a {disfmarker} a clean downsampling - upsampling , which use a new filter {vocalsound} that 's much shorter and which also cuts the frequency below sixty - four hertz ,
Turn 352, B (Professor): Right .
Turn 353, A (PhD): which was not done on our first proposal .
Turn 354, B (Professor): When you say " we have that " , does Sunil have it now , too ,
Turn 355, A (PhD): I No .
Turn 356, B (Professor): or {disfmarker} ?
Turn 357, A (PhD): No .
Turn 358, B (Professor): OK .
Turn 359, A (PhD): Because we 're still testing . So we have the result for , {vocalsound} uh , just the features
Turn 360, B (Professor): OK .
Turn 361, A (PhD): and we are currently testing with putting the neural network in the KLT . Um , it seems to improve on the well - matched case , um , {vocalsound} but it 's a little bit worse on the mismatch and highly - mismatched {disfmarker} I mean when we put the neural network . And with the current weighting I think it 's sh it will be better because the well - matched case is better . Mmm .
Turn 362, B (Professor): But how much worse {disfmarker} since the weighting might change {disfmarker} how {disfmarker} how much worse is it on the other conditions , when you say it 's a little worse ?
Turn 363, A (PhD): It 's like , uh , fff , fff {comment} {vocalsound} {pause} um , {comment} {vocalsound} {vocalsound} {pause} ten percent relative . Yeah .
Turn 364, B (Professor): OK . Um .
Turn 365, A (PhD): Mm - hmm .
Turn 366, B (Professor): But it has the , uh {disfmarker} the latencies are much shorter . That 's {disfmarker}
Turn 367, A (PhD): Uh - y w when I say it 's worse , it 's not {disfmarker} it 's when I {disfmarker} I {disfmarker} uh , compare proposal - two to proposal - one , so , r uh , y putting neural network {vocalsound} compared to n not having any neural network . I mean , this new system is {disfmarker} is {disfmarker} is better ,
Turn 368, B (Professor): Uh - huh .
Turn 369, A (PhD): because it has {vocalsound} um , this sixty - four hertz cut - off , uh , clean {vocalsound} downsampling , and , um {disfmarker} what else ? Uh , yeah , a good VAD . We put the good VAD . So . Yeah , I don't know . I {disfmarker} I {disfmarker} j uh , uh {disfmarker} pr
Turn 370, B (Professor): But the latencies {disfmarker} but you 've got the latency shorter now .
Turn 371, A (PhD): Latency is short {disfmarker} is {disfmarker} Yeah .
Turn 372, B (Professor): Yeah .
Turn 373, F (PhD): Isn't it
Turn 374, A (PhD): And so
Turn 375, B (Professor): So it 's better than the system that we had before .
Turn 376, A (PhD): Yeah . Mainly because {pause} {vocalsound} of {pause} the sixty - four hertz and the good VAD .
Turn 377, B (Professor): OK .
Turn 378, A (PhD): And then I took this system and , {vocalsound} mmm , w uh , I p we put the old filters also . So we have this good system , with good VAD , with the short filter and with the long filter , and , um , with the short filter it 's not worse . So {disfmarker} well , is it {disfmarker}
Turn 379, B (Professor): OK .
Turn 380, A (PhD): it 's in {disfmarker}
Turn 381, B (Professor): So that 's {disfmarker} that 's all fine .
Turn 382, A (PhD): Yes . Uh {disfmarker}
Turn 383, B (Professor): But what you 're saying is that when you do these {disfmarker} So let me try to understand . When {disfmarker} when you do these same improvements {vocalsound} to proposal - one ,
Turn 384, A (PhD): Mm - hmm .
Turn 385, B (Professor): that , uh , on the {disfmarker} i things are somewhat better , uh , in proposal - two for the well - matched case and somewhat worse for the other two cases .
Turn 386, A (PhD): Yeah .
Turn 387, B (Professor): So does , uh {disfmarker} when you say , uh {disfmarker} So {disfmarker} The th now that these other things are in there , is it the case maybe that the additions of proposal - two over proposal - one are {pause} less im important ?
Turn 388, A (PhD): Yeah . Probably , yeah .
Turn 389, B (Professor): I get it .
Turn 390, A (PhD): Um {disfmarker} So , yeah . Uh . Yeah , but it 's a good thing anyway to have {vocalsound} shorter delay . Then we tried , um , {vocalsound} to do something like proposal - two but having , um , e using also MSG features . So there is this KLT part , which use just the standard features ,
Turn 391, B (Professor): Mm - hmm . Right .
Turn 392, A (PhD): and then two neura two neural networks .
Turn 393, B (Professor): Mm - hmm .
Turn 394, A (PhD): Mmm , and it doesn't seem to help . Um , however , we just have {vocalsound} one result , which is the Italian mismatch , so . Uh . We have to wait for that to fill the whole table , but {disfmarker}
Turn 395, B (Professor): OK . There was a {vocalsound} start of some effort on something related to voicing or something . Is that {disfmarker} ?
Turn 396, A (PhD): Yeah . Um , {vocalsound} yeah . So basically we try to , {vocalsound} {vocalsound} uh , find {vocalsound} good features that could be used for voicing detection , uh , but it 's still , uh {disfmarker} on the , um {disfmarker} t
Turn 397, F (PhD): Oh , well , I have the picture .
Turn 398, A (PhD): we {disfmarker} w basically we are still playing with Matlab to {disfmarker} {vocalsound} to look at {disfmarker} at what happened ,
Turn 399, C (PhD): What sorts of {disfmarker}
Turn 400, F (PhD): Yeah .
Turn 401, A (PhD): and {disfmarker}
Turn 402, C (PhD): what sorts of features are you looking at ?
Turn 403, F (PhD): We have some {disfmarker}
Turn 404, A (PhD): So we would be looking at , um , the {pause} variance of the spectrum of the excitation ,
Turn 405, F (PhD): uh , um , this , this , and this .
Turn 406, A (PhD): something like this , which is {disfmarker} should be high for voiced sounds . Uh , we {disfmarker}
Turn 407, C (PhD): Wait a minute . I {disfmarker} what does that mean ? The variance of the spectrum of excitation .
Turn 408, A (PhD): Yeah . So the {disfmarker} So basically the spectrum of the excitation {vocalsound} for a purely periodic sig signal shou sh
Turn 409, B (Professor): OK . Yeah , w what yo what you 're calling the excitation , as I recall , is you 're subtracting the {disfmarker} the , um {disfmarker} the mel {disfmarker} mel {disfmarker} {vocalsound} mel filter , uh , spectrum from the FFT spectrum .
Turn 410, A (PhD): e That 's right . Yeah . So {disfmarker}
Turn 411, B (Professor): Right .
Turn 412, A (PhD): Yeah .
Turn 413, F (PhD): Mm - hmm .
Turn 414, A (PhD): So we have the mel f filter bank , we have the FFT , so we {pause} just {disfmarker}
Turn 415, B (Professor): So it 's {disfmarker} it 's not really an excitation ,
Turn 416, A (PhD): No .
Turn 417, B (Professor): but it 's something that hopefully tells you something about the excitation .
Turn 418, A (PhD): Yeah , that 's right .
Turn 419, B (Professor): Yeah , yeah .
Turn 420, A (PhD): Um {disfmarker} Yeah .
Turn 421, F (PhD): We have here some histogram ,
Turn 422, A (PhD): E yeah ,
Turn 423, F (PhD): but they have a lot of overlap .
Turn 424, A (PhD): but it 's {disfmarker} it 's still {disfmarker} Yeah . So , well , for unvoiced portion we have something tha {vocalsound} that has a mean around O point three , and for voiced portion the mean is O point fifty - nine . But the variance seem quite {vocalsound} high .
Turn 425, C (PhD): How do you know {disfmarker} ?
Turn 426, A (PhD): So {disfmarker} Mmm .
Turn 427, C (PhD): How did you get your {pause} voiced and unvoiced truth data ?
Turn 428, A (PhD): We used , uh , TIMIT and we used canonical mappings between the phones
Turn 429, F (PhD): Yeah . We , uh , use {pause} TIMIT on this ,
Turn 430, A (PhD): and
Turn 431, F (PhD): for {disfmarker}
Turn 432, A (PhD): th Yeah .
Turn 433, F (PhD): But if we look at it in one sentence , it {disfmarker} apparently it 's good , I think .
Turn 434, A (PhD): Yeah , but {disfmarker} Yeah . Uh , so it 's noisy TIMIT . That 's right . Yeah .
Turn 435, E (Grad): It 's noisy TIMIT .
Turn 436, F (PhD): Yeah .
Turn 437, A (PhD): It seems quite robust to noise , so when we take {disfmarker} we draw its parameters across time for a clean sentence and then nois the same noisy sentence , it 's very close .
Turn 438, B (Professor): Mm - hmm .
Turn 439, A (PhD): Yeah . So there are {disfmarker} there is this . There could be also the , um {disfmarker} {vocalsound} something like the maximum of the auto - correlation function or {disfmarker} which {disfmarker}
Turn 440, C (PhD): Is this a {disfmarker} a s a trained system ? Or is it a system where you just pick some thresholds ? Ho - how does it work ?
Turn 441, A (PhD): Right now we just are trying to find some features . And ,
Turn 442, C (PhD): Mm - hmm .
Turn 443, A (PhD): uh {disfmarker} Yeah . Hopefully , I think what we want to have is to put these features in s some kind of , um {disfmarker} well , to {disfmarker} to obtain a statistical model on these features and to {disfmarker} or just to use a neural network and hopefully these features w would help {disfmarker}
Turn 444, C (PhD): Because it seems like what you said about the mean of the {disfmarker} the voiced and the unvoiced {disfmarker} {comment} {vocalsound} that seemed pretty encouraging .
Turn 445, A (PhD): Mm - hmm .
Turn 446, B (Professor): Well , yeah , except the variance was big .
Turn 447, C (PhD): Right ?
Turn 448, A (PhD): Yeah . Except the variance is quite high .
Turn 449, B (Professor): Right ?
Turn 450, C (PhD): Well , y
Turn 451, A (PhD): Yeah .
Turn 452, C (PhD): Well , y I {disfmarker} I don't know that I would trust that so much because you 're doing these canonical mappings from TIMIT labellings .
Turn 453, A (PhD): Uh - huh .
Turn 454, C (PhD): Right ? So , really that 's sort of a cartoon picture about what 's voiced and unvoiced . So that could be giving you a lot of variance .
Turn 455, A (PhD): Yeah .
Turn 456, C (PhD): I mean , i it {disfmarker} it may be that {disfmarker} that you 're finding something good and that the variance is sort of artificial because of how you 're getting your truth .
Turn 457, A (PhD): Mm - hmm .
Turn 458, B (Professor): Yeah . But another way of looking at it {vocalsound} might be that {disfmarker} I mean , what w we we are coming up with feature sets after all . So another way of looking at it is that {vocalsound} um , the mel cepstru mel {pause} spectrum , mel cepstrum , {vocalsound} any of these variants , um , give you the smooth spectrum . It 's the spectral envelope . By going back to the FFT , {vocalsound} you 're getting something that is {pause} more like the raw data . So the question is , what characterization {disfmarker} and you 're playing around with this {disfmarker} another way of looking at it is what characterization {vocalsound} of the difference between {pause} the raw data {pause} and this smooth version {pause} is something that you 're missing that could help ? So , I mean , looking at different statistical measures of that difference , coming up with some things and just trying them out and seeing if you add them onto the feature vector does that make things better or worse in noise , where you 're really just i i the way I 'm looking at it is not so much you 're trying to f find the best {disfmarker} the world 's best voiced - unvoiced , uh , uh , classifier ,
Turn 459, C (PhD): Mm - hmm .
Turn 460, A (PhD): Mmm .
Turn 461, B (Professor): but it 's more that , {vocalsound} you know , uh , uh , try some different statistical characterizations of that difference back to the raw data
Turn 462, C (PhD): Right .
Turn 463, B (Professor): and {disfmarker} and m maybe there 's something there that {pause} the system can use .
Turn 464, C (PhD): Right .
Turn 465, A (PhD): Yeah . Yeah , but ther more obvious is that {disfmarker} Yeah . The {disfmarker} the more obvious is that {disfmarker} that {disfmarker} well , using the {disfmarker} th the FFT , um , {vocalsound} you just {disfmarker} it gives you just information about if it 's voiced or not voiced , ma mainly , I mean . But {disfmarker} So ,
Turn 466, B (Professor): Yeah .
Turn 467, A (PhD): this is why we {disfmarker} we started to look {pause} by having sort of voiced phonemes
Turn 468, B (Professor): Well , that 's the rea w w what I 'm arguing is that 's Yeah . I mean , uh , what I 'm arguing is that that {disfmarker} that 's givi you {disfmarker} gives you your intuition .
Turn 469, A (PhD): and {disfmarker} Mm - hmm .
Turn 470, B (Professor): But in {disfmarker} in reality , it 's {disfmarker} you know , there 's all of this {disfmarker} this overlap and so forth ,
Turn 471, E (Grad): Oh , sorry .
Turn 472, B (Professor): and {disfmarker} But what I 'm saying is that may be OK , because what you 're really getting is not actually voiced versus unvoiced , both for the fac the reason of the overlap and {disfmarker} and then , uh , th you know , structural reasons , uh , uh , like the one that Chuck said , that {disfmarker} that in fact , well , the data itself is {disfmarker} {vocalsound} that you 're working with is not perfect .
Turn 473, A (PhD): Yeah . Mm - hmm .
Turn 474, B (Professor): So , what I 'm saying is maybe that 's not a killer because you 're just getting some characterization , one that 's driven by your intuition about voiced - unvoiced certainly ,
Turn 475, A (PhD): Mm - hmm .
Turn 476, B (Professor): but it 's just some characterization {vocalsound} of something back in the {disfmarker} in the {disfmarker} in the almost raw data , rather than the smooth version .
Turn 477, A (PhD): Mm - hmm .
Turn 478, B (Professor): And your intuition is driving you towards particular kinds of , {vocalsound} uh , statistical characterizations of , um , what 's missing from the spectral envelope .
Turn 479, A (PhD): Mm - hmm .
Turn 480, B (Professor): Um , obviously you have something about the excitation , um , and what is it about the excitation , and , you know {disfmarker} and you 're not getting the excitation anyway , you know . So {disfmarker} so I {disfmarker} I would almost take a {disfmarker} uh , especially if {disfmarker} if these trainings and so forth are faster , I would almost just take a {vocalsound} uh , a scattershot at a few different {vocalsound} ways of look of characterizing that difference and , uh , you could have one of them but {disfmarker} and {disfmarker} and see , you know , which of them helps .
Turn 481, A (PhD): Mm - hmm . OK .
Turn 482, C (PhD): So i is the idea that you 're going to take {pause} whatever features you develop and {disfmarker} and just add them onto the future vector ? Or , what 's the use of the {disfmarker} the voiced - unvoiced detector ?
Turn 483, A (PhD): Uh , I guess we don't know exactly yet . But , {vocalsound} um {disfmarker} Yeah . Th
Turn 484, C (PhD): It 's not part of a VAD system that you 're doing ?
Turn 485, F (PhD): No .
Turn 486, A (PhD): Uh , no . No .
Turn 487, C (PhD): Oh , OK .
Turn 488, A (PhD): No , the idea was , I guess , to {disfmarker} to use them as {disfmarker} as features .
Turn 489, C (PhD): Features . I see .
Turn 490, A (PhD): Uh {disfmarker} Yeah , it could be , uh {disfmarker} it could be {vocalsound} a neural network that does voiced and unvoiced detection ,
Turn 491, C (PhD): Mm - hmm .
Turn 492, A (PhD): but it could be in the {disfmarker} also the big neural network that does phoneme classification .
Turn 493, C (PhD): Mm - hmm .
Turn 494, A (PhD): Mmm . Yeah .
Turn 495, B (Professor): But each one of the mixture components {disfmarker} I mean , you have , uh , uh , variance only , so it 's kind of like you 're just multiplying together these , um , probabilities from the individual features {pause} within each mixture . So it 's {disfmarker} so , uh , it seems l you know {disfmarker}
Turn 496, C (PhD): I think it 's a neat thing . Uh , it seems like a good idea .
Turn 497, B (Professor): Yeah . Um . Yeah . I mean , {vocalsound} I know that , um , people doing some robustness things a ways back were {disfmarker} were just doing {disfmarker} just being gross and just throwing in the FFT and actually it wasn't {disfmarker} wasn't {disfmarker} wasn't so bad . Uh , so it would s and {disfmarker} and you know that i it 's gotta hurt you a little bit to not have a {disfmarker} {vocalsound} a spectral , uh {disfmarker} a s a smooth spectral envelope , so there must be something else that you get {pause} in return for that {disfmarker}
Turn 498, A (PhD): Mm - hmm .
Turn 499, B (Professor): that , uh {disfmarker} uh {disfmarker} So .
Turn 500, C (PhD): So how does {disfmarker} uh , maybe I 'm going in too much detail , but {vocalsound} how exactly do you make the difference between the FFT and the smoothed {pause} spectral envelope ? Wha - wh i i uh , how is that , uh {disfmarker} ?
Turn 501, A (PhD): Um , we just {disfmarker} How did we do it up again ?
Turn 502, F (PhD): Uh , we distend the {disfmarker} we have the twenty - three coefficient af after the mel f {vocalsound} filter ,
Turn 503, A (PhD): Mm - hmm .
Turn 504, F (PhD): and we extend these coefficient between the {disfmarker} all the frequency range .
Turn 505, C (PhD): Mm - hmm .
Turn 506, F (PhD): And i the interpolation i between the point {vocalsound} is {disfmarker} give for the triang triangular filter , the value of the triangular filter and of this way we obtained this mode this model speech .
Turn 507, A (PhD): S
Turn 508, B (Professor): So you essentially take the values that {disfmarker} th that you get from the triangular filter and extend them to sor sort of like a rectangle , that 's at that m value .
Turn 509, F (PhD): Yeah .
Turn 510, A (PhD): Yeah . I think we have linear interpolation .
Turn 511, F (PhD): Mm - hmm .
Turn 512, A (PhD): So we have {disfmarker} we have one point for {disfmarker} one energy for each filter bank ,
Turn 513, F (PhD): mmm Yeah , it 's linear .
Turn 514, C (PhD): Mmm .
Turn 515, B (Professor): Oh .
Turn 516, A (PhD): which is {pause} the energy {pause} that 's centered on {disfmarker} on {disfmarker} on the triangle {disfmarker}
Turn 517, F (PhD): Yeah . At the n at the center of the filter {disfmarker}
Turn 518, C (PhD): So you {disfmarker} you end up with a vector that 's the same length as the FFT {pause} vector ?
Turn 519, A (PhD): Yeah . That 's right .
Turn 520, F (PhD): Yeah .
Turn 521, C (PhD): And then you just , uh , compute differences
Turn 522, F (PhD): Yeah . I have here one example if you {disfmarker} if you want see something like that .
Turn 523, A (PhD): Then we compute the difference .
Turn 524, C (PhD): and ,
Turn 525, A (PhD): Yeah . Uh - huh .
Turn 526, B (Professor): OK .
Turn 527, C (PhD): uh , sum the differences ?
Turn 528, A (PhD): So . And I think the variance is computed only from , like , two hundred hertz to {pause} one {disfmarker} to fifteen hundred .
Turn 529, C (PhD): Oh ! OK .
Turn 530, B (Professor): Mm - hmm .
Turn 531, F (PhD): Two thou two {disfmarker} {comment} fifteen hundred ?
Turn 532, B (Professor): Mm - hmm .
Turn 533, A (PhD): Because {disfmarker}
Turn 534, F (PhD): No .
Turn 535, B (Professor): Right .
Turn 536, F (PhD): Two hundred and fifty thousand .
Turn 537, A (PhD): Fifteen hundred . Because {disfmarker} Yeah .
Turn 538, F (PhD): Yeah . Two thousand and fifteen hundred .
Turn 539, A (PhD): Above , um {disfmarker} {vocalsound} it seems that {disfmarker} Well , some voiced sound can have also , {vocalsound} like , a noisy {pause} part on high frequencies , and {disfmarker} But {disfmarker}
Turn 540, B (Professor): Yeah .
Turn 541, A (PhD): Well , it 's just {disfmarker}
Turn 542, B (Professor): No , it 's {disfmarker} makes sense to look at {pause} low frequencies .
Turn 543, C (PhD): So this is {disfmarker} uh , basically this is comparing {vocalsound} an original version of the signal to a smoothed version of the same signal ?
Turn 544, F (PhD): Yeah .
Turn 545, B (Professor): Right . So i so i i this is {disfmarker} I mean , i you could argue about whether it should be linear interpolation or {disfmarker} or {disfmarker} or {disfmarker} or zeroeth order , but {disfmarker} but
Turn 546, C (PhD): Uh - huh .
Turn 547, B (Professor): at any rate something like this {pause} is what you 're feeding your recognizer , typically .
Turn 548, C (PhD): Like which of the {disfmarker} ?
Turn 549, B (Professor): No . Uh , so the mel cepstrum is the {disfmarker} is the {disfmarker} is the cepstrum of this {disfmarker} {vocalsound} this , uh , spectrum or log spectrum ,
Turn 550, A (PhD): So this is {disfmarker} Yeah .
Turn 551, C (PhD): Yeah . Right , right .
Turn 552, B (Professor): whatever it {disfmarker} You - you 're subtracting in {disfmarker} in {disfmarker} in {vocalsound} power domain or log domain ?
Turn 553, A (PhD): In log domain . Yeah .
Turn 554, F (PhD): Log domain .
Turn 555, B (Professor): OK . So it 's sort of like division , when you do the {disfmarker} yeah , the spectra .
Turn 556, F (PhD): Yeah .
Turn 557, A (PhD): Uh , yeah .
Turn 558, C (PhD): It 's the ratio .
Turn 559, B (Professor): Um . Yeah . But , anyway , um {disfmarker} and that 's {disfmarker}
Turn 560, C (PhD): So what 's th uh , what 's the intuition behind this kind of a thing ? I {disfmarker} I don't know really know the signal - processing well enough to understand what {disfmarker} {vocalsound} what is that doing .
Turn 561, A (PhD): So . Yeah . What happen if {disfmarker} what we have {disfmarker} have {disfmarker} what we would like to have is {pause} some spectrum of the excitation signal ,
Turn 562, B (Professor): Yeah . I guess that makes sense . Yeah .
Turn 563, A (PhD): which is for voiced sound ideally a {disfmarker} a pulse train
Turn 564, C (PhD): Uh - huh .
Turn 565, A (PhD): and for unvoiced it 's something that 's more flat .
Turn 566, C (PhD): Uh - huh . Right .
Turn 567, A (PhD): And the way to do this {vocalsound} is that {disfmarker} well , we have the {disfmarker} we have the FFT because it 's computed in {disfmarker} in the {disfmarker} in the system , and we have {vocalsound} the mel {vocalsound} filter banks ,
Turn 568, C (PhD): Mm - hmm . Mm - hmm .
Turn 569, A (PhD): and so if we {disfmarker} if we , like , remove the mel filter bank from the FFT , {vocalsound} we have something that 's {pause} close to the {pause} excitation signal .
Turn 570, E (Grad): Oh .
Turn 571, A (PhD): It 's something that 's like {vocalsound} a {disfmarker} a a train of p a pulse train for voiced sound
Turn 572, C (PhD): OK .
Turn 573, B (Professor): Yeah .
Turn 574, C (PhD): Oh ! OK . Yeah .
Turn 575, A (PhD): and that 's {disfmarker} that should be flat for {disfmarker}
Turn 576, B (Professor): Yeah .
Turn 577, C (PhD): I see . So do you have a picture that sh ?
Turn 578, A (PhD): So - It 's {disfmarker} Y
Turn 579, C (PhD): Is this for a voiced segment ,
Turn 580, A (PhD): yeah .
Turn 581, C (PhD): this picture ? What does it look like for unvoiced ?
Turn 582, F (PhD): Yeah .
Turn 583, A (PhD): You have several {disfmarker} some unvoiced ?
Turn 584, F (PhD): The dif No . Unvoiced , I don't have
Turn 585, A (PhD): Oh .
Turn 586, F (PhD): for unvoiced .
Turn 587, B (Professor): Yeah . So , you know , all {disfmarker}
Turn 588, F (PhD): I 'm sorry .
Turn 589, A (PhD): But {disfmarker} Yeah .
Turn 590, B (Professor): Yeah .
Turn 591, F (PhD): Yeah . This is the {disfmarker} between {disfmarker}
Turn 592, A (PhD): This is another voiced example . Yeah .
Turn 593, F (PhD): No . But it 's this ,
Turn 594, A (PhD): Oh , yeah . This is {disfmarker}
Turn 595, F (PhD): but between the frequency that we are considered for the excitation {disfmarker}
Turn 596, A (PhD): Right . Mm - hmm .
Turn 597, F (PhD): for the difference and this is the difference .
Turn 598, A (PhD): Yeah .
Turn 599, C (PhD): This is the difference . OK .
Turn 600, A (PhD): So , of course , it 's around zero ,
Turn 601, B (Professor): Yeah .
Turn 602, E (Grad): Sure looks {disfmarker}
Turn 603, A (PhD): but {disfmarker}
Turn 604, E (Grad): Hmm .
Turn 605, A (PhD): Well , no .
Turn 606, C (PhD): Hmm .
Turn 607, A (PhD): It is {disfmarker}
Turn 608, F (PhD): Yeah . Because we begin , {vocalsound} uh , in fifteen {vocalsound} point {disfmarker} the fifteen point .
Turn 609, C (PhD): So , does {disfmarker} does the periodicity of this signal say something about the {disfmarker} the {disfmarker}
Turn 610, F (PhD): Fifteen p
Turn 611, A (PhD): So it 's {disfmarker} Yeah .
Turn 612, B (Professor): Pitch .
Turn 613, A (PhD): It 's the pitch .
Turn 614, C (PhD): the pitch ?
Turn 615, A (PhD): Yeah . Mm - hmm .
Turn 616, B (Professor): Yeah .
Turn 617, C (PhD): OK .
Turn 618, B (Professor): That 's like fundamental frequency .
Turn 619, A (PhD): Mm - hmm .
Turn 620, B (Professor): So , I mean , i t t
Turn 621, C (PhD): OK . I see .
Turn 622, B (Professor): I mean , to first order {vocalsound} what you 'd {disfmarker} what you 're doing {disfmarker} I mean , ignore all the details and all the ways which is {disfmarker} that these are complete lies . Uh , the {disfmarker} the {disfmarker} you know , what you 're doing in feature extraction for speech recognition is you have , {vocalsound} uh , in your head a {disfmarker} a {disfmarker} a {disfmarker} a simplified production model for speech ,
Turn 623, C (PhD): Mm - hmm .
Turn 624, B (Professor): in which you have a periodic or aperiodic source that 's driving some filters .
Turn 625, C (PhD): Mm - hmm .
Turn 626, F (PhD): Yeah . This is the {disfmarker} the auto - correlation {disfmarker} the R - zero energy .
Turn 627, A (PhD): Do you have the mean {disfmarker} do you have the mean for the auto - correlation {disfmarker} ?
Turn 628, B (Professor): Uh , first order for speech recognition , you say " I don't care about the source " .
Turn 629, F (PhD): For {disfmarker} Yeah .
Turn 630, A (PhD): Well , I mean for the {disfmarker} the energy .
Turn 631, F (PhD): I have the mean .
Turn 632, B (Professor): Right ?
Turn 633, C (PhD): Right .
Turn 634, B (Professor): And so you just want to find out what the filters are .
Turn 635, C (PhD): Right .
Turn 636, F (PhD): Yeah .
Turn 637, B (Professor): The filters {vocalsound} roughly act like a , um {disfmarker} {vocalsound} a , uh {disfmarker} {vocalsound} a an overall resonant {disfmarker} you know , f some resonances and so forth that th that 's processing excitation .
Turn 638, F (PhD): Here .
Turn 639, A (PhD): They should be more close .
Turn 640, F (PhD): Ah , no . This is this ? More close . Is this ? And this .
Turn 641, C (PhD): Mm - hmm .
Turn 642, A (PhD): Yeah .
Turn 643, C (PhD): Mm - hmm .
Turn 644, A (PhD): So they are {disfmarker} this is {disfmarker} there is less difference .
Turn 645, F (PhD): Mm - hmm .
Turn 646, B (Professor): So if you look at the spectral envelope , just the very smooth properties of it , {vocalsound} you get something closer to that .
Turn 647, A (PhD): This is less {disfmarker} it 's less robust .
Turn 648, F (PhD): Less robust . Yeah .
Turn 649, A (PhD): Oh , yeah .
Turn 650, B (Professor): And the notion is if you have the full spectrum , with all the little nitty - gritty details , {vocalsound} that that has the effect of both ,
Turn 651, C (PhD): Yeah .
Turn 652, B (Professor): and it would be a multiplication in {disfmarker} in frequency domain
Turn 653, C (PhD): Mm - hmm .
Turn 654, B (Professor): so that would be like an addition in log {disfmarker} {vocalsound} power spectrum domain .
Turn 655, C (PhD): Mm - hmm . Mm - hmm .
Turn 656, B (Professor): And so this is saying , well , if you really do have that {vocalsound} sort of vocal tract envelope , and you subtract that off , what you get is the excitation . And I call that lies because you don't really have that , you just have some kind of {vocalsound} signal - processing trickery to get something that 's kind of smooth . It 's not really what 's happening in the vocal tract
Turn 657, C (PhD): Yeah .
Turn 658, B (Professor): so you 're not really getting the vocal excitation .
Turn 659, C (PhD): Right .
Turn 660, B (Professor): That 's why I was going to the {disfmarker} why I was referring to it in a more {disfmarker} {vocalsound} a more , uh , {vocalsound} uh , {vocalsound} conservative way , when I was saying " well , it 's {disfmarker} yeah , it 's the excitation " . But it 's not really the excitation . It 's whatever it is that 's different between {disfmarker}
Turn 661, C (PhD): Oh . This moved in the {disfmarker}
Turn 662, B (Professor): So {disfmarker} so , stand standing back from that , you sort of say there 's this very detailed representation .
Turn 663, C (PhD): Yeah .
Turn 664, B (Professor): You go to a smooth representation .
Turn 665, C (PhD): Mm - hmm .
Turn 666, B (Professor): You go to a smooth representation cuz this typically generalizes better .
Turn 667, C (PhD): Mm - hmm .
Turn 668, B (Professor): Um , but whenever you smooth you lose something , so the question is have you lost something you can you use ?
Turn 669, C (PhD): Right .
Turn 670, B (Professor): Um , probably you wouldn't want to go to the extreme of just ta saying " OK , our feature set will be the FFT " , cuz we really think we do gain something in robustness from going to something smoother , but maybe there 's something that we missed .
Turn 671, C (PhD): Mm - hmm .
Turn 672, B (Professor): So what is it ?
Turn 673, C (PhD): Yeah .
Turn 674, B (Professor): And then you go back to the intuition that , well , you don't really get the excitation , but you get something related to it .
Turn 675, C (PhD): Mm - hmm .
Turn 676, B (Professor): And it {disfmarker} and as you can see from those pictures , you do get something {vocalsound} that shows some periodicity , uh , in frequency ,
Turn 677, C (PhD): Mm - hmm .
Turn 678, B (Professor): you know , and {disfmarker} and {disfmarker} and also in time .
Turn 679, C (PhD): Hmm .
Turn 680, B (Professor): So {disfmarker}
Turn 681, C (PhD): That 's {disfmarker} that 's really neat .
Turn 682, B (Professor): so ,
Turn 683, C (PhD): So you don't have one for unvoiced {pause} picture ?
Turn 684, F (PhD): Uh , not here .
Turn 685, C (PhD): Oh .
Turn 686, F (PhD): No , I have s
Turn 687, A (PhD): Mm - hmm .
Turn 688, B (Professor): Yeah .
Turn 689, F (PhD): But not here .
Turn 690, B (Professor): But presumably you 'll see something that won't have this kind of , uh , uh , uh , regularity in frequency , uh , in the {disfmarker}
Turn 691, A (PhD): But {disfmarker} Yeah . Well .
Turn 692, F (PhD): Not here .
Turn 693, C (PhD): I would li I would like to see those {pause} pictures .
Turn 694, F (PhD): Well , so .
Turn 695, B (Professor): Yeah .
Turn 696, F (PhD): I can't see you {comment} now .
Turn 697, B (Professor): Yeah .
Turn 698, C (PhD): Yeah .
Turn 699, B (Professor): Yeah .
Turn 700, A (PhD): Mm - hmm .
Turn 701, F (PhD): I don't have .
Turn 702, C (PhD): And so you said this is pretty {disfmarker} doing this kind of thing is pretty robust to noise ?
Turn 703, A (PhD): It seems , yeah . Um ,
Turn 704, C (PhD): Huh .
Turn 705, F (PhD): Pfft . Oops . The mean is different {vocalsound} with it , because the {disfmarker} {vocalsound} the histogram for the {disfmarker} {vocalsound} the classifica
Turn 706, A (PhD): No , no , no . But th the kind of robustness to noise {disfmarker}
Turn 707, F (PhD): Oh !
Turn 708, A (PhD): So if {disfmarker} if you take this frame , {vocalsound} uh , from the noisy utterance and the same frame from the clean utterance {disfmarker}
Turn 709, F (PhD): Hmm .
Turn 710, C (PhD): You end up with a similar difference
Turn 711, A (PhD): Y y y yeah . We end up with {disfmarker}
Turn 712, C (PhD): over here ?
Turn 713, A (PhD): Yeah .
Turn 714, C (PhD): OK . Cool !
Turn 715, F (PhD): I have here the same frame for the {pause} clean speech {disfmarker}
Turn 716, C (PhD): Oh , that 's clean .
Turn 717, F (PhD): the same cle
Turn 718, C (PhD): Oh , OK
Turn 719, F (PhD): But they are a difference .
Turn 720, A (PhD): Yeah , that 's {disfmarker}
Turn 721, F (PhD): Because here the FFT is only with {vocalsound} two hundred fifty - six point
Turn 722, C (PhD): Oh .
Turn 723, F (PhD): and this is with five hundred {pause} twelve .
Turn 724, A (PhD): Yeah . This is kind of inter interesting also
Turn 725, C (PhD): OK .
Turn 726, A (PhD): because if we use the standard , {vocalsound} uh , frame length of {disfmarker} of , like , twenty - five milliseconds , {vocalsound} um , {vocalsound} what happens is that for low - pitched voiced , because of the frame length , y you don't really have {disfmarker} {vocalsound} you don't clearly see this periodic structure ,
Turn 727, B (Professor): Mm - hmm .
Turn 728, A (PhD): because of the first lobe of {disfmarker} of each {disfmarker} each of the harmonics .
Turn 729, C (PhD): So this one inclu is a longer {disfmarker} Ah .
Turn 730, A (PhD): So , this is like {disfmarker} yeah , fifty milliseconds or something like that .
Turn 731, F (PhD): Fifty millis Yeah .
Turn 732, A (PhD): Yeah , but it 's the same frame and {disfmarker}
Turn 733, C (PhD): Oh , it 's that time - frequency trade - off thing .
Turn 734, A (PhD): Yeah .
Turn 735, C (PhD): Right ? I see . Yeah .
Turn 736, A (PhD): So , yeah .
Turn 737, B (Professor): Mm - hmm .
Turn 738, C (PhD): Oh . Oh , so this i is this the difference here , for that ?
Turn 739, F (PhD): No . This is the signal . This is the signal .
Turn 740, A (PhD): I see that . Oh , yeah .
Turn 741, F (PhD): The frame .
Turn 742, C (PhD): Oh , that 's the f the original .
Turn 743, A (PhD): Yeah .
Turn 744, F (PhD): This is the fra the original frame .
Turn 745, A (PhD): So with a short frame basically you have only two periods
Turn 746, C (PhD): Yeah .
Turn 747, A (PhD): and it 's not {disfmarker} not enough to {disfmarker} to have this kind of neat things .
Turn 748, C (PhD): Mm - hmm .
Turn 749, F (PhD): Mm - hmm .
Turn 750, C (PhD): Yeah .
Turn 751, A (PhD): But {disfmarker}
Turn 752, F (PhD): And here {disfmarker} No , well .
Turn 753, A (PhD): Yeah . So probably we 'll have to use , {vocalsound} like , long f long frames . Mm - hmm .
Turn 754, C (PhD): Mm - hmm .
Turn 755, E (Grad): Hmm .
Turn 756, C (PhD): Oh .
Turn 757, B (Professor): Mmm .
Turn 758, C (PhD): That 's interesting .
Turn 759, B (Professor): Yeah , maybe . Well , I mean it looks better , but , I mean , the thing is if {disfmarker} if , uh {disfmarker} if you 're actually asking {disfmarker} you know , if you actually j uh , need to do {disfmarker} place along an FFT , it may be {disfmarker} it may be pushing things .
Turn 760, A (PhD): Yeah .
Turn 761, B (Professor): And {disfmarker} and , uh {disfmarker}
Turn 762, C (PhD): Would you {disfmarker} would you wanna do this kind of , uh , difference thing {vocalsound} after you do spectral subtraction ?
Turn 763, A (PhD): Uh , {vocalsound} maybe .
Turn 764, F (PhD): No . Maybe we can do that .
Turn 765, A (PhD): Mmm .
Turn 766, B (Professor): Hmm . The spectral subtraction is being done at what level ? Is it being done at the level of FFT bins or at the level of , uh , mel spectrum or something ?
Turn 767, A (PhD): Um , I guess it depends .
Turn 768, B (Professor): I mean , how are they doing it ?
Turn 769, A (PhD): How they 're doing it ? Yeah . Um , I guess Ericsson is on the , um , filter bank ,
Turn 770, F (PhD): FFT . Filter bank ,
Turn 771, A (PhD): no ? It 's on the filter bank ,
Turn 772, F (PhD): yeah .
Turn 773, A (PhD): so . So , yeah , probably {disfmarker} I i it {disfmarker} Yeah .
Turn 774, B (Professor): So in that case , it might not make much difference at all .
Turn 775, C (PhD): Seems like you 'd wanna do it on the FFT bins .
Turn 776, B (Professor): Maybe . I mean , certainly it 'd be better .
Turn 777, C (PhD): I I mean , if you were gonna {disfmarker} uh , for {disfmarker} for this purpose , that is .
Turn 778, A (PhD): Mm - hmm .
Turn 779, B (Professor): Yeah .
Turn 780, A (PhD): Mm - hmm .
Turn 781, B (Professor): Yeah . OK .
Turn 782, A (PhD): Mmm .
Turn 783, B (Professor): What else ?
Turn 784, A (PhD): Uh . {vocalsound} Yeah , that 's all . So we 'll perhaps {vocalsound} {vocalsound} {vocalsound} try to convince OGI people to use the new {disfmarker} {vocalsound} the new filters and {disfmarker} Yeah .
Turn 785, B (Professor): OK . Uh , has {disfmarker} has anything happened yet on this business of having some sort of standard , uh , source ,
Turn 786, A (PhD): Uh , not yet
Turn 787, B (Professor): or {disfmarker} ?
Turn 788, A (PhD): but I wi I will {vocalsound} call them and {disfmarker}
Turn 789, B (Professor): OK .
Turn 790, A (PhD): now they are {disfmarker} I think they have more time because they have this {disfmarker} well , Eurospeech deadline is {vocalsound} over
Turn 791, C (PhD): When is the next , um , Aurora {pause} deadline ?
Turn 792, A (PhD): and {disfmarker} It 's , um , in June . Yeah .
Turn 793, C (PhD): June .
Turn 794, B (Professor): Early June , late June , middle June ?
Turn 795, A (PhD): I don't know w
Turn 796, B (Professor): Hmm .
Turn 797, E (Grad): Hmm .
Turn 798, B (Professor): OK . Um , and {pause} he 's been doing all the talking but {disfmarker} but {vocalsound} these {disfmarker} {vocalsound} he 's {disfmarker} he 's , uh {disfmarker}
Turn 799, F (PhD): Yeah .
Turn 800, B (Professor): This is {disfmarker} this by the way a bad thing . We 're trying to get , um , m more female voices in this record as well . So . Make sur make sure Carmen {vocalsound} talks as well . Uh , but has he pretty much been talking about what you 're doing also , and {disfmarker} ?
Turn 801, F (PhD): Oh , I {disfmarker} I am doing this .
Turn 802, B (Professor): Yes .
Turn 803, F (PhD): Yeah , yeah . I don't know . I 'm sorry , but I think that for the recognizer for the meeting recorder that it 's better that I don't speak .
Turn 804, B (Professor): Yeah , well .
Turn 805, F (PhD): Because {disfmarker}
Turn 806, B (Professor): You know , uh , we 'll get {disfmarker} we 'll get to , uh , Spanish voices sometime , and {vocalsound} we do {disfmarker} we want to recognize , {vocalsound} uh , you too .
Turn 807, F (PhD): After the {disfmarker} after , uh , the result for the TI - digits {vocalsound} on the meeting record there will be foreigns people .
Turn 808, A (PhD): Yeah , but {disfmarker}
Turn 809, B (Professor): Oh , no .
Turn 810, C (PhD): Y
Turn 811, B (Professor): We like {disfmarker} we {disfmarker} we 're {disfmarker} we 're {disfmarker} w we are {disfmarker} we 're in the , uh , Bourlard - Hermansky - Morgan , uh , frame of mind . Yeah , we like high error rates . It 's {disfmarker}
Turn 812, A (PhD): Yeah .
Turn 813, B (Professor): That way there 's lots of work to do . So it 's {disfmarker} Uh , anything to talk about ?
Turn 814, D (Grad): N um , not not not much is new . So when I talked about what I 'm planning to do last time , {vocalsound} I said I was , um , going to use Avendano 's method of , um , {vocalsound} using a transformation , um , {vocalsound} to map from long analysis frames which are used for removing reverberation to short analysis frames for feature calculation . He has a trick for doing that {pause} involving viewing the DFT as a matrix . Um , but , uh , um , I decided {vocalsound} not to do that after all because I {disfmarker} I realized to use it I 'd need to have these short analysis frames get plugged directly into the feature computation somehow
Turn 815, B (Professor): Mm - hmm .
Turn 816, D (Grad): and right now I think our feature computation is set to up to , um , {vocalsound} take , um , audio as input , in general . So I decided that I {disfmarker} I 'll do the reverberation removal on the long analysis windows and then just re - synthesize audio and then send that .
Turn 817, B (Professor): This is in order to use the SRI system or something . Right ?
Turn 818, D (Grad): Um , or {disfmarker} or even if I 'm using our system , I was thinking it might be easier to just re - synthesize the audio ,
Turn 819, B (Professor): Yeah ?
Turn 820, D (Grad): because then I could just feacalc as is and I wouldn't have to change the code .
Turn 821, B (Professor): Oh , OK . Yeah . I mean , it 's {disfmarker} um , certainly in a short {disfmarker} short - term this just sounds easier .
Turn 822, D (Grad): Uh - huh .
Turn 823, B (Professor): Yeah . I mean , longer - term if it 's {disfmarker} {vocalsound} if it turns out to be useful , one {disfmarker} one might want to do something else ,
Turn 824, D (Grad): Right . That 's true .
Turn 825, B (Professor): but {disfmarker} Uh , uh , I mean , in {disfmarker} in other words , you {disfmarker} you may be putting other kinds of errors in {pause} from the re - synthesis process .
Turn 826, D (Grad): But {disfmarker} e u From the re - synthesis ? Um ,
Turn 827, B (Professor): Yeah .
Turn 828, D (Grad): O - OK . I don't know anything about re - synthesis . Uh , how likely do you think that is ?
Turn 829, B (Professor): Uh , it depends what you {disfmarker} what you do . I mean , it 's {disfmarker} it 's {disfmarker} it 's , uh , um {disfmarker} Don't know . But anyway it sounds like a reasonable way to go for a {disfmarker} for an initial thing , and we can look at {disfmarker} {vocalsound} at exactly what you end up doing and {disfmarker} and then figure out if there 's some {disfmarker} {vocalsound} something that could be {disfmarker} be hurt by the end part of the process .
Turn 830, D (Grad): OK .
Turn 831, B (Professor): OK . So that 's {disfmarker} That was it , huh ?
Turn 832, D (Grad): That {disfmarker} Yeah , e That 's it , that 's it .
Turn 833, B (Professor): OK . OK .
Turn 834, D (Grad): Uh - huh .
Turn 835, B (Professor): Um , anything to {pause} add ?
Turn 836, E (Grad): Um . Well , I 've been continuing reading . I went off on a little tangent this past week , um , looking at , uh , {vocalsound} uh , modulation s spectrum stuff , um , and {disfmarker} and learning a bit about what {disfmarker} what , um {disfmarker} what it is , and , uh , the importance of it in speech recognition . And I found some {disfmarker} {vocalsound} some , uh , neat papers , {vocalsound} um , historical papers from , {vocalsound} um , {vocalsound} Kanedera , Hermansky , and Arai .
Turn 837, B (Professor): Yeah .
Turn 838, E (Grad): And they {disfmarker} they did a lot of experiments where th where , {vocalsound} um , they take speech {vocalsound} and , um , e they modify {vocalsound} the , uh {disfmarker} they {disfmarker} they {disfmarker} they measure the relative importance of having different , um , portions of the modulation spectrum intact .
Turn 839, B (Professor): Yeah .
Turn 840, E (Grad): And they find that the {disfmarker} the spectrum between one and sixteen hertz in the modulation {vocalsound} is , uh {disfmarker} is im important for speech recognition .
Turn 841, B (Professor): Sure . I mean , this sort of goes back to earlier stuff by Drullman .
Turn 842, E (Grad): Um .
Turn 843, B (Professor): And {disfmarker} and , uh , the {disfmarker} the MSG features were sort of built up {vocalsound} with this notion {disfmarker}
Turn 844, E (Grad): Yeah . Right .
Turn 845, B (Professor): But , I guess , I thought you had brought this up in the context of , um , targets somehow .
Turn 846, E (Grad): Right .
Turn 847, B (Professor): But i m
Turn 848, E (Grad): Um {disfmarker}
Turn 849, B (Professor): i it 's not {disfmarker} I mean , they 're sort of not in the same kind of category as , say , a phonetic target or a syllabic target
Turn 850, E (Grad): Mmm . Mm - hmm .
Turn 851, B (Professor): or a {disfmarker}
Turn 852, E (Grad): Um , I was thinking more like using them as {disfmarker} as the inputs to {disfmarker} to the detectors .
Turn 853, B (Professor): or a feature or something . Oh , I see . Well , that 's sort of what MSG does .
Turn 854, E (Grad): Yeah . Yeah .
Turn 855, B (Professor): Right ? So it 's {disfmarker}
Turn 856, E (Grad): Mm - hmm .
Turn 857, B (Professor): But {disfmarker} but , uh {disfmarker}
Turn 858, E (Grad): S
Turn 859, B (Professor): Yeah .
Turn 860, E (Grad): Yeah .
Turn 861, B (Professor): Anyway , we 'll talk more about it later .
Turn 862, E (Grad): OK .
Turn 863, B (Professor): Yeah .
Turn 864, E (Grad): We can talk more about it later .
Turn 865, B (Professor): Yeah . Yeah .
Turn 866, E (Grad): Yeah .
Turn 867, B (Professor): So maybe , {vocalsound} le
Turn 868, C (PhD): Should we do digits ?
Turn 869, B (Professor): let 's do digits . Let you {disfmarker} you start .
Turn 870, D (Grad): Oh , OK .
Turn 871, E (Grad): L fifty .
Turn 872, A (PhD): Right .
