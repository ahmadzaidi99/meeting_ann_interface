{"metadata": {"meeting_name": "Bro027"}, "turns": [{"turn": 1, "name": "PhD", "id": "A", "contribution": " OK , we 're going ."}, {"turn": 2, "name": "PhD", "id": "C", "contribution": " Eight , eight ?"}, {"turn": 3, "name": "PhD", "id": "D", "contribution": " This is three ."}, {"turn": 4, "name": "PhD", "id": "C", "contribution": " Three ."}, {"turn": 5, "name": "PhD", "id": "D", "contribution": " Yep . Yep ."}, {"turn": 6, "name": "Professor", "id": "B", "contribution": " Test . Hmm . Let 's see . Move it bit . Test ? Test ? OK , I guess it 's alright . So , let 's see . Yeah , Barry 's not here and Dave 's not here . Um , I can say about {disfmarker} just q just quickly to get through it , that Dave and I submitted this ASRU ."}, {"turn": 7, "name": "PhD", "id": "A", "contribution": " This is for ASRU ."}, {"turn": 8, "name": "Professor", "id": "B", "contribution": " Yeah . So . Um . Yeah , it 's {disfmarker} it 's interesting . I mean , basically we 're dealing with rever reverberation , and , um , when we deal with pure reverberation , the technique he 's using works really , really well . Uh , and when they had the reverberation here , uh , we 'll measure the signal - to - noise ratio and it 's , uh , about nine DB . So ,"}, {"turn": 9, "name": "PhD", "id": "D", "contribution": " Hmm ."}, {"turn": 10, "name": "Professor", "id": "B", "contribution": " um ,"}, {"turn": 11, "name": "PhD", "id": "A", "contribution": " You mean , from the actual , uh , recordings ?"}, {"turn": 12, "name": "Professor", "id": "B", "contribution": " a fair amount of {disfmarker}"}, {"turn": 13, "name": "PhD", "id": "D", "contribution": " k"}, {"turn": 14, "name": "PhD", "id": "A", "contribution": " It 's nine DB ?"}, {"turn": 15, "name": "Professor", "id": "B", "contribution": " Yeah . Yeah . Um {disfmarker} And actually it brought up a question which may be relevant to the Aurora stuff too . Um , I know that when you figured out the filters that we 're using for the Mel scale , there was some experimentation that went on at {disfmarker} at , uh {disfmarker} at OGI . Um , but one of the differences that we found between the two systems that we were using , {comment} the {disfmarker} the Aurora HTK system baseline system {comment} and the system that we were {disfmarker} the {disfmarker} the uh , other system we were using , the uh , the SRI system , was that the SRI system had maybe a , um , hundred hertz high - pass . And the , uh , Aurora HTK , it was like twenty ."}, {"turn": 16, "name": "PhD", "id": "D", "contribution": " Yep . S sixty - four ."}, {"turn": 17, "name": "Professor", "id": "B", "contribution": " Uh ."}, {"turn": 18, "name": "PhD", "id": "D", "contribution": " S sixty - four ."}, {"turn": 19, "name": "Professor", "id": "B", "contribution": " Sixty - four ? Uh ."}, {"turn": 20, "name": "PhD", "id": "D", "contribution": " Yeah , if you 're using the baseline ."}, {"turn": 21, "name": "Professor", "id": "B", "contribution": " Is that the ba band center ?"}, {"turn": 22, "name": "PhD", "id": "D", "contribution": " No , the edge ."}, {"turn": 23, "name": "Professor", "id": "B", "contribution": " The edge is really , uh , sixty - four ?"}, {"turn": 24, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 25, "name": "Professor", "id": "B", "contribution": " For some reason , uh , Dave thought it was twenty ,"}, {"turn": 26, "name": "PhD", "id": "D", "contribution": "  So the , uh , center would be somewhere around like hundred"}, {"turn": 27, "name": "Professor", "id": "B", "contribution": " but ."}, {"turn": 28, "name": "PhD", "id": "D", "contribution": " and {disfmarker} hundred and {disfmarker} hundred {disfmarker} hundred and {disfmarker} maybe {disfmarker} it 's like {disfmarker} fi hundred hertz ."}, {"turn": 29, "name": "Professor", "id": "B", "contribution": " But do you know , for instance , h how far down it would be at twenty hertz ? What the {disfmarker} how much rejection would there be at twenty hertz , let 's say ?"}, {"turn": 30, "name": "PhD", "id": "D", "contribution": " At twenty hertz ."}, {"turn": 31, "name": "Professor", "id": "B", "contribution": " Yeah , any idea what the curve looks like ?"}, {"turn": 32, "name": "PhD", "id": "D", "contribution": " Twenty hertz frequency {disfmarker} Oh , it 's {disfmarker} it 's zero at twenty hertz , right ? The filter ?"}, {"turn": 33, "name": "PhD", "id": "C", "contribution": " Yea - actually , the left edge of the first filter is at sixty - four ."}, {"turn": 34, "name": "PhD", "id": "D", "contribution": " Sixt - s sixty - four ."}, {"turn": 35, "name": "PhD", "id": "C", "contribution": " So {disfmarker}"}, {"turn": 36, "name": "PhD", "id": "D", "contribution": " So anything less than sixty - four is zero ."}, {"turn": 37, "name": "PhD", "id": "C", "contribution": " Mmm ."}, {"turn": 38, "name": "Professor", "id": "B", "contribution": " It 's actually set to zero ? What kind of filter is that ?"}, {"turn": 39, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 40, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 41, "name": "Professor", "id": "B", "contribution": " Is this {disfmarker} oh , from the {disfmarker} from {disfmarker}"}, {"turn": 42, "name": "PhD", "id": "C", "contribution": " It {disfmarker} This is the filter bank in the frequency domain that starts at sixty - four ."}, {"turn": 43, "name": "Professor", "id": "B", "contribution": " Oh , so you , uh {disfmarker} so you really set it to zero , the FFT ?"}, {"turn": 44, "name": "PhD", "id": "D", "contribution": " Yeah ,"}, {"turn": 45, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 46, "name": "PhD", "id": "D", "contribution": " yeah . So it 's {disfmarker} it 's a weight on the ball spectrum . Triangular weighting ."}, {"turn": 47, "name": "Professor", "id": "B", "contribution": " Right . OK . Um {disfmarker} OK . So that 's {disfmarker} that 's a little different than Dave thought , I think . But {disfmarker} but , um , still , it 's possible that we 're getting in some more noise . So I wonder , is it {disfmarker} @ @ Was there {disfmarker} their experimentation with , uh , say , throwing away that filter or something ? And , uh {disfmarker}"}, {"turn": 48, "name": "PhD", "id": "D", "contribution": " Uh , throwing away the first ?"}, {"turn": 49, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 50, "name": "PhD", "id": "D", "contribution": " Um , yeah , we {disfmarker} we 've tried including the full {disfmarker} full bank . Right ? From zero to four K ."}, {"turn": 51, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 52, "name": "PhD", "id": "D", "contribution": " And that 's always worse than using sixty - four hertz ."}, {"turn": 53, "name": "Professor", "id": "B", "contribution": " Right , but the question is , whether sixty - four hertz is {disfmarker} is , uh , too , uh , low ."}, {"turn": 54, "name": "PhD", "id": "D", "contribution": " Yeah , I mean , make it a hundred or so ?"}, {"turn": 55, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 56, "name": "PhD", "id": "D", "contribution": " I t I think I 've tried a hundred and it was more or less the same , or slightly worse ."}, {"turn": 57, "name": "Professor", "id": "B", "contribution": " On what test set ?"}, {"turn": 58, "name": "PhD", "id": "D", "contribution": " On the same , uh , SpeechDat - Car , Aurora ."}, {"turn": 59, "name": "Professor", "id": "B", "contribution": " Um , it was on the SpeechDat - Car ."}, {"turn": 60, "name": "PhD", "id": "D", "contribution": " Yeah . So I tried a hundred to four K . Yeah ."}, {"turn": 61, "name": "Professor", "id": "B", "contribution": " Um ,"}, {"turn": 62, "name": "PhD", "id": "D", "contribution": " So it was {disfmarker}"}, {"turn": 63, "name": "Professor", "id": "B", "contribution": " and on {disfmarker} and on the , um , um , {vocalsound} TI - digits also ?"}, {"turn": 64, "name": "PhD", "id": "D", "contribution": " No , no , no . I think I just tried it on SpeechDat - Car ."}, {"turn": 65, "name": "Professor", "id": "B", "contribution": " Mmm . That 'd be something to look at sometime because what , um , eh , he was looking at was performance in this room ."}, {"turn": 66, "name": "PhD", "id": "D", "contribution": " Mm - hmm ."}, {"turn": 67, "name": "Professor", "id": "B", "contribution": " Would that be more like {disfmarker} Well , you 'd think that 'd be more like SpeechDat - Car , I guess , in terms of the noise . The SpeechDat - Car is more , uh , sort of roughly stationary , a lot of it . And {disfmarker} and TI - digits maybe is not so much as {disfmarker}"}, {"turn": 68, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 69, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 70, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 71, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 72, "name": "Professor", "id": "B", "contribution": " Mm - hmm . OK . Well , maybe it 's not a big deal . But , um {disfmarker} Anyway , that was just something we wondered about . But , um , uh , certainly a lot of the noise , uh , is , uh , below a hundred hertz . Uh , the signal - to - noise ratio , you know , looks a fair amount better if you {disfmarker} if you high - pass filter it from this room ."}, {"turn": 73, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 74, "name": "Professor", "id": "B", "contribution": " But , um {disfmarker} but it 's still pretty noisy . Even {disfmarker} even for a hundred hertz up , it 's {disfmarker} it 's still fairly noisy . The signal - to - noise ratio is {disfmarker} is {disfmarker} is actually still pretty bad ."}, {"turn": 75, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 76, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 77, "name": "Professor", "id": "B", "contribution": " So , um , I mean , the main {disfmarker} the {disfmarker} the {disfmarker}"}, {"turn": 78, "name": "PhD", "id": "A", "contribution": " So that 's on th that 's on the f the far field ones though , right ? Yeah ."}, {"turn": 79, "name": "Professor", "id": "B", "contribution": " Yeah , that 's on the far field . Yeah , the near field 's pretty good ."}, {"turn": 80, "name": "PhD", "id": "A", "contribution": " So wha what is , uh {disfmarker} what 's causing that ?"}, {"turn": 81, "name": "Professor", "id": "B", "contribution": " Well , we got a {disfmarker} a video projector in here , uh , and , uh {disfmarker} which we keep on during every {disfmarker} every session we record ,"}, {"turn": 82, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 83, "name": "Professor", "id": "B", "contribution": " which , you know , I {disfmarker} I {disfmarker} w we were aware of"}, {"turn": 84, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 85, "name": "Professor", "id": "B", "contribution": " but {disfmarker} but we thought it wasn't a bad thing ."}, {"turn": 86, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 87, "name": "Professor", "id": "B", "contribution": " I mean , that 's a nice noise source . Uh , and there 's also the , uh {disfmarker} uh , air conditioning ."}, {"turn": 88, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 89, "name": "Professor", "id": "B", "contribution": " Which , uh , you know , is a pretty low frequency kind of thing ."}, {"turn": 90, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 91, "name": "Professor", "id": "B", "contribution": " But {disfmarker} but , uh {disfmarker} So , those are {disfmarker} those are major components , I think ,"}, {"turn": 92, "name": "PhD", "id": "A", "contribution": " I see ."}, {"turn": 93, "name": "Professor", "id": "B", "contribution": " uh , for the stationary kind of stuff ."}, {"turn": 94, "name": "PhD", "id": "A", "contribution": " Mmm ."}, {"turn": 95, "name": "Professor", "id": "B", "contribution": " Um , but , um , it , uh {disfmarker} I guess , I {disfmarker} maybe I said this last week too but it {disfmarker} it {disfmarker} it really became apparent to us that we need to {disfmarker} to take account of noise . And , uh , so I think when {disfmarker} when he gets done with his prelim study I think {vocalsound} one of the next things we 'd want to do is to take this , uh {disfmarker} uh , noise , uh , processing stuff and {disfmarker} and , uh {disfmarker} uh , synthesize some speech from it ."}, {"turn": 96, "name": "PhD", "id": "A", "contribution": " When are his prelims ?"}, {"turn": 97, "name": "Professor", "id": "B", "contribution": " And then {disfmarker} Um , I think in about , um , a little less than two weeks ."}, {"turn": 98, "name": "PhD", "id": "A", "contribution": " Oh . Wow ."}, {"turn": 99, "name": "Professor", "id": "B", "contribution": " Yeah . Yeah . So . Uh , it might even be sooner . Uh , let 's see , this is the sixteenth , seventeenth ? Yeah , I don't know if he 's before {disfmarker} It might even be in a week ."}, {"turn": 100, "name": "PhD", "id": "A", "contribution": " So , I"}, {"turn": 101, "name": "Professor", "id": "B", "contribution": " A week ,"}, {"turn": 102, "name": "PhD", "id": "A", "contribution": " Huh . I {disfmarker} I guessed that they were gonna do it some time during the semester"}, {"turn": 103, "name": "Professor", "id": "B", "contribution": " week and a half ."}, {"turn": 104, "name": "PhD", "id": "A", "contribution": " but they 'll do it any time , huh ?"}, {"turn": 105, "name": "Professor", "id": "B", "contribution": " They seem to be {disfmarker} Well , the semester actually is starting up ."}, {"turn": 106, "name": "PhD", "id": "A", "contribution": " Is it already ?"}, {"turn": 107, "name": "Professor", "id": "B", "contribution": " Yeah , the semester 's late {disfmarker} late August they start here ."}, {"turn": 108, "name": "PhD", "id": "A", "contribution": " Yikes ."}, {"turn": 109, "name": "Professor", "id": "B", "contribution": " So they do it right at the beginning of the semester ."}, {"turn": 110, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 111, "name": "Professor", "id": "B", "contribution": " Yeah . So , uh {disfmarker} Yep . I mean , that {disfmarker} that was sort of one {disfmarker} I mean , the overall results seemed to be first place in {disfmarker} in {disfmarker} in the case of either , um , artificial reverberation or a modest sized training set . Uh , either way , uh , i uh , it helped a lot . And {disfmarker} But if you had a {disfmarker} a really big training set , a recognizer , uh , system that was capable of taking advantage of a really large training set {disfmarker} I thought that {disfmarker} One thing with the HTK is that is has the {disfmarker} as we 're using {disfmarker} the configuration we 're using is w s is {disfmarker} being bound by the terms of Aurora , we have all those parameters just set as they are . So even if we had a hundred times as much data , we wouldn't go out to , you know , ten or t or a hundred times as many Gaussians or anything . So , um , it 's kind of hard to take advantage of {disfmarker} of {disfmarker} of big chunks of data . Uh , whereas the other one does sort of expand as you have more training data ."}, {"turn": 112, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 113, "name": "PhD", "id": "D", "contribution": " Mmm , yeah ."}, {"turn": 114, "name": "Professor", "id": "B", "contribution": " It does it automatically , actually . And so , um , uh , that one really benefited from the larger set . And it was also a diverse set with different noises and so forth . Uh , so , um , that , uh {disfmarker} that seemed to be {disfmarker} So , if you have that {disfmarker} that better recognizer that can {disfmarker} that can build up more parameters , and if you , um , have the natural room , which in this case has a p a pretty bad signal - to - noise ratio , then in that case , um , the right thing to do is just do {disfmarker} u use speaker adaptation . And {disfmarker} and not bother with {disfmarker} with this acoustic , uh , processing . But I think that that would not be true if we did some explicit noise - processing as well as , uh , the convolutional kind of things we were doing ."}, {"turn": 115, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 116, "name": "Professor", "id": "B", "contribution": " So . That 's sort of what we found ."}, {"turn": 117, "name": "PhD", "id": "D", "contribution": " Hmm ."}, {"turn": 118, "name": "PhD", "id": "A", "contribution": " I , um {disfmarker} {vocalsound} uh , started working on the uh {disfmarker} Mississippi State recognizer . So , I got in touch with Joe and {disfmarker} and , uh , from your email and things like that ."}, {"turn": 119, "name": "PhD", "id": "D", "contribution": " Oh , OK ."}, {"turn": 120, "name": "PhD", "id": "A", "contribution": " And , uh , they added me to the list {disfmarker} uh , the mailing list ."}, {"turn": 121, "name": "PhD", "id": "D", "contribution": " OK , great ."}, {"turn": 122, "name": "PhD", "id": "A", "contribution": " And he gave me all of the pointers and everything that I needed . And so I downloaded the , um {disfmarker} There were two things , uh , that they had to download . One was the , uh , I guess the software . And another wad {disfmarker} was a , um , sort of like a sample {disfmarker} a sample run . So I downloaded the software and compiled all of that . And it compiled fine ."}, {"turn": 123, "name": "PhD", "id": "D", "contribution": " Eight ."}, {"turn": 124, "name": "PhD", "id": "A", "contribution": " No problems ."}, {"turn": 125, "name": "PhD", "id": "D", "contribution": " Oh , eh , great ."}, {"turn": 126, "name": "PhD", "id": "A", "contribution": " And , um , I grabbed the sample stuff but I haven't , uh , compiled it ."}, {"turn": 127, "name": "PhD", "id": "D", "contribution": " That sample was released only yesterday or the day before , right ?"}, {"turn": 128, "name": "PhD", "id": "A", "contribution": " No {disfmarker} Well , I haven't grabbed that one yet . So there 's two ."}, {"turn": 129, "name": "PhD", "id": "D", "contribution": " Oh , there is another short sample set {disfmarker}"}, {"turn": 130, "name": "PhD", "id": "A", "contribution": " There was another short one , yeah ."}, {"turn": 131, "name": "PhD", "id": "D", "contribution": " o o sample ."}, {"turn": 132, "name": "PhD", "id": "A", "contribution": " And so I haven't grabbed the latest one that he just , uh , put out yet ."}, {"turn": 133, "name": "PhD", "id": "D", "contribution": " OK . Oh , OK . F Yeah , OK ."}, {"turn": 134, "name": "PhD", "id": "A", "contribution": " So . Um , but , the software seemed to compile fine and everything , so . And , um , So ."}, {"turn": 135, "name": "Professor", "id": "B", "contribution": " Is there any word yet about the issues about , um , adjustments for different feature sets or anything ?"}, {"turn": 136, "name": "PhD", "id": "A", "contribution": " No , I {disfmarker} I d You asked me to write to him and I think I forgot to ask him about that . Or if I did ask him , he didn't reply ."}, {"turn": 137, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 138, "name": "PhD", "id": "A", "contribution": " I {disfmarker} I don't remember yet . Uh , I 'll {disfmarker} I 'll d I 'll double check that and ask him again ."}, {"turn": 139, "name": "Professor", "id": "B", "contribution": " Yeah . Yeah , it 's like that {disfmarker} that could r turn out to be an important issue for us ."}, {"turn": 140, "name": "PhD", "id": "D", "contribution": " Hmm . Mmm ."}, {"turn": 141, "name": "PhD", "id": "A", "contribution": " Yeah . Yeah ."}, {"turn": 142, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 143, "name": "PhD", "id": "D", "contribution": " Cuz they have it {disfmarker}"}, {"turn": 144, "name": "PhD", "id": "A", "contribution": " Maybe I 'll send it to the list . Yeah ."}, {"turn": 145, "name": "PhD", "id": "D", "contribution": " Cuz they have , uh , already frozen those in i insertion penalties and all those stuff is what {disfmarker} I feel . Because they have this document explaining the recognizer ."}, {"turn": 146, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 147, "name": "PhD", "id": "D", "contribution": " And they have these tables with , uh , various language model weights , insertion penalties ."}, {"turn": 148, "name": "PhD", "id": "A", "contribution": " OK , I haven't seen that one yet ."}, {"turn": 149, "name": "PhD", "id": "D", "contribution": " u"}, {"turn": 150, "name": "PhD", "id": "A", "contribution": " So ."}, {"turn": 151, "name": "PhD", "id": "D", "contribution": " Uh , it 's th it 's there on that web ."}, {"turn": 152, "name": "PhD", "id": "A", "contribution": " OK ."}, {"turn": 153, "name": "PhD", "id": "D", "contribution": " And , uh , on that , I mean , they have run some experiments using various insertion penalties and all those {disfmarker}"}, {"turn": 154, "name": "PhD", "id": "A", "contribution": " And so they 've picked {disfmarker} the values ."}, {"turn": 155, "name": "PhD", "id": "D", "contribution": " Yeah , I think they pi p"}, {"turn": 156, "name": "PhD", "id": "A", "contribution": " Oh , OK ."}, {"turn": 157, "name": "PhD", "id": "D", "contribution": " yeah , they picked the values from {disfmarker}"}, {"turn": 158, "name": "PhD", "id": "A", "contribution": " OK ."}, {"turn": 159, "name": "Professor", "id": "B", "contribution": " For r w what test set ?"}, {"turn": 160, "name": "PhD", "id": "D", "contribution": " Uh , p the one that they have reported is a NIST evaluation , Wall Street Journal ."}, {"turn": 161, "name": "Professor", "id": "B", "contribution": " But that has nothing to do with what we 're testing on , right ?"}, {"turn": 162, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 163, "name": "PhD", "id": "D", "contribution": " You know . No . So they 're , like {disfmarker} um {disfmarker} So they are actually trying to , uh , fix that {disfmarker} those values using the clean , uh , training part of the Wall Street Journal . Which is {disfmarker} I mean , the Aurora . Aurora has a clean subset ."}, {"turn": 164, "name": "Professor", "id": "B", "contribution": " Right ."}, {"turn": 165, "name": "PhD", "id": "D", "contribution": " I mean , they want to train it and then this {disfmarker} they 're going to run some evaluations ."}, {"turn": 166, "name": "Professor", "id": "B", "contribution": " So they 're set they 're setting it based on that ?"}, {"turn": 167, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 168, "name": "Professor", "id": "B", "contribution": " OK . So now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we can't modify these parameters ."}, {"turn": 169, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 170, "name": "Professor", "id": "B", "contribution": " But , um ,"}, {"turn": 171, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 172, "name": "Professor", "id": "B", "contribution": " uh {disfmarker} but it 's still worth , I think , just {disfmarker} since {disfmarker} you know , just chatting with Joe about the issue ."}, {"turn": 173, "name": "PhD", "id": "A", "contribution": " Yeah , OK . Do you think that 's something I should just send to him"}, {"turn": 174, "name": "Professor", "id": "B", "contribution": " Um {disfmarker}"}, {"turn": 175, "name": "PhD", "id": "A", "contribution": " or do you think I should send it to this {disfmarker} there 's an {disfmarker} a m a mailing list ."}, {"turn": 176, "name": "Professor", "id": "B", "contribution": " Well , it 's not a secret . I mean , we 're , you know , certainly willing to talk about it with everybody , but I think {disfmarker} I think that , um {disfmarker} um , it 's probably best to start talking with him just to {disfmarker}"}, {"turn": 177, "name": "PhD", "id": "A", "contribution": " OK ."}, {"turn": 178, "name": "Professor", "id": "B", "contribution": " Uh @ @ {comment} you know , it 's a dialogue between two of you about what {disfmarker} you know , what does he think about this and what {disfmarker} what {disfmarker} you know {disfmarker} what could be done about it ."}, {"turn": 179, "name": "PhD", "id": "A", "contribution": " Yeah . OK ."}, {"turn": 180, "name": "Professor", "id": "B", "contribution": " Um , if you get ten people in {disfmarker} involved in it there 'll be a lot of perspectives based on , you know , how {disfmarker}"}, {"turn": 181, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 182, "name": "Professor", "id": "B", "contribution": " you know ."}, {"turn": 183, "name": "PhD", "id": "A", "contribution": " Right ."}, {"turn": 184, "name": "Professor", "id": "B", "contribution": " Uh {disfmarker} But , I mean , I think it all should come up eventually ,"}, {"turn": 185, "name": "PhD", "id": "A", "contribution": " OK ."}, {"turn": 186, "name": "Professor", "id": "B", "contribution": " but if {disfmarker} if {disfmarker} if there is any , uh , uh , way to move in {disfmarker} a way that would {disfmarker} that would , you know , be more open to different kinds of features . But if {disfmarker} if , uh {disfmarker} if there isn't , and it 's just kind of shut down and {disfmarker} and then also there 's probably not worthwhile bringing it into a larger forum where {disfmarker} where political issues will come in ."}, {"turn": 187, "name": "PhD", "id": "A", "contribution": " Yeah . OK ."}, {"turn": 188, "name": "PhD", "id": "D", "contribution": " Oh . So this is now {disfmarker} it 's {disfmarker} it 's compiled under Solaris ?"}, {"turn": 189, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 190, "name": "PhD", "id": "D", "contribution": " Yeah , OK ."}, {"turn": 191, "name": "PhD", "id": "A", "contribution": " Yep ."}, {"turn": 192, "name": "PhD", "id": "D", "contribution": " Because he {disfmarker} there was some mail r saying that it 's {disfmarker} may not be stable for Linux and all those ."}, {"turn": 193, "name": "PhD", "id": "A", "contribution": " Yeah . Yeah , i that was a particular version ."}, {"turn": 194, "name": "PhD", "id": "D", "contribution": " SUSI"}, {"turn": 195, "name": "PhD", "id": "A", "contribution": " Yeah , SUSI or whatever it was"}, {"turn": 196, "name": "PhD", "id": "D", "contribution": " yeah . Yeah , yeah ."}, {"turn": 197, "name": "PhD", "id": "A", "contribution": " but we don't have that ."}, {"turn": 198, "name": "PhD", "id": "D", "contribution": " Yeah , OK ."}, {"turn": 199, "name": "PhD", "id": "A", "contribution": " So . Should be OK ."}, {"turn": 200, "name": "PhD", "id": "D", "contribution": " OK , that 's fine ."}, {"turn": 201, "name": "PhD", "id": "A", "contribution": " Yeah , it compiled fine actually ."}, {"turn": 202, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 203, "name": "PhD", "id": "A", "contribution": " No {disfmarker} no errors . Nothing . So ."}, {"turn": 204, "name": "Professor", "id": "B", "contribution": " Uh , this is slightly off topic"}, {"turn": 205, "name": "PhD", "id": "D", "contribution": " That 's good ."}, {"turn": 206, "name": "Professor", "id": "B", "contribution": " but , uh , I noticed , just glancing at the , uh , Hopkins workshop , uh , web site that , uh , um {disfmarker} one of the thing I don't know {disfmarker} Well , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together a {disfmarker} a , uh , tool kit for doing , uh r um , arbitrary graphical models for , uh , speech recognition ."}, {"turn": 207, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 208, "name": "Professor", "id": "B", "contribution": " So {disfmarker} And Jeff , uh {disfmarker} the two Jeffs were"}, {"turn": 209, "name": "PhD", "id": "A", "contribution": " Who 's the second Jeff ?"}, {"turn": 210, "name": "Professor", "id": "B", "contribution": " Uh {disfmarker} Oh , uh , do you know Geoff Zweig ?"}, {"turn": 211, "name": "PhD", "id": "A", "contribution": " No ."}, {"turn": 212, "name": "Professor", "id": "B", "contribution": " Oh . Uh , he {disfmarker} he , uh {disfmarker} he was here for a couple years"}, {"turn": 213, "name": "PhD", "id": "A", "contribution": " Oh , OK ."}, {"turn": 214, "name": "Professor", "id": "B", "contribution": " and he , uh {disfmarker} got his PHD . He {disfmarker} And he 's , uh , been at IBM for the last couple years ."}, {"turn": 215, "name": "PhD", "id": "A", "contribution": " Oh , OK ."}, {"turn": 216, "name": "Professor", "id": "B", "contribution": " So ."}, {"turn": 217, "name": "PhD", "id": "A", "contribution": " Wow . That would be neat ."}, {"turn": 218, "name": "Professor", "id": "B", "contribution": " Uh , so he did {disfmarker} he did his PHD on dynamic Bayes - nets , uh , for {disfmarker} for speech recognition . He had some continuity built into the model , presumably to handle some , um , inertia in the {disfmarker} in the production system , and , um {disfmarker}"}, {"turn": 219, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 220, "name": "Professor", "id": "B", "contribution": " So ."}, {"turn": 221, "name": "PhD", "id": "D", "contribution": " Hmm ."}, {"turn": 222, "name": "PhD", "id": "C", "contribution": " Um , I 've been playing with , first , the , um , VAD . Um , {vocalsound} so it 's exactly the same approach , but the features that the VAD neural network use are , uh , MFCC after noise compensation . Oh , I think I have the results ."}, {"turn": 223, "name": "Professor", "id": "B", "contribution": " What was it using before ?"}, {"turn": 224, "name": "PhD", "id": "C", "contribution": " Before it was just P L"}, {"turn": 225, "name": "PhD", "id": "D", "contribution": ""}, {"turn": 226, "name": "PhD", "id": "C", "contribution": " So ."}, {"turn": 227, "name": "PhD", "id": "D", "contribution": " Yeah , it was actually {disfmarker} No . Not {disfmarker} I mean , it was just the noisy features I guess ."}, {"turn": 228, "name": "PhD", "id": "C", "contribution": " Yeah ,"}, {"turn": 229, "name": "PhD", "id": "D", "contribution": " Yeah , yeah , yeah ,"}, {"turn": 230, "name": "PhD", "id": "C", "contribution": " noisy {disfmarker} noisy features ."}, {"turn": 231, "name": "PhD", "id": "D", "contribution": " not compensated ."}, {"turn": 232, "name": "PhD", "id": "C", "contribution": " Um {disfmarker} This is what we get after {disfmarker} This {disfmarker} So , actually , we , yeah , here the features are noise compensated and there is also the LDA filter . Um , and then it 's a pretty small neural network which use , um , {vocalsound} nine frames of {disfmarker} of six features from C - zero to C - fives , plus the first derivatives . And it has one hundred hidden units ."}, {"turn": 233, "name": "PhD", "id": "A", "contribution": " Is that nine frames u s uh , centered around the current frame ? Or {disfmarker}"}, {"turn": 234, "name": "PhD", "id": "C", "contribution": " Yeah . Mm - hmm ."}, {"turn": 235, "name": "Professor", "id": "B", "contribution": " S so , I 'm {disfmarker} I 'm sorry , there 's {disfmarker} there 's {disfmarker} there 's how many {disfmarker} how many inputs ?"}, {"turn": 236, "name": "PhD", "id": "C", "contribution": " So it 's twelve times nine ."}, {"turn": 237, "name": "Professor", "id": "B", "contribution": " Twelve times nine inputs , and a hundred , uh , hidden ."}, {"turn": 238, "name": "PhD", "id": "C", "contribution": " Hidden and"}, {"turn": 239, "name": "PhD", "id": "D", "contribution": " Two outputs ."}, {"turn": 240, "name": "PhD", "id": "C", "contribution": " two outputs ."}, {"turn": 241, "name": "Professor", "id": "B", "contribution": " Two outputs . OK . So I guess about eleven thousand parameters , which {disfmarker} actually shouldn't be a problem , even in {disfmarker} in small phones . Yeah ."}, {"turn": 242, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 243, "name": "PhD", "id": "A", "contribution": " So , I 'm {disfmarker} I 'm {disfmarker} s so what is different between this and {disfmarker} and what you {disfmarker}"}, {"turn": 244, "name": "PhD", "id": "C", "contribution": " It should be OK . So the previous syst It 's based on the system that has a fifty - three point sixty - six percent improvement . It 's the same system . The only thing that changed is the n a p eh {disfmarker} a es the estimation of the silence probabilities ."}, {"turn": 245, "name": "PhD", "id": "A", "contribution": " Ah . OK ."}, {"turn": 246, "name": "PhD", "id": "C", "contribution": " Which now is based on , uh , cleaned features ."}, {"turn": 247, "name": "Professor", "id": "B", "contribution": " And , it 's a l it 's a lot better ."}, {"turn": 248, "name": "PhD", "id": "A", "contribution": " Wow ."}, {"turn": 249, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 250, "name": "Professor", "id": "B", "contribution": " That 's great ."}, {"turn": 251, "name": "PhD", "id": "C", "contribution": " Um {disfmarker} So it 's {disfmarker} it 's not bad , but the problem is still that the latency is too large ."}, {"turn": 252, "name": "Professor", "id": "B", "contribution": " What 's the latency ?"}, {"turn": 253, "name": "PhD", "id": "C", "contribution": " Because {disfmarker} um {disfmarker} the {disfmarker} the latency of the VAD is two hundred and twenty milliseconds . And , uh , the VAD is used uh , i for on - line normalization , and it 's used before the delta computation . So if you add these components it goes t to a hundred and seventy , right ?"}, {"turn": 254, "name": "Professor", "id": "B", "contribution": " I {disfmarker} I 'm confused . You started off with two - twenty and you ended up with one - seventy ?"}, {"turn": 255, "name": "PhD", "id": "C", "contribution": " With two an two hundred and seventy ."}, {"turn": 256, "name": "Professor", "id": "B", "contribution": " Two - seventy ."}, {"turn": 257, "name": "PhD", "id": "C", "contribution": " If {disfmarker} Yeah , if you add the c delta comp delta computation"}, {"turn": 258, "name": "Professor", "id": "B", "contribution": " Oh ."}, {"turn": 259, "name": "PhD", "id": "C", "contribution": " which is done afterwards . Um {disfmarker}"}, {"turn": 260, "name": "Professor", "id": "B", "contribution": " So it 's two - twenty . I the is this {disfmarker} are these twenty - millisecond frames ? Is that why ? Is it after downsampling ? or {disfmarker}"}, {"turn": 261, "name": "PhD", "id": "C", "contribution": " The two - twenty is one hundred milliseconds for the um {disfmarker} No , it 's forty milliseconds for t for the , uh , uh , cleaning of the speech . Um {disfmarker} then there is , um , the neural network which use nine frames . So it adds forty milliseconds ."}, {"turn": 262, "name": "Professor", "id": "B", "contribution": " a OK ."}, {"turn": 263, "name": "PhD", "id": "C", "contribution": " Um , after that , um , you have the um , filtering of the silence probabilities . Which is a million filter it , and it creates a one hundred milliseconds delay . So , um {disfmarker}"}, {"turn": 264, "name": "Professor", "id": "B", "contribution": ""}, {"turn": 265, "name": "PhD", "id": "D", "contribution": " Plus there is a delta at the input ."}, {"turn": 266, "name": "PhD", "id": "C", "contribution": " Yeah , and there is the delta at the input which is ,"}, {"turn": 267, "name": "Professor", "id": "B", "contribution": " One hundred milliseconds for smoothing ."}, {"turn": 268, "name": "PhD", "id": "C", "contribution": " um {disfmarker} So it 's {disfmarker} @ @ {disfmarker}"}, {"turn": 269, "name": "Professor", "id": "B", "contribution": " Uh , median ."}, {"turn": 270, "name": "PhD", "id": "C", "contribution": ""}, {"turn": 271, "name": "PhD", "id": "D", "contribution": " It 's like forty plus {disfmarker} forty {disfmarker} plus {disfmarker}"}, {"turn": 272, "name": "Professor", "id": "B", "contribution": " And then forty {disfmarker}"}, {"turn": 273, "name": "PhD", "id": "C", "contribution": " Mmm . Forty {disfmarker} This forty plus twenty , plus one hundred ."}, {"turn": 274, "name": "Professor", "id": "B", "contribution": " forty p"}, {"turn": 275, "name": "PhD", "id": "C", "contribution": " Uh {disfmarker}"}, {"turn": 276, "name": "PhD", "id": "D", "contribution": " So it 's two hundred actually ."}, {"turn": 277, "name": "PhD", "id": "C", "contribution": " Yeah , there are twenty that comes from {disfmarker} There is ten that comes from the LDA filters also . Right ?"}, {"turn": 278, "name": "PhD", "id": "D", "contribution": " Oh , OK ."}, {"turn": 279, "name": "PhD", "id": "C", "contribution": " Uh , so it 's two hundred and ten , yeah ."}, {"turn": 280, "name": "PhD", "id": "D", "contribution": " If you are using {disfmarker}"}, {"turn": 281, "name": "Professor", "id": "B", "contribution": " Uh {disfmarker}"}, {"turn": 282, "name": "PhD", "id": "C", "contribution": " Plus the frame ,"}, {"turn": 283, "name": "PhD", "id": "D", "contribution": " t If you are using three frames {disfmarker}"}, {"turn": 284, "name": "PhD", "id": "C", "contribution": " so it 's two - twenty ."}, {"turn": 285, "name": "PhD", "id": "D", "contribution": " If you are phrasing f {comment} using three frames , it is thirty here for delta ."}, {"turn": 286, "name": "PhD", "id": "C", "contribution": " Yeah , I think it 's {disfmarker} it 's five frames , but ."}, {"turn": 287, "name": "PhD", "id": "D", "contribution": " So five frames , that 's twenty . OK , so it 's who un {comment} two hundred and ten ."}, {"turn": 288, "name": "Professor", "id": "B", "contribution": " Uh , p Wait a minute . It 's forty {disfmarker} {vocalsound} forty for the {disfmarker} for the cleaning of the speech ,"}, {"turn": 289, "name": "PhD", "id": "C", "contribution": " So . Forty cleaning ."}, {"turn": 290, "name": "Professor", "id": "B", "contribution": " forty for the I N {disfmarker} ANN , a hundred for the smoothing ."}, {"turn": 291, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 292, "name": "Professor", "id": "B", "contribution": " Well , but at ten {disfmarker} ,"}, {"turn": 293, "name": "PhD", "id": "C", "contribution": " Twenty for the delta ."}, {"turn": 294, "name": "Professor", "id": "B", "contribution": " Twenty for delta ."}, {"turn": 295, "name": "PhD", "id": "D", "contribution": " At th {nonvocalsound} At the input . I mean , that 's at the input to the net ."}, {"turn": 296, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 297, "name": "Professor", "id": "B", "contribution": " Delta at input to net ?"}, {"turn": 298, "name": "PhD", "id": "D", "contribution": " And there i"}, {"turn": 299, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 300, "name": "PhD", "id": "D", "contribution": " Yeah . So it 's like s five , six cepstrum plus delta at nine {disfmarker} nine frames of {disfmarker}"}, {"turn": 301, "name": "Professor", "id": "B", "contribution": " And then ten milliseconds for {disfmarker}"}, {"turn": 302, "name": "PhD", "id": "D", "contribution": " Fi - There 's an LDA filter ."}, {"turn": 303, "name": "Professor", "id": "B", "contribution": " ten milliseconds for LDA filter , and t and ten {disfmarker} another ten milliseconds you said for the frame ?"}, {"turn": 304, "name": "PhD", "id": "C", "contribution": " For the frame I guess . I computed two - twenty {disfmarker} Yeah , well , it 's {disfmarker} I guess it 's for the fr {disfmarker} the {disfmarker}"}, {"turn": 305, "name": "Professor", "id": "B", "contribution": " OK . And then there 's delta besides that ?"}, {"turn": 306, "name": "PhD", "id": "C", "contribution": " So this is the features that are used by our network and then afterwards , you have to compute the delta on the , uh , main feature stream ,"}, {"turn": 307, "name": "Professor", "id": "B", "contribution": " OK ."}, {"turn": 308, "name": "PhD", "id": "C", "contribution": " which is um , delta and double - deltas , which is fifty milliseconds ."}, {"turn": 309, "name": "Professor", "id": "B", "contribution": " Yeah . No , I mean , the {disfmarker} after the noise part , the forty {disfmarker} the {disfmarker} the other hundred and eighty {disfmarker} Well , I mean , Wait a minute . Some of this is , uh {disfmarker} is , uh {disfmarker} is in parallel , isn't it ? I mean , the LDA {disfmarker} Oh , you have the LDA as part of the V D - uh , VAD ? Or {disfmarker}"}, {"turn": 310, "name": "PhD", "id": "C", "contribution": " The VAD use , uh , LDA filtered features also ."}, {"turn": 311, "name": "Professor", "id": "B", "contribution": " Oh , it does ?"}, {"turn": 312, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 313, "name": "Professor", "id": "B", "contribution": " Ah . So in that case there isn't too much in parallel . Uh {disfmarker}"}, {"turn": 314, "name": "PhD", "id": "C", "contribution": " No . There is , um , just downsampling , upsampling , and the LDA ."}, {"turn": 315, "name": "Professor", "id": "B", "contribution": " Um , so the delta at the end is how much ?"}, {"turn": 316, "name": "PhD", "id": "C", "contribution": " It 's fifty ."}, {"turn": 317, "name": "PhD", "id": "D", "contribution": " It 's {disfmarker}"}, {"turn": 318, "name": "Professor", "id": "B", "contribution": " Fifty . Alright . So {disfmarker}"}, {"turn": 319, "name": "PhD", "id": "C", "contribution": " But well , we could probably put the delta , um , {vocalsound} before on - line normalization . It should not that make a big difference ,"}, {"turn": 320, "name": "PhD", "id": "A", "contribution": " What if you used a smaller window for the delta ?"}, {"turn": 321, "name": "PhD", "id": "C", "contribution": " because {disfmarker}"}, {"turn": 322, "name": "PhD", "id": "A", "contribution": " Could that help a little bit ? I mean , I guess there 's a lot of things you could do to {disfmarker}"}, {"turn": 323, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 324, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 325, "name": "PhD", "id": "C", "contribution": " Yeah ,"}, {"turn": 326, "name": "Professor", "id": "B", "contribution": " So"}, {"turn": 327, "name": "PhD", "id": "C", "contribution": " but , nnn {disfmarker}"}, {"turn": 328, "name": "Professor", "id": "B", "contribution": " Yeah . So if you {disfmarker} if you put the delta before the , uh , ana on - line {disfmarker} If {disfmarker} Yeah {disfmarker}"}, {"turn": 329, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 330, "name": "Professor", "id": "B", "contribution": " uh {disfmarker} then {disfmarker} then it could go in parallel ."}, {"turn": 331, "name": "PhD", "id": "C", "contribution": " Cuz i"}, {"turn": 332, "name": "Professor", "id": "B", "contribution": " And then y then you don't have that additive {disfmarker}"}, {"turn": 333, "name": "PhD", "id": "C", "contribution": " Yeah ,"}, {"turn": 334, "name": "PhD", "id": "D", "contribution": " Yep ."}, {"turn": 335, "name": "PhD", "id": "C", "contribution": " cuz the time constant of the on - line normalization is pretty long compared to the delta window ,"}, {"turn": 336, "name": "Professor", "id": "B", "contribution": " OK ."}, {"turn": 337, "name": "PhD", "id": "C", "contribution": " so . It should not make {disfmarker}"}, {"turn": 338, "name": "Professor", "id": "B", "contribution": " OK . And you ought to be able to shove tw , uh {disfmarker} sh uh {disfmarker} pull off twenty milliseconds from somewhere else to get it under two hundred , right ? I mean {disfmarker}"}, {"turn": 339, "name": "PhD", "id": "A", "contribution": " Is two hundred the d"}, {"turn": 340, "name": "Professor", "id": "B", "contribution": " The hundred milla"}, {"turn": 341, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 342, "name": "Professor", "id": "B", "contribution": " mill a hundred milliseconds for smoothing is sort of an arbitrary amount . It could be eighty and {disfmarker} and probably do @ @ {disfmarker}"}, {"turn": 343, "name": "PhD", "id": "C", "contribution": " Yeah ,"}, {"turn": 344, "name": "PhD", "id": "A", "contribution": " i a hun"}, {"turn": 345, "name": "PhD", "id": "C", "contribution": " yeah ."}, {"turn": 346, "name": "PhD", "id": "A", "contribution": " uh {disfmarker} Wh - what 's the baseline you need to be under ? Two hundred ?"}, {"turn": 347, "name": "Professor", "id": "B", "contribution": " Well , we don't know . They 're still arguing about it ."}, {"turn": 348, "name": "PhD", "id": "C", "contribution": ""}, {"turn": 349, "name": "PhD", "id": "A", "contribution": " Oh ."}, {"turn": 350, "name": "Professor", "id": "B", "contribution": " I mean , if it 's two {disfmarker} if {disfmarker} if it 's , uh {disfmarker} if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . If it 's two hundred , if we shaved off twenty , we could {disfmarker} we could , uh , meet it by moving the delta back ."}, {"turn": 351, "name": "PhD", "id": "A", "contribution": " So , how do you know that what you have is too much if they 're still deciding ?"}, {"turn": 352, "name": "Professor", "id": "B", "contribution": " Uh , we don't , but it 's just {disfmarker} I mean , the main thing is that since that we got burned last time , and {disfmarker} you know , by not worrying about it very much , we 're just staying conscious of it ."}, {"turn": 353, "name": "PhD", "id": "A", "contribution": " Uh - huh . Oh , OK , I see ."}, {"turn": 354, "name": "Professor", "id": "B", "contribution": " And so , th I mean , if {disfmarker} if {disfmarker} if a week before we have to be done someone says , \" Well , you have to have fifty milliseconds less than you have now \" , it would be pretty frantic around here . So {disfmarker}"}, {"turn": 355, "name": "PhD", "id": "A", "contribution": " Ah , OK ."}, {"turn": 356, "name": "Professor", "id": "B", "contribution": " Uh {disfmarker}"}, {"turn": 357, "name": "PhD", "id": "A", "contribution": " But still , that 's {disfmarker} that 's a pretty big , uh , win . And it doesn't seem like you 're {disfmarker} in terms of your delay , you 're , uh , that {disfmarker}"}, {"turn": 358, "name": "Professor", "id": "B", "contribution": " He added a bit on , I guess , because before we were {disfmarker} we were {disfmarker} had {disfmarker} were able to have the noise , uh , stuff , uh , and the LVA be in parallel ."}, {"turn": 359, "name": "PhD", "id": "C", "contribution": " Hmm ."}, {"turn": 360, "name": "Professor", "id": "B", "contribution": " And now he 's {disfmarker} he 's requiring it to be done first ."}, {"turn": 361, "name": "PhD", "id": "C", "contribution": " Well , but I think the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so ."}, {"turn": 362, "name": "Professor", "id": "B", "contribution": " Right . Well , so you say {disfmarker} let 's say ten milliseconds {disfmarker} seconds for the LDA ."}, {"turn": 363, "name": "PhD", "id": "C", "contribution": " And {disfmarker} and {disfmarker} but {disfmarker} the LDA is , well , pretty short right now ."}, {"turn": 364, "name": "Professor", "id": "B", "contribution": " Well , ten . And then forty for the other ."}, {"turn": 365, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 366, "name": "PhD", "id": "D", "contribution": " Yeah , the LDA {disfmarker} LDA {disfmarker} we don't know , is , like {disfmarker} is it very crucial for the features , right ?"}, {"turn": 367, "name": "PhD", "id": "C", "contribution": " No . I just {disfmarker} This is the first try ."}, {"turn": 368, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 369, "name": "Professor", "id": "B", "contribution": " Right ,"}, {"turn": 370, "name": "PhD", "id": "C", "contribution": " I mean , I {disfmarker} maybe the LDA 's not very useful then ."}, {"turn": 371, "name": "Professor", "id": "B", "contribution": " so you could start pulling back ,"}, {"turn": 372, "name": "PhD", "id": "D", "contribution": " S s h"}, {"turn": 373, "name": "Professor", "id": "B", "contribution": " but {disfmarker}"}, {"turn": 374, "name": "PhD", "id": "D", "contribution": " Yeah ,"}, {"turn": 375, "name": "Professor", "id": "B", "contribution": " But I think you have {disfmarker}"}, {"turn": 376, "name": "PhD", "id": "D", "contribution": " l"}, {"turn": 377, "name": "Professor", "id": "B", "contribution": " I mean , you have twenty for delta computation which y now you 're sort of doing twice , right ? But yo w were you doing that before ?"}, {"turn": 378, "name": "PhD", "id": "C", "contribution": " Mmm . Well , in the proposal , um , the input of the VAD network were just three frames , I think ."}, {"turn": 379, "name": "PhD", "id": "D", "contribution": " On the {disfmarker} in the {disfmarker} Mm - hmm . Just {disfmarker} Yeah , just the static , no delta ."}, {"turn": 380, "name": "Professor", "id": "B", "contribution": " Right ."}, {"turn": 381, "name": "PhD", "id": "C", "contribution": " Uh , static features ."}, {"turn": 382, "name": "Professor", "id": "B", "contribution": " So , what you have now is fort uh , forty for the {disfmarker} the noise , twenty for the delta , and ten for the LDA . That 's seventy milliseconds of stuff which was formerly in parallel ,"}, {"turn": 383, "name": "PhD", "id": "C", "contribution": ""}, {"turn": 384, "name": "Professor", "id": "B", "contribution": " right ? So I think ,"}, {"turn": 385, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 386, "name": "Professor", "id": "B", "contribution": " you know , that 's {disfmarker} that 's the difference as far as the timing , right ?"}, {"turn": 387, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 388, "name": "Professor", "id": "B", "contribution": " Um , and you could experiment with cutting various pieces of these back a bit , but {disfmarker} I mean , we 're s we 're not {disfmarker} we 're not in terrible shape ."}, {"turn": 389, "name": "PhD", "id": "A", "contribution": " Yeah , that 's what it seems like to me . It 's pretty good ."}, {"turn": 390, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 391, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 392, "name": "Professor", "id": "B", "contribution": " It 's {disfmarker} it 's not like it 's adding up to four hundred milliseconds or something ."}, {"turn": 393, "name": "PhD", "id": "A", "contribution": " Where {disfmarker} where is this {disfmarker} where is this fifty - seven point O two in {disfmarker} in comparison to the last evaluation ?"}, {"turn": 394, "name": "Professor", "id": "B", "contribution": " Well , it 's {disfmarker} I think it 's better than anything , uh , anybody got ."}, {"turn": 395, "name": "PhD", "id": "A", "contribution": " Oh , is that right ?"}, {"turn": 396, "name": "PhD", "id": "C", "contribution": " Yeah . The best was fifty - four point five ."}, {"turn": 397, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 398, "name": "PhD", "id": "D", "contribution": " Point s"}, {"turn": 399, "name": "PhD", "id": "A", "contribution": " Oh ."}, {"turn": 400, "name": "Professor", "id": "B", "contribution": " Yeah . Uh"}, {"turn": 401, "name": "PhD", "id": "C", "contribution": " And our system was forty - nine , but with the neural network ."}, {"turn": 402, "name": "PhD", "id": "A", "contribution": " Wow . So this is almost ten percent ."}, {"turn": 403, "name": "Professor", "id": "B", "contribution": " With the f with the neural net . Yeah , and r and {disfmarker}"}, {"turn": 404, "name": "PhD", "id": "C", "contribution": " It would"}, {"turn": 405, "name": "PhD", "id": "D", "contribution": " Yeah , so this is {disfmarker} this is like the first proposal . The proposal - one . It was forty - four , actually ."}, {"turn": 406, "name": "Professor", "id": "B", "contribution": " Yeah . Yeah . And we still don't have the neural net in . So {disfmarker} so it 's {disfmarker}"}, {"turn": 407, "name": "PhD", "id": "A", "contribution": " Wow ."}, {"turn": 408, "name": "Professor", "id": "B", "contribution": " You know . So it 's {disfmarker} We 're {disfmarker} we 're doing better ."}, {"turn": 409, "name": "PhD", "id": "A", "contribution": " This is {disfmarker} this is really good ."}, {"turn": 410, "name": "Professor", "id": "B", "contribution": " I mean , we 're getting better recognition . I mean , I 'm sure other people working on this are not sitting still either , but {disfmarker}"}, {"turn": 411, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 412, "name": "Professor", "id": "B", "contribution": " but {disfmarker} but , uh {disfmarker} Uh , I mean , the important thing is that we learn how to do this better , and , you know . So . Um , Yeah . So , our , um {disfmarker} Yeah , you can see the kind of {disfmarker} kind of numbers that we 're having , say , on SpeechDat - Car which is a hard task , cuz it 's really , um {disfmarker} I think it 's just sort of {disfmarker} sort of reasonable numbers , starting to be . I mean , it 's still terri"}, {"turn": 413, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Yeah , even for a well - matched case it 's sixty percent error rate reduction ,"}, {"turn": 414, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 415, "name": "PhD", "id": "C", "contribution": " which is {disfmarker}"}, {"turn": 416, "name": "Professor", "id": "B", "contribution": " Yeah . Probably half . Good !"}, {"turn": 417, "name": "PhD", "id": "C", "contribution": " Um , Yeah . So actually , this is in between {vocalsound} what we had with the previous VAD and what Sunil did with an IDL VAD . Which gave sixty - two percent improvement , right ?"}, {"turn": 418, "name": "PhD", "id": "D", "contribution": " Yeah , it 's almost that ."}, {"turn": 419, "name": "PhD", "id": "C", "contribution": " So {disfmarker}"}, {"turn": 420, "name": "PhD", "id": "D", "contribution": " It 's almost an average somewhere around {disfmarker}"}, {"turn": 421, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 422, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 423, "name": "PhD", "id": "A", "contribution": " What was that ? Say that last part again ?"}, {"turn": 424, "name": "PhD", "id": "C", "contribution": " So , if you use , like , an IDL VAD , uh , for dropping the frames ,"}, {"turn": 425, "name": "PhD", "id": "D", "contribution": " o o Or the best we can get ."}, {"turn": 426, "name": "PhD", "id": "C", "contribution": " the best that we can get {disfmarker} i That means that we estimate the silence probability on the clean version of the utterances . Then you can go up to sixty - two percent error rate reduction , globally ."}, {"turn": 427, "name": "PhD", "id": "A", "contribution": " Mmm ."}, {"turn": 428, "name": "PhD", "id": "C", "contribution": " Mmm {disfmarker} Yeah ."}, {"turn": 429, "name": "PhD", "id": "A", "contribution": " So that would be even {disfmarker} That wouldn't change this number down here to sixty - two ?"}, {"turn": 430, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 431, "name": "Professor", "id": "B", "contribution": " Yeah . So you {disfmarker} you were get"}, {"turn": 432, "name": "PhD", "id": "C", "contribution": " If you add a g good v very good VAD , that works as well as a VAD working on clean speech ,"}, {"turn": 433, "name": "PhD", "id": "A", "contribution": " Yeah . Yeah ."}, {"turn": 434, "name": "PhD", "id": "C", "contribution": " then you wou you would go {disfmarker}"}, {"turn": 435, "name": "PhD", "id": "A", "contribution": " So that 's sort of the best you could hope for ."}, {"turn": 436, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 437, "name": "PhD", "id": "A", "contribution": " I see ."}, {"turn": 438, "name": "Professor", "id": "B", "contribution": " Probably . Yeah . So fi si fifty - three is what you were getting with the old VAD ."}, {"turn": 439, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 440, "name": "Professor", "id": "B", "contribution": " And , uh {disfmarker} and sixty - two with the {disfmarker} the , you know , quote , unquote , cheating VAD . And fifty - seven is what you got with the real VAD ."}, {"turn": 441, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 442, "name": "Professor", "id": "B", "contribution": " That 's great ."}, {"turn": 443, "name": "PhD", "id": "C", "contribution": " Uh , yeah , the next thing is , I started to play {disfmarker} Well , I don't want to worry too much about the delay , no . Maybe it 's better to wait"}, {"turn": 444, "name": "Professor", "id": "B", "contribution": " OK ."}, {"turn": 445, "name": "PhD", "id": "C", "contribution": " for the decision"}, {"turn": 446, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 447, "name": "PhD", "id": "C", "contribution": " from the committee . Uh , but I started to play with the , um , {vocalsound} {vocalsound} uh , tandem neural network . Mmm I just did the configuration that 's very similar to what we did for the February proposal . And {disfmarker} Um . So . There is a f a first feature stream that use uh straight MFCC features ."}, {"turn": 448, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 449, "name": "PhD", "id": "C", "contribution": " Well , these features actually . And the other stream is the output of a neural network , using as input , also , these , um , cleaned MFCC . Um {disfmarker}"}, {"turn": 450, "name": "PhD", "id": "A", "contribution": " Those are th those are th what is going into the tandem net ?"}, {"turn": 451, "name": "PhD", "id": "C", "contribution": " I don't have the comp Mmm ?"}, {"turn": 452, "name": "PhD", "id": "A", "contribution": " Those two ?"}, {"turn": 453, "name": "PhD", "id": "C", "contribution": " So there is just this feature stream , {comment} the fifteen MFCC plus delta and double - delta ."}, {"turn": 454, "name": "Professor", "id": "B", "contribution": " No ."}, {"turn": 455, "name": "PhD", "id": "A", "contribution": " Yeah ?"}, {"turn": 456, "name": "PhD", "id": "C", "contribution": " Um , so it 's {disfmarker} makes forty - five features {comment} that are used as input to the HTK . And then , there is {disfmarker} there are more inputs that comes from the tandem MLP ."}, {"turn": 457, "name": "PhD", "id": "A", "contribution": " Oh , oh . OK . I see ."}, {"turn": 458, "name": "Professor", "id": "B", "contribution": " Yeah , h he likes to use them both ,"}, {"turn": 459, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 460, "name": "Professor", "id": "B", "contribution": " cuz then it has one part that 's discriminative ,"}, {"turn": 461, "name": "PhD", "id": "C", "contribution": " Yeah . Um {disfmarker}"}, {"turn": 462, "name": "Professor", "id": "B", "contribution": " one part that 's not ."}, {"turn": 463, "name": "PhD", "id": "A", "contribution": " Right . OK ."}, {"turn": 464, "name": "PhD", "id": "C", "contribution": " So , um , uh , yeah . Right now it seems that {disfmarker} i I just tested on SpeechDat - Car while the experiment are running on your {disfmarker} on TI - digits . Well , it improves on the well - matched and the mismatched conditions , but it get worse on the highly mismatched . Um ,"}, {"turn": 465, "name": "PhD", "id": "A", "contribution": " Compared to these numbers ?"}, {"turn": 466, "name": "PhD", "id": "C", "contribution": " Compared to these numbers , yeah . Um ,"}, {"turn": 467, "name": "Professor", "id": "B", "contribution": " y"}, {"turn": 468, "name": "PhD", "id": "C", "contribution": " like , on the well - match and medium mismatch , the gain is around five percent relative , but it goes down a lot more , like fifteen percent on the HM case ."}, {"turn": 469, "name": "Professor", "id": "B", "contribution": " You 're just using the full ninety features ?"}, {"turn": 470, "name": "PhD", "id": "C", "contribution": "  The {disfmarker}"}, {"turn": 471, "name": "Professor", "id": "B", "contribution": " Y you have ninety features ?"}, {"turn": 472, "name": "PhD", "id": "C", "contribution": " i I have , um {disfmarker} From the networks , it 's twenty - eight . So {disfmarker}"}, {"turn": 473, "name": "Professor", "id": "B", "contribution": " And from the other side it 's forty - five ."}, {"turn": 474, "name": "PhD", "id": "C", "contribution": " So , d i It 's forty - five ."}, {"turn": 475, "name": "Professor", "id": "B", "contribution": " So it 's {disfmarker} you have seventy - three features ,"}, {"turn": 476, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 477, "name": "Professor", "id": "B", "contribution": " and you 're just feeding them like that ."}, {"turn": 478, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 479, "name": "Professor", "id": "B", "contribution": " There isn't any KLT or anything ?"}, {"turn": 480, "name": "PhD", "id": "C", "contribution": " Mm - hmm . There 's a KLT after the neural network , as {disfmarker} as before ."}, {"turn": 481, "name": "PhD", "id": "A", "contribution": " That 's how you get down to twenty - eight ?"}, {"turn": 482, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 483, "name": "PhD", "id": "A", "contribution": " Why twenty - eight ?"}, {"turn": 484, "name": "PhD", "id": "C", "contribution": " I don't know ."}, {"turn": 485, "name": "PhD", "id": "A", "contribution": " Oh ."}, {"turn": 486, "name": "PhD", "id": "C", "contribution": " Uh . It 's {disfmarker} i i i It 's because it 's what we did for the first proposal . We tested , uh , trying to go down"}, {"turn": 487, "name": "PhD", "id": "A", "contribution": " Ah ."}, {"turn": 488, "name": "Professor", "id": "B", "contribution": " It 's a multiple of seven ."}, {"turn": 489, "name": "PhD", "id": "C", "contribution": " and Yeah ."}, {"turn": 490, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 491, "name": "PhD", "id": "C", "contribution": " So {disfmarker} Um ."}, {"turn": 492, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 493, "name": "PhD", "id": "C", "contribution": " I wanted to do something very similar to the proposal as a first {disfmarker} first try ."}, {"turn": 494, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 495, "name": "PhD", "id": "A", "contribution": " I see ."}, {"turn": 496, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 497, "name": "PhD", "id": "A", "contribution": " Yeah . That makes sense ."}, {"turn": 498, "name": "PhD", "id": "C", "contribution": " But we have to {disfmarker} for sure , we have to go down , because the limit is now sixty features ."}, {"turn": 499, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 500, "name": "PhD", "id": "C", "contribution": " So , uh , we have to find a way to decrease the number of features . Um {disfmarker}"}, {"turn": 501, "name": "PhD", "id": "A", "contribution": " So , it seems funny that {disfmarker} I don't know , maybe I don't u quite understand everything , {comment} but that adding features {disfmarker} I guess {disfmarker} I guess if you 're keeping the back - end fixed . Maybe that 's it . Because it seems like just adding information shouldn't give worse results . But I guess if you 're keeping the number of Gaussians fixed in the recognizer , then {disfmarker}"}, {"turn": 502, "name": "Professor", "id": "B", "contribution": " Well , yeah ."}, {"turn": 503, "name": "PhD", "id": "C", "contribution": " Mmm ."}, {"turn": 504, "name": "Professor", "id": "B", "contribution": " But , I mean , just in general , adding information {disfmarker} Suppose the information you added , well , was a really terrible feature and all it brought in was noise ."}, {"turn": 505, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 506, "name": "Professor", "id": "B", "contribution": " Right ? So {disfmarker} so , um {disfmarker} Or {disfmarker} or suppose it wasn't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier ."}, {"turn": 507, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 508, "name": "Professor", "id": "B", "contribution": " Right ? In that case you wouldn't necessarily expect it to be better at all ."}, {"turn": 509, "name": "PhD", "id": "A", "contribution": " Oh , yeah , I wasn't necessarily saying it should be better . I 'm just surprised that you 're getting fifteen percent relative worse on the wel"}, {"turn": 510, "name": "Professor", "id": "B", "contribution": " Uh - huh ."}, {"turn": 511, "name": "PhD", "id": "C", "contribution": " But it 's worse ."}, {"turn": 512, "name": "Professor", "id": "B", "contribution": " On the highly mismatched condition ."}, {"turn": 513, "name": "PhD", "id": "A", "contribution": " On the highly mismatch ."}, {"turn": 514, "name": "PhD", "id": "C", "contribution": " Yeah , I {disfmarker}"}, {"turn": 515, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 516, "name": "Professor", "id": "B", "contribution": " So , \" highly mismatched condition \" means that in fact your training is a bad estimate of your test ."}, {"turn": 517, "name": "PhD", "id": "C", "contribution": " Uh - huh ."}, {"turn": 518, "name": "Professor", "id": "B", "contribution": " So having {disfmarker} having , uh , a g a l a greater number of features , if they aren't maybe the right features that you use , certainly can e can easily , uh , make things worse . I mean , you 're right . If you have {disfmarker} if you have , uh , lots and lots of data , and you have {disfmarker} and your {disfmarker} your {disfmarker} your training is representative of your test , then getting more sources of information should just help . But {disfmarker} but it 's {disfmarker} It doesn't necessarily work that way ."}, {"turn": 519, "name": "PhD", "id": "A", "contribution": " Huh ."}, {"turn": 520, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 521, "name": "Professor", "id": "B", "contribution": " So I wonder , um , Well , what 's your {disfmarker} what 's your thought about what to do next with it ?"}, {"turn": 522, "name": "PhD", "id": "C", "contribution": " Um , I don't know . I 'm surprised , because I expected the neural net to help more when there is more mismatch , as it was the case for the {disfmarker}"}, {"turn": 523, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 524, "name": "PhD", "id": "D", "contribution": " So , was the training set same as the p the February proposal ? OK ."}, {"turn": 525, "name": "PhD", "id": "C", "contribution": " Yeah , it 's the same training set , so it 's TIMIT with the TI - digits ' , uh , noises , uh , added ."}, {"turn": 526, "name": "PhD", "id": "D", "contribution": ""}, {"turn": 527, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 528, "name": "PhD", "id": "C", "contribution": " Um {disfmarker}"}, {"turn": 529, "name": "Professor", "id": "B", "contribution": " Well , we might {disfmarker} uh , we might have to experiment with , uh better training sets . Again . But ,"}, {"turn": 530, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 531, "name": "Professor", "id": "B", "contribution": " I {disfmarker} The other thing is , I mean , before you found that was the best configuration , but you might have to retest those things now that we have different {disfmarker} The rest of it is different , right ? So , um , uh , For instance , what 's the effect of just putting the neural net on without the o other {disfmarker} other path ?"}, {"turn": 532, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 533, "name": "Professor", "id": "B", "contribution": " I mean , you know what the straight features do ."}, {"turn": 534, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 535, "name": "Professor", "id": "B", "contribution": " That gives you this . You know what it does in combination ."}, {"turn": 536, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 537, "name": "Professor", "id": "B", "contribution": " You don't necessarily know what {disfmarker}"}, {"turn": 538, "name": "PhD", "id": "A", "contribution": " What if you did the {disfmarker} Would it make sense to do the KLT on the full set of combined features ? Instead of just on the {disfmarker}"}, {"turn": 539, "name": "PhD", "id": "C", "contribution": " Yeah . I g I guess . Um . The reason I did it this ways is that in February , it {disfmarker} we {disfmarker} we tested different things like that , so , having two KLT , having just a KLT for a network , or having a global KLT ."}, {"turn": 540, "name": "PhD", "id": "A", "contribution": " Oh , I see ."}, {"turn": 541, "name": "PhD", "id": "C", "contribution": " And {disfmarker}"}, {"turn": 542, "name": "PhD", "id": "A", "contribution": " So you tried the global KLT before"}, {"turn": 543, "name": "PhD", "id": "C", "contribution": " Well {disfmarker}"}, {"turn": 544, "name": "PhD", "id": "A", "contribution": " and it didn't really {disfmarker}"}, {"turn": 545, "name": "PhD", "id": "C", "contribution": " Yeah . And , uh , th Yeah ."}, {"turn": 546, "name": "PhD", "id": "A", "contribution": " I see ."}, {"turn": 547, "name": "PhD", "id": "C", "contribution": " The differences between these configurations were not huge , but {disfmarker} it was marginally better with this configuration ."}, {"turn": 548, "name": "PhD", "id": "A", "contribution": " Uh - huh . Uh - huh ."}, {"turn": 549, "name": "Professor", "id": "B", "contribution": " But , yeah , that 's obviously another thing to try ,"}, {"turn": 550, "name": "PhD", "id": "C", "contribution": " Um ."}, {"turn": 551, "name": "Professor", "id": "B", "contribution": " since things are {disfmarker} things are different ."}, {"turn": 552, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Mm - hmm ."}, {"turn": 553, "name": "Professor", "id": "B", "contribution": " And I guess if the {disfmarker} These are all {disfmarker} so all of these seventy - three features are going into , um , the , uh {disfmarker} the HMM ."}, {"turn": 554, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 555, "name": "Professor", "id": "B", "contribution": " And is {disfmarker} are {disfmarker} i i are {disfmarker} are any deltas being computed of tha of them ?"}, {"turn": 556, "name": "PhD", "id": "C", "contribution": " Of the straight features , yeah ."}, {"turn": 557, "name": "Professor", "id": "B", "contribution": " n Not of the {disfmarker}"}, {"turn": 558, "name": "PhD", "id": "C", "contribution": " So . But n th the , um , tandem features are u used as they are ."}, {"turn": 559, "name": "Professor", "id": "B", "contribution": " Are not ."}, {"turn": 560, "name": "PhD", "id": "C", "contribution": " So , yeah , maybe we can add some context from these features also as {disfmarker} Dan did in {disfmarker} in his last work ."}, {"turn": 561, "name": "Professor", "id": "B", "contribution": " Could . i Yeah , but the other thing I was thinking was , um {disfmarker} Uh , now I lost track of what I was thinking . But ."}, {"turn": 562, "name": "PhD", "id": "A", "contribution": " What is the {disfmarker} You said there was a limit of sixty features or something ?"}, {"turn": 563, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 564, "name": "PhD", "id": "A", "contribution": " What 's the relation between that limit and the , um , forty - eight {disfmarker} uh , forty eight hundred bits per second ?"}, {"turn": 565, "name": "Professor", "id": "B", "contribution": " Oh , I know what I was gonna say ."}, {"turn": 566, "name": "PhD", "id": "C", "contribution": " Um , not {disfmarker} no relation ."}, {"turn": 567, "name": "Professor", "id": "B", "contribution": " No relation ."}, {"turn": 568, "name": "PhD", "id": "A", "contribution": " So I {disfmarker} I {disfmarker} I don't understand ,"}, {"turn": 569, "name": "PhD", "id": "C", "contribution": " The f the forty - eight hundred bits is for transmission of some features ."}, {"turn": 570, "name": "PhD", "id": "A", "contribution": " because i I mean , if you 're only using h"}, {"turn": 571, "name": "PhD", "id": "C", "contribution": " And generally , i it {disfmarker} s allows you to transmit like , fifteen , uh , cepstrum ."}, {"turn": 572, "name": "Professor", "id": "B", "contribution": " The issue was that , um , this is supposed to be a standard that 's then gonna be fed to somebody 's recognizer somewhere which might be , you know , it {disfmarker} it might be a concern how many parameters are use {disfmarker} u used and so forth . And so , uh , they felt they wanted to set a limit . So they chose sixty . Some people wanted to use hundreds of parameters and {disfmarker} and that bothered some other people ."}, {"turn": 573, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 574, "name": "Professor", "id": "B", "contribution": " u And so they just chose that . I {disfmarker} I {disfmarker} I think it 's kind of r arbitrary too . But {disfmarker} but that 's {disfmarker} that 's kind of what was chosen . I {disfmarker} I remembered what I was going to say . What I was going to say is that , um , maybe {disfmarker} {vocalsound} maybe with the noise removal , uh , these things are now more correlated . So you have two sets of things that are kind of uncorrelated , uh , within themselves , but they 're pretty correlated with one another ."}, {"turn": 575, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 576, "name": "Professor", "id": "B", "contribution": " And , um , they 're being fed into these , uh , variants , only Gaussians and so forth , and {disfmarker} and , uh ,"}, {"turn": 577, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 578, "name": "Professor", "id": "B", "contribution": " so maybe it would be a better idea now than it was before to , uh , have , uh , one KLT over everything , to de - correlate it ."}, {"turn": 579, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Yeah , I see ."}, {"turn": 580, "name": "Professor", "id": "B", "contribution": " Maybe . You know ."}, {"turn": 581, "name": "PhD", "id": "D", "contribution": " What are the S N Rs in the training set , TIMIT ?"}, {"turn": 582, "name": "PhD", "id": "C", "contribution": " It 's , uh , ranging from zero to clean ? Yeah . From zero to clean ."}, {"turn": 583, "name": "PhD", "id": "D", "contribution": " Mm - hmm ."}, {"turn": 584, "name": "Professor", "id": "B", "contribution": " Yeah . So we found this {disfmarker} this , uh {disfmarker} this Macrophone data , and so forth , that we were using for these other experiments , to be pretty good ."}, {"turn": 585, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 586, "name": "Professor", "id": "B", "contribution": " So that 's {disfmarker} i after you explore these other alternatives , that might be another way to start looking , is {disfmarker} is just improving the training set ."}, {"turn": 587, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 588, "name": "Professor", "id": "B", "contribution": " I mean , we were getting , uh , lots better recognition using that , than {disfmarker} Of course , you do have the problem that , um , u i {comment} we are not able to increase the number of Gaussians , uh , or anything to , uh , uh , to match anything . So we 're only improving the training of our feature set , but that 's still probably something ."}, {"turn": 589, "name": "PhD", "id": "A", "contribution": " So you 're saying , add the Macrophone data to the training of the neural net ? The tandem net ?"}, {"turn": 590, "name": "Professor", "id": "B", "contribution": " Yeah , that 's the only place that we can train ."}, {"turn": 591, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 592, "name": "Professor", "id": "B", "contribution": " We can't train the other stuff with anything other than the standard amount ,"}, {"turn": 593, "name": "PhD", "id": "A", "contribution": " Right ."}, {"turn": 594, "name": "Professor", "id": "B", "contribution": " so . Um , um {disfmarker}"}, {"turn": 595, "name": "PhD", "id": "A", "contribution": " What {disfmarker} what was it trained on again ? The one that you used ?"}, {"turn": 596, "name": "PhD", "id": "C", "contribution": " It 's TIMIT with noise ."}, {"turn": 597, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 598, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 599, "name": "PhD", "id": "C", "contribution": " So , yeah , it 's rather a small {disfmarker}"}, {"turn": 600, "name": "Professor", "id": "B", "contribution": " How big is the net , by the way ?"}, {"turn": 601, "name": "PhD", "id": "C", "contribution": " Um , Uh , it 's , uh , five hundred hidden units . And {disfmarker}"}, {"turn": 602, "name": "Professor", "id": "B", "contribution": " And again , you did experiments back then where you made it bigger and it {disfmarker} and that was {disfmarker} that was sort of the threshold point . Much less than that , it was worse ,"}, {"turn": 603, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 604, "name": "Professor", "id": "B", "contribution": " and"}, {"turn": 605, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 606, "name": "Professor", "id": "B", "contribution": " much more than that , it wasn't much better . Hmm ."}, {"turn": 607, "name": "PhD", "id": "C", "contribution": " Yeah . @ @ ?"}, {"turn": 608, "name": "PhD", "id": "D", "contribution": " So is it {disfmarker} is it though the performance , big relation in the high ma high mismatch has something to do with the , uh , cleaning up that you {disfmarker} that is done on the TIMIT after adding noise ?"}, {"turn": 609, "name": "PhD", "id": "C", "contribution": ""}, {"turn": 610, "name": "PhD", "id": "D", "contribution": " So {disfmarker} it 's {disfmarker} i All the noises are from the TI - digits ,"}, {"turn": 611, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 612, "name": "PhD", "id": "D", "contribution": " right ? So you {disfmarker} i"}, {"turn": 613, "name": "PhD", "id": "C", "contribution": " Um {disfmarker} They {disfmarker} k uh {disfmarker}"}, {"turn": 614, "name": "PhD", "id": "D", "contribution": " Well , it it 's like the high mismatch of the SpeechDat - Car after cleaning up , maybe having more noise than the {disfmarker} the training set of TIMIT after clean {disfmarker} s after you do the noise clean - up ."}, {"turn": 615, "name": "PhD", "id": "C", "contribution": " Mmm ."}, {"turn": 616, "name": "PhD", "id": "D", "contribution": " I mean , earlier you never had any compensation , you just trained it straight away ."}, {"turn": 617, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 618, "name": "PhD", "id": "D", "contribution": " So it had like all these different conditions of S N Rs , actually in their training set of neural net ."}, {"turn": 619, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Mm - hmm ."}, {"turn": 620, "name": "PhD", "id": "D", "contribution": " But after cleaning up you have now a different set of S N Rs , right ?"}, {"turn": 621, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 622, "name": "PhD", "id": "D", "contribution": " For the training of the neural net ."}, {"turn": 623, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 624, "name": "PhD", "id": "D", "contribution": " And {disfmarker} is it something to do with the mismatch that {disfmarker} that 's created after the cleaning up , like the high mismatch {disfmarker}"}, {"turn": 625, "name": "PhD", "id": "C", "contribution": " You mean the {disfmarker} the most noisy occurrences on SpeechDat - Car might be a lot more noisy than {disfmarker}"}, {"turn": 626, "name": "PhD", "id": "D", "contribution": " Mm - hmm . Of {disfmarker} that {disfmarker} I mean , the SNR after the noise compensation of the SpeechDat - Car ."}, {"turn": 627, "name": "Professor", "id": "B", "contribution": " Oh , so {disfmarker} Right . So the training {disfmarker} the {disfmarker} the neural net is being trained with noise compensated stuff ."}, {"turn": 628, "name": "PhD", "id": "C", "contribution": " Maybe ."}, {"turn": 629, "name": "PhD", "id": "D", "contribution": "  Yeah ."}, {"turn": 630, "name": "PhD", "id": "C", "contribution": " Yeah , yeah ."}, {"turn": 631, "name": "Professor", "id": "B", "contribution": " Which makes sense ,"}, {"turn": 632, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 633, "name": "Professor", "id": "B", "contribution": " but , uh , you 're saying {disfmarker} Yeah , the noisier ones are still going to be , even after our noise compensation , are still gonna be pretty noisy ."}, {"turn": 634, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 635, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 636, "name": "PhD", "id": "D", "contribution": " Yeah , so now the after - noise compensation the neural net is seeing a different set of S N Rs than that was originally there in the training set . Of TIMIT . Because in the TIMIT it was zero to some clean ."}, {"turn": 637, "name": "Professor", "id": "B", "contribution": " Right . Yes ."}, {"turn": 638, "name": "PhD", "id": "D", "contribution": " So the net saw all the SNR @ @ conditions ."}, {"turn": 639, "name": "Professor", "id": "B", "contribution": " Right ."}, {"turn": 640, "name": "PhD", "id": "D", "contribution": " Now after cleaning up it 's a different set of SNR ."}, {"turn": 641, "name": "Professor", "id": "B", "contribution": " Right ."}, {"turn": 642, "name": "PhD", "id": "D", "contribution": " And that SNR may not be , like , com covering the whole set of S N Rs that you 're getting in the SpeechDat - Car ."}, {"turn": 643, "name": "Professor", "id": "B", "contribution": " Right , but the SpeechDat - Car data that you 're seeing is also reduced in noise by the noise compensation ."}, {"turn": 644, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 645, "name": "PhD", "id": "D", "contribution": " Yeah , yeah , yeah , yeah , it is . But , I 'm saying , there could be some {disfmarker} some issues of {disfmarker}"}, {"turn": 646, "name": "Professor", "id": "B", "contribution": " So ."}, {"turn": 647, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 648, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 649, "name": "PhD", "id": "C", "contribution": " Well , if the initial range of SNR is different , we {disfmarker} the problem was already there before . And {disfmarker}"}, {"turn": 650, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 651, "name": "PhD", "id": "C", "contribution": " Because {disfmarker} Mmm {disfmarker}"}, {"turn": 652, "name": "Professor", "id": "B", "contribution": " Yeah , I mean , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set ."}, {"turn": 653, "name": "PhD", "id": "C", "contribution": " Hmm ."}, {"turn": 654, "name": "Professor", "id": "B", "contribution": " Uh {disfmarker}"}, {"turn": 655, "name": "PhD", "id": "D", "contribution": " On the test set , yeah ."}, {"turn": 656, "name": "Professor", "id": "B", "contribution": " Right ? I mean , you 're saying there 's a mismatch in noise that wasn't there before ,"}, {"turn": 657, "name": "PhD", "id": "D", "contribution": " Hmm . Mm - hmm ."}, {"turn": 658, "name": "Professor", "id": "B", "contribution": " but if they were both the same before , then if they were both reduic reduced equally , then , there would not be a mismatch ."}, {"turn": 659, "name": "PhD", "id": "D", "contribution": " Mm - hmm ."}, {"turn": 660, "name": "Professor", "id": "B", "contribution": " So , I mean , this may be {disfmarker} Heaven forbid , this noise compensation process may be imperfect , but . Uh , so maybe it 's treating some things differently ."}, {"turn": 661, "name": "PhD", "id": "C", "contribution": " Yeah , uh {disfmarker}"}, {"turn": 662, "name": "PhD", "id": "D", "contribution": " Well , I {disfmarker} I don't know . I {disfmarker} I just {disfmarker} that could be seen from the TI - digits , uh , testing condition because , um , the noises are from the TI - digits , right ? Noise {disfmarker}"}, {"turn": 663, "name": "PhD", "id": "C", "contribution": " Yeah . So {disfmarker}"}, {"turn": 664, "name": "PhD", "id": "D", "contribution": " So cleaning up the TI - digits and if the performance goes down in the TI - digits mismatch {disfmarker} high mismatch like this {disfmarker}"}, {"turn": 665, "name": "PhD", "id": "C", "contribution": " Clean training , yeah ."}, {"turn": 666, "name": "PhD", "id": "D", "contribution": " on a clean training , or zero DB testing ."}, {"turn": 667, "name": "PhD", "id": "C", "contribution": " Yeah , we 'll {disfmarker} so we 'll see . Uh ."}, {"turn": 668, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 669, "name": "PhD", "id": "C", "contribution": " Maybe ."}, {"turn": 670, "name": "PhD", "id": "D", "contribution": " Then it 's something to do ."}, {"turn": 671, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 672, "name": "Professor", "id": "B", "contribution": " I mean , one of the things about {disfmarker}"}, {"turn": 673, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 674, "name": "Professor", "id": "B", "contribution": " I mean , the Macrophone data , um , I think , you know , it was recorded over many different telephones ."}, {"turn": 675, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 676, "name": "Professor", "id": "B", "contribution": " And , um , so , there 's lots of different kinds of acoustic conditions . I mean , it 's not artificially added noise or anything . So it 's not the same . I don't think there 's anybody recording over a car from a car , but {disfmarker} I think it 's {disfmarker} it 's varied enough that if {disfmarker} if doing this adjustments , uh , and playing around with it doesn't , uh , make it better , the most {disfmarker} uh , it seems like the most obvious thing to do is to improve the training set . Um {disfmarker} I mean , what we were {disfmarker} uh {disfmarker} the condition {disfmarker} It {disfmarker} it gave us an enormous amount of improvement in what we were doing with Meeting Recorder digits , even though there , again , these m Macrophone digits were very , very different from , uh , what we were going on here . I mean , we weren't talking over a telephone here . But it was just {disfmarker} I think just having a {disfmarker} a nice variation in acoustic conditions was just a good thing ."}, {"turn": 677, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Yep ."}, {"turn": 678, "name": "PhD", "id": "D", "contribution": " Mmm ."}, {"turn": 679, "name": "PhD", "id": "C", "contribution": " Yeah , actually {vocalsound} to s eh , what I observed in the HM case is that the number of deletion dramatically increases . It {disfmarker} it doubles ."}, {"turn": 680, "name": "Professor", "id": "B", "contribution": " Number of deletions ."}, {"turn": 681, "name": "PhD", "id": "C", "contribution": " When I added the num the neural network it doubles the number of deletions . Yeah , so I don't you know {vocalsound} how to interpret that , but , mmm {disfmarker}"}, {"turn": 682, "name": "Professor", "id": "B", "contribution": " Yeah . Me either ."}, {"turn": 683, "name": "PhD", "id": "C", "contribution": " t"}, {"turn": 684, "name": "PhD", "id": "A", "contribution": " And {disfmarker} and did {disfmarker} an other numbers stay the same ? Insertion substitutions stay the same ?"}, {"turn": 685, "name": "PhD", "id": "C", "contribution": " They p stayed the same ,"}, {"turn": 686, "name": "PhD", "id": "A", "contribution": " Roughly ?"}, {"turn": 687, "name": "PhD", "id": "C", "contribution": " they {disfmarker} maybe they are a little bit uh , lower ."}, {"turn": 688, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 689, "name": "PhD", "id": "C", "contribution": " They are a little bit better . Yeah . But {disfmarker}"}, {"turn": 690, "name": "Professor", "id": "B", "contribution": " Did they increase the number of deletions even for the cases that got better ?"}, {"turn": 691, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 692, "name": "Professor", "id": "B", "contribution": " Say , for the {disfmarker} I mean , it {disfmarker}"}, {"turn": 693, "name": "PhD", "id": "C", "contribution": " No , it doesn't ."}, {"turn": 694, "name": "Professor", "id": "B", "contribution": " So it 's only the highly mismatched ?"}, {"turn": 695, "name": "PhD", "id": "C", "contribution": " No ."}, {"turn": 696, "name": "Professor", "id": "B", "contribution": " And it {disfmarker} Remind me again , the \" highly mismatched \" means that the {disfmarker}"}, {"turn": 697, "name": "PhD", "id": "C", "contribution": " Clean training and {disfmarker}"}, {"turn": 698, "name": "Professor", "id": "B", "contribution": " Uh , sorry ?"}, {"turn": 699, "name": "PhD", "id": "C", "contribution": " It 's clean training {disfmarker} Well , close microphone training and distant microphone , um , high speed , I think ."}, {"turn": 700, "name": "Professor", "id": "B", "contribution": " Close mike training {disfmarker}"}, {"turn": 701, "name": "PhD", "id": "C", "contribution": " Well {disfmarker} The most noisy cases are the distant microphone for testing ."}, {"turn": 702, "name": "Professor", "id": "B", "contribution": " Right . So {disfmarker} Well , maybe the noise subtraction is subtracting off speech ."}, {"turn": 703, "name": "PhD", "id": "C", "contribution": " Separating . Yeah ."}, {"turn": 704, "name": "Professor", "id": "B", "contribution": " Wh"}, {"turn": 705, "name": "PhD", "id": "C", "contribution": " But {disfmarker} Yeah . I mean , but without the neural network it 's {disfmarker} well , it 's better . It 's just when we add the neural networks ."}, {"turn": 706, "name": "Professor", "id": "B", "contribution": " Yeah , right ."}, {"turn": 707, "name": "PhD", "id": "C", "contribution": " The feature are the same except that {disfmarker}"}, {"turn": 708, "name": "Professor", "id": "B", "contribution": " Uh , that 's right , that 's right . Um {disfmarker}"}, {"turn": 709, "name": "PhD", "id": "A", "contribution": " Well that {disfmarker} that says that , you know , the , um {disfmarker} the models in {disfmarker} in , uh , the recognizer are really paying attention to the neural net features ."}, {"turn": 710, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 711, "name": "PhD", "id": "A", "contribution": " Uh ."}, {"turn": 712, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 713, "name": "Professor", "id": "B", "contribution": " But , yeah , actually {disfmarker} {nonvocalsound} the TIMIT noises {pause} are sort of a range of noises and they 're not so much the stationary driving kind of noises , right ? It 's {disfmarker} it 's pretty different . Isn't it ?"}, {"turn": 714, "name": "PhD", "id": "C", "contribution": " Uh , there is a car noise . So there are f just four noises . Um , uh , \" Car \" , I think , \" Babble \" ,"}, {"turn": 715, "name": "PhD", "id": "D", "contribution": " \" Babble . \""}, {"turn": 716, "name": "PhD", "id": "C", "contribution": " \" Subway \" , right ? and {disfmarker}"}, {"turn": 717, "name": "PhD", "id": "D", "contribution": " \" Street \" or \" Airport \" or something ."}, {"turn": 718, "name": "PhD", "id": "C", "contribution": " and {disfmarker} \" Street \" isn't {disfmarker}"}, {"turn": 719, "name": "PhD", "id": "D", "contribution": " Or \" Train station \" ."}, {"turn": 720, "name": "PhD", "id": "C", "contribution": " \" Train station \" , yeah ."}, {"turn": 721, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 722, "name": "PhD", "id": "C", "contribution": " So {disfmarker} it 's mostly {disfmarker} Well , \" Car \" is stationary ,"}, {"turn": 723, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 724, "name": "PhD", "id": "C", "contribution": " \" Babble \" , it 's a stationary background plus some voices ,"}, {"turn": 725, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 726, "name": "PhD", "id": "C", "contribution": " some speech over it . And the other two are rather stationary also ."}, {"turn": 727, "name": "Professor", "id": "B", "contribution": " Well , I {disfmarker} I think that if you run it {disfmarker} Actually , you {disfmarker} maybe you remember this . When you {disfmarker} in {disfmarker} in the old experiments when you ran with the neural net only , and didn't have this side path , um , uh , with the {disfmarker} the pure features as well , did it make things better to have the neural net ?"}, {"turn": 728, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 729, "name": "Professor", "id": "B", "contribution": " Was it about the same ? Uh , w i"}, {"turn": 730, "name": "PhD", "id": "C", "contribution": " It was {disfmarker} b a little bit worse ."}, {"turn": 731, "name": "Professor", "id": "B", "contribution": " Than {disfmarker} ?"}, {"turn": 732, "name": "PhD", "id": "C", "contribution": " Than just the features , yeah ."}, {"turn": 733, "name": "Professor", "id": "B", "contribution": " So , until you put the second path in with the pure features , the neural net wasn't helping at all ."}, {"turn": 734, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 735, "name": "Professor", "id": "B", "contribution": " Well , that 's interesting ."}, {"turn": 736, "name": "PhD", "id": "C", "contribution": " It was helping , uh , if the features are b were bad ,"}, {"turn": 737, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 738, "name": "PhD", "id": "C", "contribution": " I mean . Just plain P L Ps or M F"}, {"turn": 739, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 740, "name": "PhD", "id": "C", "contribution": " C Cs . as soon as we added LDA on - line normalization , and {vocalsound} all these things , then {disfmarker}"}, {"turn": 741, "name": "Professor", "id": "B", "contribution": " They were doing similar enough things . Well , I still think it would be k sort of interesting to see what would happen if you just had the neural net without the side thing ."}, {"turn": 742, "name": "PhD", "id": "C", "contribution": " Yeah ,"}, {"turn": 743, "name": "Professor", "id": "B", "contribution": " And {disfmarker} and the thing I {disfmarker} I have in mind is , uh , maybe you 'll see that the results are not just a little bit worse ."}, {"turn": 744, "name": "PhD", "id": "C", "contribution": " mm - hmm ."}, {"turn": 745, "name": "Professor", "id": "B", "contribution": " Maybe that they 're a lot worse . You know ? And , um {disfmarker} But if on the ha other hand , uh , it 's , say , somewhere in between what you 're seeing now and {disfmarker} and {disfmarker} and , uh , what you 'd have with just the pure features , then maybe there is some problem of a {disfmarker} of a , uh , combination of these things , or correlation between them somehow ."}, {"turn": 746, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 747, "name": "Professor", "id": "B", "contribution": " If it really is that the net is hurting you at the moment , then I think the issue is to focus on {disfmarker} on , uh , improving the {disfmarker} the net ."}, {"turn": 748, "name": "PhD", "id": "C", "contribution": " Yeah ,"}, {"turn": 749, "name": "Professor", "id": "B", "contribution": " Um ."}, {"turn": 750, "name": "PhD", "id": "C", "contribution": " mm - hmm ."}, {"turn": 751, "name": "Professor", "id": "B", "contribution": " So what 's the overall effe I mean , you haven't done all the experiments but you said it was i somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? But it 's {disfmarker} but of course that one 's weighted lower ,"}, {"turn": 752, "name": "PhD", "id": "C", "contribution": " Y yeah , oh . Yeah ."}, {"turn": 753, "name": "Professor", "id": "B", "contribution": " so I wonder what the net effect is ."}, {"turn": 754, "name": "PhD", "id": "C", "contribution": " I d I {disfmarker} I think it 's {disfmarker} it was one or two percent . That 's not that bad , but it was l like two percent relative worse on SpeechDat - Car . I have to {disfmarker} to check that . Well , I have {disfmarker} I will ."}, {"turn": 755, "name": "PhD", "id": "D", "contribution": " Well , it will {disfmarker} overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like f w twenty - five {disfmarker} point two five eight ."}, {"turn": 756, "name": "Professor", "id": "B", "contribution": " Right ."}, {"turn": 757, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Hmm ."}, {"turn": 758, "name": "Professor", "id": "B", "contribution": " Right . So the {disfmarker} so the worst it could be , if the others were exactly the same , is four ,"}, {"turn": 759, "name": "PhD", "id": "D", "contribution": " Is it like {disfmarker}"}, {"turn": 760, "name": "Professor", "id": "B", "contribution": " and {disfmarker} and , uh , in fact since the others are somewhat better {disfmarker}"}, {"turn": 761, "name": "PhD", "id": "D", "contribution": " Yeah , so it 's four . Is i So either it 'll get cancelled out , or you 'll get , like , almost the same ."}, {"turn": 762, "name": "Professor", "id": "B", "contribution": " Uh ."}, {"turn": 763, "name": "PhD", "id": "C", "contribution": " Yeah , it was {disfmarker} it was slightly worse ."}, {"turn": 764, "name": "PhD", "id": "D", "contribution": " Slightly bad . Yeah ."}, {"turn": 765, "name": "PhD", "id": "C", "contribution": " Um ,"}, {"turn": 766, "name": "Professor", "id": "B", "contribution": " Yeah , it should be pretty close to cancelled out ."}, {"turn": 767, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 768, "name": "PhD", "id": "A", "contribution": " You know , I 've been wondering about something ."}, {"turn": 769, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 770, "name": "PhD", "id": "A", "contribution": " In the , um {disfmarker} a lot of the , um {disfmarker} the Hub - five systems , um , recently have been using LDA . and {disfmarker} and they , um {disfmarker} They run LDA on the features right before they train the models . So there 's the {disfmarker} the LDA is {disfmarker} is right there before the H M"}, {"turn": 771, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 772, "name": "PhD", "id": "A", "contribution": " So , you guys are using LDA but it seems like it 's pretty far back in the process ."}, {"turn": 773, "name": "PhD", "id": "D", "contribution": " Uh , this LDA is different from the LDA that you are talking about . The LDA that you {disfmarker} saying is , like , you take a block of features , like nine frames or something , {comment} and then do an LDA on it ,"}, {"turn": 774, "name": "PhD", "id": "A", "contribution": " Yeah . Uh - huh ."}, {"turn": 775, "name": "PhD", "id": "D", "contribution": " and then reduce the dimensionality to something like twenty - four or something like that ."}, {"turn": 776, "name": "PhD", "id": "A", "contribution": " Yeah , you c you c you can ."}, {"turn": 777, "name": "PhD", "id": "D", "contribution": " And then feed it to HMM ."}, {"turn": 778, "name": "PhD", "id": "A", "contribution": " I mean , it 's {disfmarker} you know , you 're just basically i"}, {"turn": 779, "name": "PhD", "id": "D", "contribution": " Yeah , so this is like a two d two dimensional tile ."}, {"turn": 780, "name": "PhD", "id": "A", "contribution": " You 're shifting the feature space . Yeah ."}, {"turn": 781, "name": "PhD", "id": "D", "contribution": " So this is a two dimensional tile . And the LDA that we are f applying is only in time , not in frequency {disfmarker} high cost frequency . So it 's like {disfmarker} more like a filtering in time , rather than doing a r"}, {"turn": 782, "name": "PhD", "id": "A", "contribution": " Ah . OK . So what i what about , um {disfmarker} i u what i w I mean , I don't know if this is a good idea or not , but what if you put {disfmarker} ran the other kind of LDA , uh , on your features right before they go into the HMM ?"}, {"turn": 783, "name": "PhD", "id": "D", "contribution": " Uh , it {disfmarker}"}, {"turn": 784, "name": "PhD", "id": "C", "contribution": " Mm - hmm . No , actually , I think {disfmarker} i"}, {"turn": 785, "name": "PhD", "id": "D", "contribution": " m"}, {"turn": 786, "name": "PhD", "id": "C", "contribution": " Well . What do we do with the ANN is {disfmarker} is something like that except that it 's not linear . But it 's {disfmarker} it 's like a nonlinear discriminant analysis ."}, {"turn": 787, "name": "PhD", "id": "A", "contribution": " Yeah . Right , it 's the {disfmarker} It 's {disfmarker} Right . The {disfmarker} So {disfmarker} Yeah , so it 's sort of like {disfmarker}"}, {"turn": 788, "name": "PhD", "id": "C", "contribution": " But ."}, {"turn": 789, "name": "PhD", "id": "A", "contribution": " The tandem stuff is kind of like i nonlinear LDA ."}, {"turn": 790, "name": "PhD", "id": "C", "contribution": " Yeah . It 's {disfmarker}"}, {"turn": 791, "name": "PhD", "id": "A", "contribution": " I g"}, {"turn": 792, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 793, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 794, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 795, "name": "PhD", "id": "A", "contribution": " But I mean , w but the other features that you have , um , th the non - tandem ones ,"}, {"turn": 796, "name": "PhD", "id": "C", "contribution": " Uh . Mm - hmm . Yeah , I know . That {disfmarker} that {disfmarker} Yeah . Well , in the proposal , they were transformed u using PCA , but {disfmarker}"}, {"turn": 797, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 798, "name": "PhD", "id": "C", "contribution": " Yeah , it might be that LDA could be better ."}, {"turn": 799, "name": "Professor", "id": "B", "contribution": " The a the argument i is kind of i in {disfmarker} and it 's not like we really know , but the argument anyway is that , um , uh , we always have the prob I mean , discriminative things are good . LDA , neural nets , they 're good ."}, {"turn": 800, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 801, "name": "Professor", "id": "B", "contribution": " Uh , they 're good because you {disfmarker} you {disfmarker} you learn to distinguish between these categories that you want to be good at distinguishing between . And PCA doesn't do that . It {disfmarker} PAC - PCA {disfmarker} low - order PCA throws away pieces that are uh , maybe not {disfmarker} not gonna be helpful just because they 're small , basically ."}, {"turn": 802, "name": "PhD", "id": "A", "contribution": " Right ."}, {"turn": 803, "name": "Professor", "id": "B", "contribution": " But , uh , the problem is , training sets aren't perfect and testing sets are different . So you f you {disfmarker} you face the potential problem with discriminative stuff , be it LDA or neural nets , that you are training to discriminate between categories in one space but what you 're really gonna be g getting is {disfmarker} is something else ."}, {"turn": 804, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 805, "name": "Professor", "id": "B", "contribution": " And so , uh , Stephane 's idea was , uh , let 's feed , uh , both this discriminatively trained thing and something that 's not . So you have a good set of features that everybody 's worked really hard to make ,"}, {"turn": 806, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 807, "name": "Professor", "id": "B", "contribution": " and then , uh , you {disfmarker} you discriminately train it , but you also take the path that {disfmarker} that doesn't have that ,"}, {"turn": 808, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 809, "name": "Professor", "id": "B", "contribution": " and putting those in together . And that {disfmarker} that seem So it 's kind of like a combination of the {disfmarker} uh , what , uh , Dan has been calling , you know , a feature {disfmarker} uh , you know , a feature combination versus posterior combination or something . It 's {disfmarker} it 's , you know , you have the posterior combination but then you get the features from that and use them as a feature combination with these {disfmarker} these other things . And that seemed , at least in the last one , as he was just saying , he {disfmarker} he {disfmarker} when he only did discriminative stuff , i it actually was {disfmarker} was {disfmarker} it didn't help at all in this particular case ."}, {"turn": 810, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 811, "name": "Professor", "id": "B", "contribution": " There was enough of a difference , I guess , between the testing and training . But by having them both there {disfmarker} The fact is some of the time , the discriminative stuff is gonna help you ."}, {"turn": 812, "name": "PhD", "id": "A", "contribution": " Mm - hmm ."}, {"turn": 813, "name": "Professor", "id": "B", "contribution": " And some of the time it 's going to hurt you ,"}, {"turn": 814, "name": "PhD", "id": "A", "contribution": " Right ."}, {"turn": 815, "name": "Professor", "id": "B", "contribution": " and by combining two information sources if , you know {disfmarker} if {disfmarker} if {disfmarker}"}, {"turn": 816, "name": "PhD", "id": "A", "contribution": " So you wouldn't necessarily then want to do LDA on the non - tandem features because now you 're doing something to them that {disfmarker}"}, {"turn": 817, "name": "Professor", "id": "B", "contribution": " That i i I think that 's counter to that idea ."}, {"turn": 818, "name": "PhD", "id": "A", "contribution": " Yeah , right ."}, {"turn": 819, "name": "Professor", "id": "B", "contribution": " Now , again , it 's {disfmarker} we 're just trying these different things . We don't really know what 's gonna work best . But if that 's the hypothesis , at least it would be counter to that hypothesis to do that ."}, {"turn": 820, "name": "PhD", "id": "A", "contribution": " Right ."}, {"turn": 821, "name": "Professor", "id": "B", "contribution": " Um , and in principle you would think that the neural net would do better at the discriminant part than LDA ."}, {"turn": 822, "name": "PhD", "id": "A", "contribution": " Right . Yeah . Well {disfmarker} y"}, {"turn": 823, "name": "Professor", "id": "B", "contribution": " Though , maybe not ."}, {"turn": 824, "name": "PhD", "id": "A", "contribution": " Yeah . Exactly . I mean , we , uh {disfmarker} we were getting ready to do the tandem , uh , stuff for the Hub - five system , and , um , Andreas and I talked about it , and the idea w the thought was , \" Well , uh , yeah , that i you know {disfmarker} th the neural net should be better , but we should at least have uh , a number , you know , to show that we did try the LDA in place of the neural net , so that we can you know , show a clear path ."}, {"turn": 825, "name": "Professor", "id": "B", "contribution": " Right ."}, {"turn": 826, "name": "PhD", "id": "A", "contribution": " You know , that you have it without it , then you have the LDA , then you have the neural net , and you can see , theoretically . So . I was just wondering {disfmarker} I {disfmarker} I {disfmarker}"}, {"turn": 827, "name": "Professor", "id": "B", "contribution": " Well , I think that 's a good idea ."}, {"turn": 828, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 829, "name": "Professor", "id": "B", "contribution": " Did {disfmarker} did you do that"}, {"turn": 830, "name": "PhD", "id": "A", "contribution": " Um . No ."}, {"turn": 831, "name": "Professor", "id": "B", "contribution": " or {disfmarker} tha that 's a {disfmarker}"}, {"turn": 832, "name": "PhD", "id": "A", "contribution": " That 's what {disfmarker} that 's what we 're gonna do next as soon as I finish this other thing . So ."}, {"turn": 833, "name": "Professor", "id": "B", "contribution": " Yeah . Yeah . No , well , that 's a good idea . I {disfmarker} I {disfmarker}"}, {"turn": 834, "name": "PhD", "id": "A", "contribution": " We just want to show ."}, {"turn": 835, "name": "Professor", "id": "B", "contribution": " i Yeah ."}, {"turn": 836, "name": "PhD", "id": "A", "contribution": " I mean , it {disfmarker} everybody believes it ,"}, {"turn": 837, "name": "Professor", "id": "B", "contribution": " Oh , no it 's a g"}, {"turn": 838, "name": "PhD", "id": "A", "contribution": " but you know , we just {disfmarker}"}, {"turn": 839, "name": "Professor", "id": "B", "contribution": " No , no , but it might not {disfmarker} not even be true ."}, {"turn": 840, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 841, "name": "Professor", "id": "B", "contribution": " I mean , it 's {disfmarker} it 's {disfmarker} it 's {disfmarker} it 's {disfmarker} it 's a great idea . I mean , one of the things that always disturbed me , uh , in the {disfmarker} the resurgence of neural nets that happened in the eighties was that , um , a lot of people {disfmarker} Because neural nets were pretty easy to {disfmarker} to use {disfmarker} a lot of people were just using them for all sorts of things without , uh , looking at all into the linear , uh {disfmarker} uh , versions of them ."}, {"turn": 842, "name": "PhD", "id": "A", "contribution": " Yeah . Mm - hmm . Yeah ."}, {"turn": 843, "name": "Professor", "id": "B", "contribution": " And , uh , people were doing recurrent nets but not looking at IIR filters , and {disfmarker} You know , I mean , uh , so I think , yeah , it 's definitely a good idea to try it ."}, {"turn": 844, "name": "PhD", "id": "A", "contribution": " Yeah , and everybody 's putting that on their {vocalsound} systems now , and so , I that 's what made me wonder about this ,"}, {"turn": 845, "name": "Professor", "id": "B", "contribution": " Well , they 've been putting them in their systems off and on for ten years ,"}, {"turn": 846, "name": "PhD", "id": "A", "contribution": " but ."}, {"turn": 847, "name": "Professor", "id": "B", "contribution": " but {disfmarker} but {disfmarker} but , uh ,"}, {"turn": 848, "name": "PhD", "id": "A", "contribution": " Yeah , what I mean is it 's {disfmarker} it 's like in the Hub - five evaluations , you know , and you read the system descriptions and everybody 's got , {vocalsound} you know , LDA on their features ."}, {"turn": 849, "name": "Professor", "id": "B", "contribution": " And now they all have that . I see ."}, {"turn": 850, "name": "PhD", "id": "A", "contribution": " And so ."}, {"turn": 851, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 852, "name": "PhD", "id": "A", "contribution": " Uh ."}, {"turn": 853, "name": "PhD", "id": "C", "contribution": " It 's the transformation they 're estimating on {disfmarker} Well , they are trained on the same data as the final HMM are ."}, {"turn": 854, "name": "PhD", "id": "A", "contribution": " Yeah , so it 's different . Yeah , exactly . Cuz they don't have these , you know , mismatches that {disfmarker} that you guys have ."}, {"turn": 855, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 856, "name": "PhD", "id": "A", "contribution": " So that 's why I was wondering if maybe it 's not even a good idea ."}, {"turn": 857, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 858, "name": "PhD", "id": "A", "contribution": " I don't know . I {disfmarker} I don't know enough about it ,"}, {"turn": 859, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 860, "name": "PhD", "id": "A", "contribution": " but {disfmarker} Um ."}, {"turn": 861, "name": "Professor", "id": "B", "contribution": " I mean , part of why {disfmarker} I {disfmarker} I think part of why you were getting into the KLT {disfmarker} Y you were describing to me at one point that you wanted to see if , uh , you know , getting good orthogonal features was {disfmarker} and combining the {disfmarker} the different temporal ranges {disfmarker} was the key thing that was happening or whether it was this discriminant thing , right ? So you were just trying {disfmarker} I think you r I mean , this is {disfmarker} it doesn't have the LDA aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ?"}, {"turn": 862, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 863, "name": "Professor", "id": "B", "contribution": " I think you were ."}, {"turn": 864, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Yeah ."}, {"turn": 865, "name": "Professor", "id": "B", "contribution": " Does something . It doesn't work as well . Yeah . Yeah ."}, {"turn": 866, "name": "PhD", "id": "D", "contribution": " So , yeah , I 've been exploring a parallel VAD without neural network with , like , less latency using SNR and energy , um , after the cleaning up . So what I 'd been trying was , um , uh {disfmarker} After the b after the noise compensation , n I was trying t to f find a f feature based on the ratio of the energies , that is , cl after clean and before clean . So that if {disfmarker} if they are , like , pretty c close to one , which means it 's speech . And if it is n if it is close to zero , which is {disfmarker} So it 's like a scale @ @ probability value . So I was trying , uh , with full band and multiple bands , m ps uh {disfmarker} separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . Uh , the advantage being like it doesn't have the latency of the neural net if it {disfmarker} if it can"}, {"turn": 867, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 868, "name": "PhD", "id": "D", "contribution": " g And {pause} it gave me like , uh , one point {disfmarker} One {disfmarker} more than one percent relative improvement . So , from fifty - three point six it went to fifty f four point eight . So it 's , like , only slightly more than a percent improvement ,"}, {"turn": 869, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 870, "name": "PhD", "id": "D", "contribution": " just like {disfmarker} Which means that it 's {disfmarker} it 's doing a slightly better job than the previous VAD ,"}, {"turn": 871, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 872, "name": "PhD", "id": "D", "contribution": " uh , at a l lower delay ."}, {"turn": 873, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 874, "name": "PhD", "id": "D", "contribution": " Um , so , um {disfmarker}"}, {"turn": 875, "name": "Professor", "id": "B", "contribution": " But {disfmarker} i d I 'm sorry ,"}, {"turn": 876, "name": "PhD", "id": "D", "contribution": " so {disfmarker} u"}, {"turn": 877, "name": "Professor", "id": "B", "contribution": " does it still have the median {pause} filter stuff ?"}, {"turn": 878, "name": "PhD", "id": "D", "contribution": " It still has the median filter ."}, {"turn": 879, "name": "Professor", "id": "B", "contribution": " So it still has most of the delay ,"}, {"turn": 880, "name": "PhD", "id": "D", "contribution": " So {disfmarker}"}, {"turn": 881, "name": "Professor", "id": "B", "contribution": " it just doesn't {disfmarker}"}, {"turn": 882, "name": "PhD", "id": "D", "contribution": " Yeah , so d with the delay , that 's gone is the input , which is the sixty millisecond . The forty plus {pause} twenty ."}, {"turn": 883, "name": "Professor", "id": "B", "contribution": " Well , w i"}, {"turn": 884, "name": "PhD", "id": "D", "contribution": " At the input of the neural net you have this , uh , f nine frames of context plus the delta ."}, {"turn": 885, "name": "Professor", "id": "B", "contribution": " Oh , plus the delta ,"}, {"turn": 886, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 887, "name": "Professor", "id": "B", "contribution": " right . OK ."}, {"turn": 888, "name": "PhD", "id": "D", "contribution": " Yeah . So that delay , plus the LDA ."}, {"turn": 889, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 890, "name": "PhD", "id": "D", "contribution": " Uh , so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output ."}, {"turn": 891, "name": "Professor", "id": "B", "contribution": " Mm - hmm . Mm - hmm ."}, {"turn": 892, "name": "PhD", "id": "D", "contribution": " Um . So . Yeah . So the {disfmarker} the {disfmarker} di the biggest {disfmarker} The problem f for me was to find a consistent threshold that works {pause} well across the different databases , because I t I try to make it work on tr SpeechDat - Car"}, {"turn": 893, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 894, "name": "PhD", "id": "D", "contribution": " and it fails on TI - digits , or if I try to make it work on that it 's just the Italian or something , it doesn't work on the Finnish ."}, {"turn": 895, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 896, "name": "PhD", "id": "D", "contribution": " So , um . So there are {disfmarker} there was , like , some problem in balancing the deletions and insertions when I try different thresholds ."}, {"turn": 897, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 898, "name": "PhD", "id": "D", "contribution": " So {disfmarker} The {disfmarker} I 'm still trying to make it better by using some other features from the {disfmarker} after the p clean up {disfmarker} maybe , some , uh , correlation {disfmarker} auto - correlation or some s additional features of {disfmarker} to mainly the improvement of the VAD . I 've been trying ."}, {"turn": 899, "name": "Professor", "id": "B", "contribution": " Now this {disfmarker} this {disfmarker} this , uh , \" before and after clean \" , it sounds like you think that 's a good feature . That {disfmarker} that , it {disfmarker} you th think that the , uh {disfmarker} the {disfmarker} i it appears to be a good feature , right ?"}, {"turn": 900, "name": "PhD", "id": "D", "contribution": " Mm - hmm ."}, {"turn": 901, "name": "Professor", "id": "B", "contribution": " What about using it in the neural net ?"}, {"turn": 902, "name": "PhD", "id": "D", "contribution": " Yeah ."}, {"turn": 903, "name": "PhD", "id": "C", "contribution": " Yeah , eventually we could {disfmarker} could just"}, {"turn": 904, "name": "PhD", "id": "D", "contribution": " Yeah , so {disfmarker} Yeah , so that 's the {disfmarker} Yeah . So we 've been thinking about putting it into the neural net also ."}, {"turn": 905, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 906, "name": "PhD", "id": "D", "contribution": " Because they did {disfmarker} that itself {disfmarker}"}, {"turn": 907, "name": "PhD", "id": "C", "contribution": " Then you don't have to worry about the thresholds and {disfmarker}"}, {"turn": 908, "name": "PhD", "id": "D", "contribution": " There 's a threshold and {disfmarker} Yeah ."}, {"turn": 909, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 910, "name": "PhD", "id": "C", "contribution": " but just {disfmarker}"}, {"turn": 911, "name": "PhD", "id": "D", "contribution": " Yeah . So that {disfmarker} that 's , uh {disfmarker}"}, {"turn": 912, "name": "Professor", "id": "B", "contribution": " Yeah . So if we {disfmarker} if we can live with the latency or cut the latencies elsewhere , then {disfmarker} then that would be a , uh , good thing ."}, {"turn": 913, "name": "PhD", "id": "D", "contribution": " Yeah . Yeah ."}, {"turn": 914, "name": "Professor", "id": "B", "contribution": " Um , anybody {disfmarker} has anybody {disfmarker} you guys or {disfmarker} or Naren , uh , somebody , tried the , uh , um , second th second stream thing ? Uh ."}, {"turn": 915, "name": "PhD", "id": "D", "contribution": " Oh , I just {disfmarker} I just h put the second stream in place and , uh ran one experiment , but just like {disfmarker} just to know that everything is fine ."}, {"turn": 916, "name": "Professor", "id": "B", "contribution": " Uh - huh ."}, {"turn": 917, "name": "PhD", "id": "D", "contribution": " So it was like , uh , forty - five cepstrum plus twenty - three mel {disfmarker} log mel ."}, {"turn": 918, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 919, "name": "PhD", "id": "D", "contribution": " And {disfmarker} and , just , like , it gave me the baseline performance of the Aurora , which is like zero improvement ."}, {"turn": 920, "name": "Professor", "id": "B", "contribution": " Yeah . Yeah ."}, {"turn": 921, "name": "PhD", "id": "D", "contribution": " So I just tried it on Italian just to know that everything is {disfmarker} But I {disfmarker} I didn't export anything out of it because it was , like , a weird feature set ."}, {"turn": 922, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 923, "name": "PhD", "id": "D", "contribution": " So ."}, {"turn": 924, "name": "Professor", "id": "B", "contribution": " Yeah . Well , what I think , you know , would be more what you 'd want to do is {disfmarker} is {disfmarker} is , uh , put it into another neural net . Right ?"}, {"turn": 925, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 926, "name": "PhD", "id": "D", "contribution": " Yeah , yeah , yeah , yeah ."}, {"turn": 927, "name": "Professor", "id": "B", "contribution": " And then {disfmarker} But , yeah , we 're {disfmarker} we 're not quite there yet . So we have to {vocalsound} figure out the neural nets , I guess ."}, {"turn": 928, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 929, "name": "PhD", "id": "D", "contribution": " The uh , other thing I was wondering was , um , if the neural net , um , has any {disfmarker} because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , a additional {disfmarker} some four plus some {disfmarker} f few more conditions which it hasn't seen , actually ,"}, {"turn": 930, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 931, "name": "PhD", "id": "D", "contribution": " from the {disfmarker} f f while testing ."}, {"turn": 932, "name": "PhD", "id": "C", "contribution": " Yeah , yeah . Right ."}, {"turn": 933, "name": "PhD", "id": "D", "contribution": " Um {disfmarker} instead of just h having c uh , those cleaned up t cepstrum , sh should we feed some additional information , like {disfmarker} The {disfmarker} the {disfmarker} We have the VAD flag . I mean , should we f feed the VAD flag , also , at the input so that it {disfmarker} it has some additional discriminating information at the input ?"}, {"turn": 934, "name": "PhD", "id": "C", "contribution": " Hmm - hmm ! Um {disfmarker}"}, {"turn": 935, "name": "Professor", "id": "B", "contribution": " Wh - uh , the {disfmarker} the VAD what ?"}, {"turn": 936, "name": "PhD", "id": "D", "contribution": " We have the VAD information also available at the back - end ."}, {"turn": 937, "name": "Professor", "id": "B", "contribution": " Uh - huh ."}, {"turn": 938, "name": "PhD", "id": "D", "contribution": " So if it is something the neural net is not able to discriminate the classes {disfmarker}"}, {"turn": 939, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 940, "name": "PhD", "id": "D", "contribution": " I mean {disfmarker} Because most of it is sil I mean , we have dropped some silence f We have dropped so silence frames ?"}, {"turn": 941, "name": "Professor", "id": "B", "contribution": " Mm - hmm ."}, {"turn": 942, "name": "PhD", "id": "D", "contribution": " No , we haven't dropped silence frames still ."}, {"turn": 943, "name": "PhD", "id": "C", "contribution": " Uh , still not . Yeah ."}, {"turn": 944, "name": "PhD", "id": "D", "contribution": " Yeah . So {disfmarker}"}, {"turn": 945, "name": "PhD", "id": "C", "contribution": " Th"}, {"turn": 946, "name": "PhD", "id": "D", "contribution": " the b b biggest classification would be the speech and silence . So , by having an additional , uh , feature which says \" this is speech and this is nonspeech \" , I mean , it certainly helps in some unseen noise conditions for the neural net ."}, {"turn": 947, "name": "PhD", "id": "A", "contribution": " What {disfmarker} Do y do you have that feature available for the test data ?"}, {"turn": 948, "name": "PhD", "id": "D", "contribution": " Well , I mean , we have {disfmarker} we are transferring the VAD to the back - end {disfmarker} feature to the back - end . Because we are dropping it at the back - end after everything {disfmarker} all the features are computed ."}, {"turn": 949, "name": "PhD", "id": "A", "contribution": " Oh , oh , I see ."}, {"turn": 950, "name": "PhD", "id": "D", "contribution": " So {disfmarker}"}, {"turn": 951, "name": "PhD", "id": "A", "contribution": " I see ."}, {"turn": 952, "name": "PhD", "id": "D", "contribution": " so the neural {disfmarker} so that is coming from a separate neural net or some VAD ."}, {"turn": 953, "name": "PhD", "id": "A", "contribution": " OK . OK ."}, {"turn": 954, "name": "PhD", "id": "D", "contribution": " Which is {disfmarker} which is certainly giving a"}, {"turn": 955, "name": "PhD", "id": "A", "contribution": " So you 're saying , feed that , also , into {pause} the neural net ."}, {"turn": 956, "name": "PhD", "id": "D", "contribution": " to {disfmarker} Yeah . So it it 's an {disfmarker} additional discriminating information ."}, {"turn": 957, "name": "PhD", "id": "A", "contribution": " Yeah . Yeah . Right ."}, {"turn": 958, "name": "PhD", "id": "D", "contribution": " So that {disfmarker}"}, {"turn": 959, "name": "Professor", "id": "B", "contribution": " You could feed it into the neural net . The other thing {comment} you could do is just , um , p modify the , uh , output probabilities of the {disfmarker} of the , uh , uh , um , neural net , tandem neural net , {comment} based on the fact that you have a silence probability ."}, {"turn": 960, "name": "PhD", "id": "D", "contribution": " Mm - hmm ."}, {"turn": 961, "name": "Professor", "id": "B", "contribution": " Right ?"}, {"turn": 962, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 963, "name": "Professor", "id": "B", "contribution": " So you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize ."}, {"turn": 964, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 965, "name": "Professor", "id": "B", "contribution": " Uh , I mean , you 'd have to do the nonlinearity part and deal with that . Uh , I mean , go backwards from what the nonlinearity would , you know {disfmarker} would be ."}, {"turn": 966, "name": "PhD", "id": "D", "contribution": " Through {disfmarker} t to the soft max ."}, {"turn": 967, "name": "Professor", "id": "B", "contribution": " But {disfmarker} but , uh {disfmarker}"}, {"turn": 968, "name": "PhD", "id": "C", "contribution": " Yeah , so {disfmarker} maybe , yeah , when {disfmarker}"}, {"turn": 969, "name": "PhD", "id": "A", "contribution": " But in principle wouldn't it be better to feed it in ? And let the net do that ?"}, {"turn": 970, "name": "Professor", "id": "B", "contribution": " Well , u Not sure ."}, {"turn": 971, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 972, "name": "Professor", "id": "B", "contribution": " I mean , let 's put it this way . I mean , y you {disfmarker} you have this complicated system with thousands and thousand parameters"}, {"turn": 973, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 974, "name": "Professor", "id": "B", "contribution": " and you can tell it , uh , \" Learn this thing . \" Or you can say , \" It 's silence ! Go away ! \" I mean , I mean , i Doesn't {disfmarker} ? I think {disfmarker} I think the second one sounds a lot more direct ."}, {"turn": 975, "name": "PhD", "id": "A", "contribution": " What {disfmarker} what if you {disfmarker}"}, {"turn": 976, "name": "Professor", "id": "B", "contribution": " Uh ."}, {"turn": 977, "name": "PhD", "id": "A", "contribution": " Right . So , what if you then , uh {disfmarker} since you know this , what if you only use the neural net on the speech portions ?"}, {"turn": 978, "name": "Professor", "id": "B", "contribution": " Well , uh ,"}, {"turn": 979, "name": "PhD", "id": "C", "contribution": " That 's what {disfmarker}"}, {"turn": 980, "name": "PhD", "id": "A", "contribution": " Well , I guess that 's the same . Uh , that 's similar ."}, {"turn": 981, "name": "Professor", "id": "B", "contribution": " Yeah , I mean , y you 'd have to actually run it continuously ,"}, {"turn": 982, "name": "PhD", "id": "A", "contribution": " But I mean {disfmarker} I mean , train the net only on {disfmarker}"}, {"turn": 983, "name": "Professor", "id": "B", "contribution": " but it 's {disfmarker} @ @ {disfmarker} Well , no , you want to train on {disfmarker} on the nonspeech also , because that 's part of what you 're learning in it , to {disfmarker} to {disfmarker} to generate , that it 's {disfmarker} it has to distinguish between ."}, {"turn": 984, "name": "PhD", "id": "D", "contribution": " Speech ."}, {"turn": 985, "name": "PhD", "id": "A", "contribution": " But I mean , if you 're gonna {disfmarker} if you 're going to multiply the output of the net by this other decision , uh , would {disfmarker} then you don't care about whether the net makes that distinction , right ?"}, {"turn": 986, "name": "Professor", "id": "B", "contribution": " Well , yeah . But this other thing isn't perfect ."}, {"turn": 987, "name": "PhD", "id": "A", "contribution": " Ah ."}, {"turn": 988, "name": "Professor", "id": "B", "contribution": " So that you bring in some information from the net itself ."}, {"turn": 989, "name": "PhD", "id": "A", "contribution": " Right , OK . That 's a good point ."}, {"turn": 990, "name": "Professor", "id": "B", "contribution": " Yeah . Now the only thing that {disfmarker} that bothers me about all this is that I {disfmarker} I {disfmarker} I {disfmarker} The {disfmarker} the fact {disfmarker} i i It 's sort of bothersome that you 're getting more deletions ."}, {"turn": 991, "name": "PhD", "id": "C", "contribution": " Yeah . But {disfmarker} So I might maybe look at , is it due to the fact that um , the probability of the silence at the output of the network , is , uh ,"}, {"turn": 992, "name": "Professor", "id": "B", "contribution": " Is too high ."}, {"turn": 993, "name": "PhD", "id": "C", "contribution": " too {disfmarker} too high or {disfmarker}"}, {"turn": 994, "name": "Professor", "id": "B", "contribution": " Yeah . So maybe {disfmarker} So {disfmarker}"}, {"turn": 995, "name": "PhD", "id": "C", "contribution": " If it 's the case , then multiplying it again by {disfmarker} i by something ?"}, {"turn": 996, "name": "PhD", "id": "D", "contribution": " It may not be {disfmarker} it {disfmarker}"}, {"turn": 997, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 998, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 999, "name": "PhD", "id": "D", "contribution": " Yeah , it {disfmarker} it may be too {disfmarker} it 's too high in a sense , like , everything is more like a , um , flat probability ."}, {"turn": 1000, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 1001, "name": "PhD", "id": "C", "contribution": " Oh - eee - hhh ."}, {"turn": 1002, "name": "PhD", "id": "D", "contribution": " So , like , it 's not really doing any distinction between speech and nonspeech {disfmarker}"}, {"turn": 1003, "name": "PhD", "id": "C", "contribution": " Uh , yeah ."}, {"turn": 1004, "name": "PhD", "id": "D", "contribution": " or , I mean , different {disfmarker} among classes ."}, {"turn": 1005, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 1006, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 1007, "name": "PhD", "id": "A", "contribution": " Be interesting to look at the {disfmarker} Yeah , for the {disfmarker} I wonder if you could do this . But if you look at the , um , highly mism high mismat the output of the net on the high mismatch case and just look at , you know , the distribution versus the {disfmarker} the other ones , do you {disfmarker} do you see more peaks or something ?"}, {"turn": 1008, "name": "PhD", "id": "C", "contribution": " Yeah . Yeah , like the entropy of the {disfmarker} the output ,"}, {"turn": 1009, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 1010, "name": "Professor", "id": "B", "contribution": " Yeah , for instance ."}, {"turn": 1011, "name": "PhD", "id": "C", "contribution": " or {disfmarker}"}, {"turn": 1012, "name": "Professor", "id": "B", "contribution": " But I {disfmarker} bu"}, {"turn": 1013, "name": "PhD", "id": "C", "contribution": " It {disfmarker} it seems that the VAD network doesn't {disfmarker} Well , it doesn't drop , uh , too many frames because the dele the number of deletion is reasonable . But it 's just when we add the tandem , the final MLP , and then {disfmarker}"}, {"turn": 1014, "name": "Professor", "id": "B", "contribution": " Yeah . Now the only problem is you don't want to ta I guess wait for the output of the VAD before you can put something into the other system ,"}, {"turn": 1015, "name": "PhD", "id": "C", "contribution": " u"}, {"turn": 1016, "name": "Professor", "id": "B", "contribution": " cuz that 'll shoot up the latency a lot , right ? Am I missing something here ?"}, {"turn": 1017, "name": "PhD", "id": "C", "contribution": " But {disfmarker}"}, {"turn": 1018, "name": "PhD", "id": "D", "contribution": " Mm - hmm ."}, {"turn": 1019, "name": "PhD", "id": "C", "contribution": " Yeah . Right ."}, {"turn": 1020, "name": "Professor", "id": "B", "contribution": " Yeah . So that 's maybe a problem with what I was just saying . But {disfmarker} but {disfmarker} I I guess {disfmarker}"}, {"turn": 1021, "name": "PhD", "id": "A", "contribution": " But if you were gonna put it in as a feature it means you already have it by the time you get to the tandem net , right ?"}, {"turn": 1022, "name": "PhD", "id": "D", "contribution": " Um , well . We {disfmarker} w we don't have it , actually ,"}, {"turn": 1023, "name": "Professor", "id": "B", "contribution": " No ."}, {"turn": 1024, "name": "PhD", "id": "D", "contribution": " because it 's {disfmarker} it has a high rate energy {disfmarker}"}, {"turn": 1025, "name": "PhD", "id": "A", "contribution": " Ah ."}, {"turn": 1026, "name": "PhD", "id": "D", "contribution": " the VAD has a {disfmarker}"}, {"turn": 1027, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 1028, "name": "PhD", "id": "A", "contribution": " OK ."}, {"turn": 1029, "name": "Professor", "id": "B", "contribution": " It 's kind of done in {disfmarker} I mean , some of the things are , not in parallel , but certainly , it would be in parallel with the {disfmarker} with a tandem net ."}, {"turn": 1030, "name": "PhD", "id": "A", "contribution": " Right ."}, {"turn": 1031, "name": "Professor", "id": "B", "contribution": " In time . So maybe , if that doesn't work , um {disfmarker} But it would be interesting to see if that was the problem , anyway . And {disfmarker} and {disfmarker} and then I guess another alternative would be to take the feature that you 're feeding into the VAD , and feeding it into the other one as well ."}, {"turn": 1032, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 1033, "name": "Professor", "id": "B", "contribution": " And then maybe it would just learn {disfmarker} learn it better ."}, {"turn": 1034, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 1035, "name": "Professor", "id": "B", "contribution": " Um {disfmarker} But that 's {disfmarker} Yeah , that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , um , causing deletions by having this silence probability up {disfmarker} up too high ,"}, {"turn": 1036, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 1037, "name": "Professor", "id": "B", "contribution": " at some point where the VAD is saying it 's actually speech ."}, {"turn": 1038, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 1039, "name": "Professor", "id": "B", "contribution": " Which is probably true ."}, {"turn": 1040, "name": "PhD", "id": "C", "contribution": " So , m"}, {"turn": 1041, "name": "Professor", "id": "B", "contribution": " Cuz {disfmarker} Well , the V A if the VAD said {disfmarker} since the VAD is {disfmarker} is {disfmarker} is right a lot , uh {disfmarker}"}, {"turn": 1042, "name": "PhD", "id": "C", "contribution": " Yeah ."}, {"turn": 1043, "name": "Professor", "id": "B", "contribution": " Hmm . Anyway . Might be ."}, {"turn": 1044, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 1045, "name": "Professor", "id": "B", "contribution": " Yeah . Well , we just started working with it . But these are {disfmarker} these are some good ideas I think ."}, {"turn": 1046, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Yeah , and the other thing {disfmarker} Well , there are other issues maybe for the tandem , like , uh , well , do we want to , w uh n Do we want to work on the targets ? Or , like , instead of using phonemes , using more context dependent units ?"}, {"turn": 1047, "name": "PhD", "id": "A", "contribution": " For the tandem net you mean ?"}, {"turn": 1048, "name": "PhD", "id": "C", "contribution": " Well , I 'm {disfmarker} Yeah ."}, {"turn": 1049, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 1050, "name": "PhD", "id": "C", "contribution": " I 'm thinking , also , a w about Dan 's work where he {disfmarker} he trained {vocalsound} a network , not on phoneme targets but on the HMM state targets . And {disfmarker} it was giving s slightly better results ."}, {"turn": 1051, "name": "Professor", "id": "B", "contribution": " Problem is , if you are going to run this on different m test sets , including large vocabulary ,"}, {"turn": 1052, "name": "PhD", "id": "C", "contribution": " Yeah . Yeah ."}, {"turn": 1053, "name": "Professor", "id": "B", "contribution": " um ,"}, {"turn": 1054, "name": "PhD", "id": "C", "contribution": " Uh {disfmarker}"}, {"turn": 1055, "name": "Professor", "id": "B", "contribution": " I think {disfmarker}"}, {"turn": 1056, "name": "PhD", "id": "C", "contribution": " Mmm . I was just thinking maybe about , like , generalized diphones , and {disfmarker} come up with a {disfmarker} a reasonable , not too large , set of context dependent units , and {disfmarker} and {disfmarker} Yeah . And then anyway we would have to reduce this with the KLT ."}, {"turn": 1057, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 1058, "name": "PhD", "id": "C", "contribution": " So . But {disfmarker} I don't know ."}, {"turn": 1059, "name": "Professor", "id": "B", "contribution": " Yeah . Well , maybe . But I d I d it {disfmarker} it {disfmarker} i it 's all worth looking at ,"}, {"turn": 1060, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 1061, "name": "Professor", "id": "B", "contribution": " but it sounds to me like , uh , looking at the relationship between this and the {disfmarker} speech noise stuff is {disfmarker} is {disfmarker} is probably a key thing ."}, {"turn": 1062, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 1063, "name": "Professor", "id": "B", "contribution": " That and the correlation between stuff ."}, {"turn": 1064, "name": "PhD", "id": "A", "contribution": " So if , uh {disfmarker} if the , uh , high mismatch case had been more like the , uh , the other two cases {comment} in terms of giving you just a better performance , {comment} how would this number have changed ?"}, {"turn": 1065, "name": "PhD", "id": "C", "contribution": " Mm - hmm . Oh , it would be {disfmarker} Yeah . Around five percent better , I guess . If {disfmarker} if {disfmarker} i"}, {"turn": 1066, "name": "PhD", "id": "A", "contribution": " y Like sixty ?"}, {"turn": 1067, "name": "Professor", "id": "B", "contribution": " Well , we don't know what 's it 's gonna be the TI - digits yet . He hasn't got the results back yet ."}, {"turn": 1068, "name": "PhD", "id": "C", "contribution": " Yeah . If you extrapolate the SpeechDat - Car well - matched and medium - mismatch , it 's around , yeah , maybe five ."}, {"turn": 1069, "name": "PhD", "id": "A", "contribution": " Uh - huh . Yeah . So this would be sixty - two ?"}, {"turn": 1070, "name": "Professor", "id": "B", "contribution": " Sixty - two ."}, {"turn": 1071, "name": "PhD", "id": "A", "contribution": " Which is {disfmarker}"}, {"turn": 1072, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 1073, "name": "PhD", "id": "C", "contribution": " Sixty - two , yeah ."}, {"turn": 1074, "name": "PhD", "id": "D", "contribution": " Somewhere around sixty , must be . Right ? Yeah ."}, {"turn": 1075, "name": "PhD", "id": "C", "contribution": " Well , it 's around five percent , because it 's {disfmarker} s Right ? If everything is five percent ."}, {"turn": 1076, "name": "PhD", "id": "D", "contribution": " Yeah . Yeah ."}, {"turn": 1077, "name": "PhD", "id": "A", "contribution": " All the other ones were five percent ,"}, {"turn": 1078, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 1079, "name": "PhD", "id": "A", "contribution": " the {disfmarker}"}, {"turn": 1080, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 1081, "name": "PhD", "id": "C", "contribution": " I d I d I just have the SpeechDat - Car right now , so {disfmarker}"}, {"turn": 1082, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 1083, "name": "PhD", "id": "C", "contribution": " It 's running {disfmarker} it shou we should have the results today during the afternoon ,"}, {"turn": 1084, "name": "PhD", "id": "A", "contribution": " Hmm ."}, {"turn": 1085, "name": "PhD", "id": "C", "contribution": " but {disfmarker} Well ."}, {"turn": 1086, "name": "Professor", "id": "B", "contribution": " Hmm . Well {disfmarker} Um {disfmarker} So I won't be here for {disfmarker}"}, {"turn": 1087, "name": "PhD", "id": "A", "contribution": " When {disfmarker} When do you leave ?"}, {"turn": 1088, "name": "Professor", "id": "B", "contribution": " Uh , I 'm leaving next Wednesday . May or may not be in in the morning . I leave in the afternoon . Um ,"}, {"turn": 1089, "name": "PhD", "id": "A", "contribution": " But you 're {disfmarker}"}, {"turn": 1090, "name": "Professor", "id": "B", "contribution": " so I {disfmarker}"}, {"turn": 1091, "name": "PhD", "id": "A", "contribution": " are you {disfmarker} you 're not gonna be around this afternoon ?"}, {"turn": 1092, "name": "Professor", "id": "B", "contribution": " Yeah ."}, {"turn": 1093, "name": "PhD", "id": "A", "contribution": " Oh ."}, {"turn": 1094, "name": "Professor", "id": "B", "contribution": " Oh , well . I 'm talking about next week . I 'm leaving {disfmarker} leaving next Wednesday ."}, {"turn": 1095, "name": "PhD", "id": "A", "contribution": " Uh - huh ."}, {"turn": 1096, "name": "Professor", "id": "B", "contribution": " This afternoon {disfmarker} uh {disfmarker} Oh , right , for the Meeting meeting ? Yeah , that 's just cuz of something on campus ."}, {"turn": 1097, "name": "PhD", "id": "A", "contribution": " Ah , OK , OK ."}, {"turn": 1098, "name": "Professor", "id": "B", "contribution": " Yeah . But , um , yeah , so next week I won't , and the week after I won't , cuz I 'll be in Finland . And the week after that I won't . By that time you 'll be {disfmarker} {comment} Uh , you 'll both be gone {pause} from here . So there 'll be no {disfmarker} definitely no meeting on {disfmarker} on September sixth . Uh ,"}, {"turn": 1099, "name": "PhD", "id": "A", "contribution": " What 's September sixth ?"}, {"turn": 1100, "name": "Professor", "id": "B", "contribution": " and {disfmarker} Uh , that 's during Eurospeech ."}, {"turn": 1101, "name": "PhD", "id": "A", "contribution": " Oh , oh , right . OK ."}, {"turn": 1102, "name": "Professor", "id": "B", "contribution": " So , uh , Sunil will be in Oregon . Uh , Stephane and I will be in Denmark . Uh {disfmarker} Right ? So it 'll be a few weeks , really , before we have a meeting of the same cast of characters . Um , but , uh {disfmarker} I guess , just {disfmarker} I mean , you guys should probably meet . And maybe Barry {disfmarker} Barry will be around . And {disfmarker} and then uh , uh , we 'll start up again with Dave and {disfmarker} Dave and Barry and Stephane and us on the , uh , twentieth . No . Thirteenth ? About a month ?"}, {"turn": 1103, "name": "PhD", "id": "A", "contribution": " So , uh , you 're gonna be gone for the next three weeks or something ?"}, {"turn": 1104, "name": "Professor", "id": "B", "contribution": " I 'm gone for two and a half weeks starting {disfmarker} starting next Wed - late next Wednesday ."}, {"turn": 1105, "name": "PhD", "id": "A", "contribution": " So that 's {disfmarker} you won't be at the next three of these meetings . Is that right ?"}, {"turn": 1106, "name": "Professor", "id": "B", "contribution": " Uh , I won't {disfmarker} it 's probably four because of {disfmarker} is it three ? Let 's see , twenty - third , thirtieth , sixth . That 's right , next three . And the {disfmarker} the third one won't {disfmarker} probably won't be a meeting , cuz {disfmarker} cuz , uh , Su - Sunil , Stephane , and I will all not be here ."}, {"turn": 1107, "name": "PhD", "id": "A", "contribution": " Oh , right . Right ."}, {"turn": 1108, "name": "Professor", "id": "B", "contribution": " Um {disfmarker} Mmm . {comment} So it 's just , uh , the next two where there will be {disfmarker} there , you know , may as well be meetings ,"}, {"turn": 1109, "name": "PhD", "id": "A", "contribution": " OK ."}, {"turn": 1110, "name": "Professor", "id": "B", "contribution": " but I just won't be at them . And then starting up on the thirteenth , {nonvocalsound} uh , we 'll have meetings again but we 'll have to do without Sunil here somehow ."}, {"turn": 1111, "name": "PhD", "id": "A", "contribution": " When do you go back ?"}, {"turn": 1112, "name": "Professor", "id": "B", "contribution": " So ."}, {"turn": 1113, "name": "PhD", "id": "D", "contribution": " Thirty - first , August ."}, {"turn": 1114, "name": "Professor", "id": "B", "contribution": " Yeah . Yeah . So . Cool ."}, {"turn": 1115, "name": "PhD", "id": "A", "contribution": " When is the evaluation ? November , or something ?"}, {"turn": 1116, "name": "Professor", "id": "B", "contribution": " Yeah , it was supposed to be November fifteenth . Has anybody heard anything different ?"}, {"turn": 1117, "name": "PhD", "id": "C", "contribution": " I don't know . The meeting in {disfmarker} is the five and six of December . So {disfmarker}"}, {"turn": 1118, "name": "PhD", "id": "D", "contribution": " p s It 's like {disfmarker} Yeah , it 's tentatively all full . Yeah ."}, {"turn": 1119, "name": "PhD", "id": "C", "contribution": " Mm - hmm ."}, {"turn": 1120, "name": "PhD", "id": "D", "contribution": " Uh , that 's a proposed date , I guess ."}, {"turn": 1121, "name": "PhD", "id": "C", "contribution": " Yeah , um {disfmarker} so the evaluation should be on a week before or {disfmarker}"}, {"turn": 1122, "name": "PhD", "id": "A", "contribution": " Yeah ."}, {"turn": 1123, "name": "Professor", "id": "B", "contribution": " Yep . But , no , this is good progress . So . Uh {disfmarker} OK ."}, {"turn": 1124, "name": "PhD", "id": "A", "contribution": " Should we do digits ?"}, {"turn": 1125, "name": "Professor", "id": "B", "contribution": " Guess we 're done . Digits ? Yep ."}, {"turn": 1126, "name": "PhD", "id": "A", "contribution": " OK ."}, {"turn": 1127, "name": "Professor", "id": "B", "contribution": " It 's a wrap ."}]}